{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuwurgcxfiRF",
        "outputId": "69518234-59d3-42fb-c5e8-638fb460c82f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (2.0.0+cu118)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import imageio.v3 as iio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "!pip install torchmetrics\n",
        "import torchmetrics\n",
        "\n",
        "!pip install einops\n",
        "import einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQyigSZEGUxi",
        "outputId": "3275af30-943f-444e-b142-a0b7c4283bd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  inflating: Dataset_Student/val/data/video_1941/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1941/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1941/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1941/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1941/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1941/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1941/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1941/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1941/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1941/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1941/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1941/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1941/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1941/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1941/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1941/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1941/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1941/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1941/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1941/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1941/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1941/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1941/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1941/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1941/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1941/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1941/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1941/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1941/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1941/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1941/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1941/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1180/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1180/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1510/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1510/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1722/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1722/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1346/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1346/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1948/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1948/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1174/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1174/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1983/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1983/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1977/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1977/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1379/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1379/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1173/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1173/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1341/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1341/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1725/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1725/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1517/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1517/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1187/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1187/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1528/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1528/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1970/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1970/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1984/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1984/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1118/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1118/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1924/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1924/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1588/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1588/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1315/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1315/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1127/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1127/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1543/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1543/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1771/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1771/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1785/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1785/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1923/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1923/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1749/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1749/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1782/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1782/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1776/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1776/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1544/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1544/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1120/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1120/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1312/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1312/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1129/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1129/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1915/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1915/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1586/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1586/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1116/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1116/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1324/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1324/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1740/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1740/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1572/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1572/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1912/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1912/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1778/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1778/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1575/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1575/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1747/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1747/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1323/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1323/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1111/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1111/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1581/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1581/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1186/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1186/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1340/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1340/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1172/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1172/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1516/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1516/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1724/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1724/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1985/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1985/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1529/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1529/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1971/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1971/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1723/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1723/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1511/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1511/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1175/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1175/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1949/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1949/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1347/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1347/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1181/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1181/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1378/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1378/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1976/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1976/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1982/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1982/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1143/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1143/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1371/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1371/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1715/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1715/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1527/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1527/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1385/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1385/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1518/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1518/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1940/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1940/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1188/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1188/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1382/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1382/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1520/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1520/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1712/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1712/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1376/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1376/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1144/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1144/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1978/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1978/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1947/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1947/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1349/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1349/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1913/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1913/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1779/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1779/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1580/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1580/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1746/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1746/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1574/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1574/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1110/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1110/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1322/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1322/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1914/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1914/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1128/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1128/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1325/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1325/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1117/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1117/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1573/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1573/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1741/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1741/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1587/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1587/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1922/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1922/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1748/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1748/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1545/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1545/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1777/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1777/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1313/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1313/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1121/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1121/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1783/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1783/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1589/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1589/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1925/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1925/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1119/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1119/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1784/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1784/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1126/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1126/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1314/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1314/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1770/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1770/._image_18.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_15.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_15.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_14.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_14.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_16.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_16.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_17.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_17.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_13.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_13.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_12.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_12.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_10.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_10.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_11.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_11.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_8.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_8.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_9.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_9.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/mask.npy  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._mask.npy  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_2.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_2.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_3.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_3.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_1.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_1.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_0.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_0.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_4.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_4.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_5.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_5.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_7.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_7.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_6.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_6.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_20.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_20.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_21.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_21.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_19.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_19.png  \n",
            "  inflating: Dataset_Student/val/data/video_1542/image_18.png  \n",
            "  inflating: __MACOSX/Dataset_Student/val/data/video_1542/._image_18.png  \n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/uc?id=1PHlqeEjte_ZvBdnpFAZiQXaaycqb5Ul1\n",
        "!unzip Dataset_Student_annot.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "7K3pbtqjF4Vv"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "-MVbXJMZHIJJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import os.path\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "from typing import List, Union, Tuple, Any\n",
        "\n",
        "\n",
        "class VideoRecord(object):\n",
        "    \"\"\"\n",
        "    Helper class for class VideoFrameDataset. This class\n",
        "    represents a video sample's metadata.\n",
        "\n",
        "    Args:\n",
        "        root_datapath: the system path to the root folder\n",
        "                       of the videos.\n",
        "        row: A list with four or more elements where 1) The first\n",
        "             element is the path to the video sample's frames excluding\n",
        "             the root_datapath prefix 2) The  second element is the starting frame id of the video\n",
        "             3) The third element is the inclusive ending frame id of the video\n",
        "             4) The fourth element is the label index.\n",
        "             5) any following elements are labels in the case of multi-label classification\n",
        "    \"\"\"\n",
        "    def __init__(self, row, root_datapath):\n",
        "        self._data = row\n",
        "        self._path = os.path.join(root_datapath, row[0])\n",
        "\n",
        "\n",
        "    @property\n",
        "    def path(self) -> str:\n",
        "        return self._path\n",
        "\n",
        "    @property\n",
        "    def num_frames(self) -> int:\n",
        "        return self.end_frame - self.start_frame + 1  # +1 because end frame is inclusive\n",
        "    @property\n",
        "    def start_frame(self) -> int:\n",
        "        return int(self._data[1])\n",
        "\n",
        "    @property\n",
        "    def end_frame(self) -> int:\n",
        "        return int(self._data[2])\n",
        "\n",
        "    @property\n",
        "    def label(self) -> Union[int, List[int]]:\n",
        "        # just one label_id\n",
        "        if len(self._data) == 4:\n",
        "            return int(self._data[3])\n",
        "        # sample associated with multiple labels\n",
        "        else:\n",
        "            return [int(label_id) for label_id in self._data[3:]]\n",
        "\n",
        "class VideoFrameDataset(torch.utils.data.Dataset):\n",
        "    r\"\"\"\n",
        "    A highly efficient and adaptable dataset class for videos.\n",
        "    Instead of loading every frame of a video,\n",
        "    loads x RGB frames of a video (sparse temporal sampling) and evenly\n",
        "    chooses those frames from start to end of the video, returning\n",
        "    a list of x PIL images or ``FRAMES x CHANNELS x HEIGHT x WIDTH``\n",
        "    tensors where FRAMES=x if the ``ImglistToTensor()``\n",
        "    transform is used.\n",
        "\n",
        "    More specifically, the frame range [START_FRAME, END_FRAME] is divided into NUM_SEGMENTS\n",
        "    segments and FRAMES_PER_SEGMENT consecutive frames are taken from each segment.\n",
        "\n",
        "    Note:\n",
        "        A demonstration of using this class can be seen\n",
        "        in ``demo.py``\n",
        "        https://github.com/RaivoKoot/Video-Dataset-Loading-Pytorch\n",
        "\n",
        "    Note:\n",
        "        This dataset broadly corresponds to the frame sampling technique\n",
        "        introduced in ``Temporal Segment Networks`` at ECCV2016\n",
        "        https://arxiv.org/abs/1608.00859.\n",
        "\n",
        "\n",
        "    Note:\n",
        "        This class relies on receiving video data in a structure where\n",
        "        inside a ``ROOT_DATA`` folder, each video lies in its own folder,\n",
        "        where each video folder contains the frames of the video as\n",
        "        individual files with a naming convention such as\n",
        "        img_001.jpg ... img_059.jpg.\n",
        "        For enumeration and annotations, this class expects to receive\n",
        "        the path to a .txt file where each video sample has a row with four\n",
        "        (or more in the case of multi-label, see README on Github)\n",
        "        space separated values:\n",
        "        ``VIDEO_FOLDER_PATH     START_FRAME      END_FRAME      LABEL_INDEX``.\n",
        "        ``VIDEO_FOLDER_PATH`` is expected to be the path of a video folder\n",
        "        excluding the ``ROOT_DATA`` prefix. For example, ``ROOT_DATA`` might\n",
        "        be ``home\\data\\datasetxyz\\videos\\``, inside of which a ``VIDEO_FOLDER_PATH``\n",
        "        might be ``jumping\\0052\\`` or ``sample1\\`` or ``00053\\``.\n",
        "\n",
        "    Args:\n",
        "        root_path: The root path in which video folders lie.\n",
        "                   this is ROOT_DATA from the description above.\n",
        "        annotationfile_path: The .txt annotation file containing\n",
        "                             one row per video sample as described above.\n",
        "        num_segments: The number of segments the video should\n",
        "                      be divided into to sample frames from.\n",
        "        frames_per_segment: The number of frames that should\n",
        "                            be loaded per segment. For each segment's\n",
        "                            frame-range, a random start index or the\n",
        "                            center is chosen, from which frames_per_segment\n",
        "                            consecutive frames are loaded.\n",
        "        imagefile_template: The image filename template that video frame files\n",
        "                            have inside of their video folders as described above.\n",
        "        transform: Transform pipeline that receives a list of PIL images/frames.\n",
        "        test_mode: If True, frames are taken from the center of each\n",
        "                   segment, instead of a random location in each segment.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 root_path: str,\n",
        "                 annotationfile_path: str,\n",
        "                 num_segments: int = 3,\n",
        "                 frames_per_segment: int = 1,\n",
        "                 imagefile_template: str='image_{:d}.png',\n",
        "                 transform = None,\n",
        "                 mask: bool =False,\n",
        "                 mask_template: str='mask.npy',\n",
        "                 test_mode: bool = False):\n",
        "        super(VideoFrameDataset, self).__init__()\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.annotationfile_path = annotationfile_path\n",
        "        self.num_segments = num_segments\n",
        "        self.frames_per_segment = frames_per_segment\n",
        "        self.imagefile_template = imagefile_template\n",
        "        self.transform = transform\n",
        "        self.mask = mask\n",
        "        self.mask_template = mask_template\n",
        "        self.test_mode = test_mode\n",
        "\n",
        "        self._parse_annotationfile()\n",
        "        self._sanity_check_samples()\n",
        "\n",
        "    def _load_image(self, directory: str, idx: int) -> Image.Image:\n",
        "        return Image.open(os.path.join(directory, self.imagefile_template.format(idx))).convert('RGB')\n",
        "    \n",
        "    def _load_mask(self, directory: str) -> torch.Tensor:\n",
        "        return torch.Tensor(np.load(os.path.join(directory, self.mask_template)))\n",
        "\n",
        "    def _parse_annotationfile(self):\n",
        "        self.video_list = [VideoRecord(x.strip().split(), self.root_path) for x in open(self.annotationfile_path)]\n",
        "\n",
        "    def _sanity_check_samples(self):\n",
        "        for record in self.video_list:\n",
        "            if record.num_frames <= 0 or record.start_frame == record.end_frame:\n",
        "                print(f\"\\nDataset Warning: video {record.path} seems to have zero RGB frames on disk!\\n\")\n",
        "\n",
        "            elif record.num_frames < (self.num_segments * self.frames_per_segment):\n",
        "                print(f\"\\nDataset Warning: video {record.path} has {record.num_frames} frames \"\n",
        "                      f\"but the dataloader is set up to load \"\n",
        "                      f\"(num_segments={self.num_segments})*(frames_per_segment={self.frames_per_segment})\"\n",
        "                      f\"={self.num_segments * self.frames_per_segment} frames. Dataloader will throw an \"\n",
        "                      f\"error when trying to load this video.\\n\")\n",
        "\n",
        "    def _get_start_indices(self, record: VideoRecord) -> 'np.ndarray[int]':\n",
        "        \"\"\"\n",
        "        For each segment, choose a start index from where frames\n",
        "        are to be loaded from.\n",
        "\n",
        "        Args:\n",
        "            record: VideoRecord denoting a video sample.\n",
        "        Returns:\n",
        "            List of indices of where the frames of each\n",
        "            segment are to be loaded from.\n",
        "        \"\"\"\n",
        "        # choose start indices that are perfectly evenly spread across the video frames.\n",
        "        if self.test_mode:\n",
        "            distance_between_indices = (record.num_frames - self.frames_per_segment + 1) / float(self.num_segments)\n",
        "\n",
        "            start_indices = np.array([int(distance_between_indices / 2.0 + distance_between_indices * x)\n",
        "                                      for x in range(self.num_segments)])\n",
        "        # randomly sample start indices that are approximately evenly spread across the video frames.\n",
        "        else:\n",
        "            max_valid_start_index = (record.num_frames - self.frames_per_segment + 1) // self.num_segments\n",
        "\n",
        "            start_indices = np.multiply(list(range(self.num_segments)), max_valid_start_index) + \\\n",
        "                      np.random.randint(max_valid_start_index, size=self.num_segments)\n",
        "\n",
        "        return start_indices\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Union[\n",
        "        Tuple[List[Image.Image], Union[int, List[int]]],\n",
        "        Tuple['torch.Tensor[num_frames, channels, height, width]', Union[int, List[int]]],\n",
        "        Tuple[Any, Union[int, List[int]]],\n",
        "        ]:\n",
        "        \"\"\"\n",
        "        For video with id idx, loads self.NUM_SEGMENTS * self.FRAMES_PER_SEGMENT\n",
        "        frames from evenly chosen locations across the video.\n",
        "\n",
        "        Args:\n",
        "            idx: Video sample index.\n",
        "        Returns:\n",
        "            A tuple of (video, label). Label is either a single\n",
        "            integer or a list of integers in the case of multiple labels.\n",
        "            Video is either 1) a list of PIL images if no transform is used\n",
        "            2) a batch of shape (NUM_IMAGES x CHANNELS x HEIGHT x WIDTH) in the range [0,1]\n",
        "            if the transform \"ImglistToTensor\" is used\n",
        "            3) or anything else if a custom transform is used.\n",
        "        \"\"\"\n",
        "        record: VideoRecord = self.video_list[idx]\n",
        "\n",
        "        frame_start_indices: 'np.ndarray[int]' = self._get_start_indices(record)\n",
        "\n",
        "        return self._get(record, frame_start_indices)\n",
        "\n",
        "    def _get(self, record: VideoRecord, frame_start_indices: 'np.ndarray[int]') -> Union[\n",
        "        Tuple[List[Image.Image], Union[int, List[int]]],\n",
        "        Tuple['torch.Tensor[num_frames, channels, height, width]', Union[int, List[int]]],\n",
        "        Tuple[Any, Union[int, List[int]]],\n",
        "        ]:\n",
        "        \"\"\"\n",
        "        Loads the frames of a video at the corresponding\n",
        "        indices.\n",
        "\n",
        "        Args:\n",
        "            record: VideoRecord denoting a video sample.\n",
        "            frame_start_indices: Indices from which to load consecutive frames from.\n",
        "        Returns:\n",
        "            A tuple of (video, label). Label is either a single\n",
        "            integer or a list of integers in the case of multiple labels.\n",
        "            Video is either 1) a list of PIL images if no transform is used\n",
        "            2) a batch of shape (NUM_IMAGES x CHANNELS x HEIGHT x WIDTH) in the range [0,1]\n",
        "            if the transform \"ImglistToTensor\" is used\n",
        "            3) or anything else if a custom transform is used.\n",
        "        \"\"\"\n",
        "\n",
        "        frame_start_indices = frame_start_indices + record.start_frame\n",
        "        images = list()\n",
        "\n",
        "        # from each start_index, load self.frames_per_segment\n",
        "        # consecutive frames\n",
        "        for start_index in frame_start_indices:\n",
        "            frame_index = int(start_index)\n",
        "\n",
        "            # load self.frames_per_segment consecutive frames\n",
        "            for _ in range(self.frames_per_segment):\n",
        "                image = self._load_image(record.path, frame_index)\n",
        "                images.append(image)\n",
        "\n",
        "                if frame_index < record.end_frame:\n",
        "                    frame_index += 1\n",
        "\n",
        "        if self.transform is not None:\n",
        "            images = self.transform(images)\n",
        "\n",
        "        if self.mask:\n",
        "            mask = self._load_mask(record.path)\n",
        "            return images, record.label, mask\n",
        "\n",
        "        return images, record.label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.video_list)\n",
        "\n",
        "class ImglistToTensor(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Converts a list of PIL images in the range [0,255] to a torch.FloatTensor\n",
        "    of shape (NUM_IMAGES x CHANNELS x HEIGHT x WIDTH) in the range [0,1].\n",
        "    Can be used as first transform for ``VideoFrameDataset``.\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def forward(img_list: List[Image.Image]) -> 'torch.Tensor[NUM_IMAGES, CHANNELS, HEIGHT, WIDTH]':\n",
        "        \"\"\"\n",
        "        Converts each PIL image in a list to\n",
        "        a torch Tensor and stacks them into\n",
        "        a single tensor.\n",
        "\n",
        "        Args:\n",
        "            img_list: list of PIL images.\n",
        "        Returns:\n",
        "            tensor of size ``NUM_IMAGES x CHANNELS x HEIGHT x WIDTH``\n",
        "        \"\"\"\n",
        "        return torch.stack([transforms.functional.to_tensor(pic) for pic in img_list])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "C_DC8vKZHZWO"
      },
      "outputs": [],
      "source": [
        "## IJEPA Model\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from einops import rearrange\n",
        "import numpy as np\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "\n",
        "\n",
        "def _no_grad_trunc_normal_(tensor, mean, std, a, b):\n",
        "    def norm_cdf(x):\n",
        "        # Computes standard normal cumulative distribution function\n",
        "        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n",
        "\n",
        "    if (mean < a - 2 * std) or (mean > b + 2 * std):\n",
        "        warnings.warn(\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"\n",
        "                      \"The distribution of values may be incorrect.\",\n",
        "                      stacklevel=2)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Values are generated by using a truncated uniform distribution and\n",
        "        # then using the inverse CDF for the normal distribution.\n",
        "        # Get upper and lower cdf values\n",
        "        l = norm_cdf((a - mean) / std)\n",
        "        u = norm_cdf((b - mean) / std)\n",
        "\n",
        "        # Uniformly fill tensor with values from [l, u], then translate to\n",
        "        # [2l-1, 2u-1].\n",
        "        tensor.uniform_(2 * l - 1, 2 * u - 1)\n",
        "\n",
        "        # Use inverse cdf transform for normal distribution to get truncated\n",
        "        # standard normal\n",
        "        tensor.erfinv_()\n",
        "\n",
        "        # Transform to proper mean, std\n",
        "        tensor.mul_(std * math.sqrt(2.))\n",
        "        tensor.add_(mean)\n",
        "\n",
        "        # Clamp to ensure it's in the proper range\n",
        "        tensor.clamp_(min=a, max=b)\n",
        "        return tensor\n",
        "\n",
        " \n",
        "def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n",
        "    # type: (Tensor, float, float, float, float) -> Tensor\n",
        "    r\"\"\"Fills the input Tensor with values drawn from a truncated\n",
        "    normal distribution. The values are effectively drawn from the\n",
        "    normal distribution :math:`\\mathcal{N}(\\text{mean}, \\text{std}^2)`\n",
        "    with values outside :math:`[a, b]` redrawn until they are within\n",
        "    the bounds. The method used for generating the random values works\n",
        "    best when :math:`a \\leq \\text{mean} \\leq b`.\n",
        "    Args:\n",
        "        tensor: an n-dimensional `torch.Tensor`\n",
        "        mean: the mean of the normal distribution\n",
        "        std: the standard deviation of the normal distribution\n",
        "        a: the minimum cutoff value\n",
        "        b: the maximum cutoff value\n",
        "    Examples:\n",
        "        >>> w = torch.empty(3, 5)\n",
        "        >>> nn.init.trunc_normal_(w)\n",
        "    \"\"\"\n",
        "    return _no_grad_trunc_normal_(tensor, mean, std, a, b)\n",
        "\n",
        "\n",
        "def drop_path(x, drop_prob: float = 0., training: bool = False):\n",
        "    \"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n",
        "    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n",
        "    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n",
        "    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n",
        "    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n",
        "    'survival rate' as the argument.\n",
        "    \"\"\"\n",
        "    if drop_prob == 0. or not training:\n",
        "        return x\n",
        "    keep_prob = 1 - drop_prob\n",
        "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
        "    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
        "    random_tensor.floor_()  # binarize\n",
        "    output = x.div(keep_prob) * random_tensor\n",
        "    return output\n",
        "\n",
        "class EarlyStop:\n",
        "    def __init__(self, patience, loss=False):\n",
        "        self.patience = patience\n",
        "        self.best_value = np.inf if loss else 0\n",
        "        self.best_epoch = 0\n",
        "        self.loss = loss\n",
        "\n",
        "    def step(self, current_value, current_epoch):\n",
        "        print(\"Current:{} Best:{}\".format(current_value, self.best_value))\n",
        "        if self.loss:\n",
        "            if current_value < self.best_value:\n",
        "                self.best_value = current_value\n",
        "                self.best_epoch = current_epoch\n",
        "        else:\n",
        "            if current_value > self.best_value:\n",
        "                self.best_value = current_value\n",
        "                self.best_epoch = current_epoch\n",
        "\n",
        "    def stop_training(self, current_epoch) -> bool:\n",
        "        return current_epoch - self.best_epoch > self.patience\n",
        "\n",
        "\n",
        "class CustomDataParallel(nn.DataParallel):\n",
        "    \"\"\"\n",
        "    Wrapper for scoring with nn.DataParallel object containing LTRModel.\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.module.forward(x)  # type: ignore\n",
        "\n",
        "\n",
        "class DropPath(nn.Module):\n",
        "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
        "    \"\"\"\n",
        "    def __init__(self, drop_prob=None):\n",
        "        super(DropPath, self).__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def forward(self, x):\n",
        "        return drop_path(x, self.drop_prob, self.training)\n",
        "\n",
        "\n",
        "class PatchEmbed(nn.Module):\n",
        "    \"\"\" Image to Patch Embedding\n",
        "    \"\"\"\n",
        "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
        "        super().__init__()\n",
        "        img_size = img_size, img_size\n",
        "        patch_size = patch_size, patch_size\n",
        "        num_patches = (img_size[1] // patch_size[1]) * (img_size[0] // patch_size[0])\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = num_patches\n",
        "\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, T, H, W = x.shape\n",
        "        x = rearrange(x, 'b c t h w -> (b t) c h w')\n",
        "        x = self.proj(x)\n",
        "        W = x.size(-1)\n",
        "        x = x.flatten(2).transpose(1, 2)\n",
        "        return x, T, W\n",
        "\n",
        "class Mlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = act_layer()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0., with_qkv=True):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "        self.with_qkv = with_qkv\n",
        "        if self.with_qkv:\n",
        "           self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "           self.proj = nn.Linear(dim, dim)\n",
        "           self.proj_drop = nn.Dropout(proj_drop)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        if self.with_qkv:\n",
        "           qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "           q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        else:\n",
        "           qkv = x.reshape(B, N, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)\n",
        "           q, k, v  = qkv, qkv, qkv\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        if self.with_qkv:\n",
        "           x = self.proj(x)\n",
        "           x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
        "                 drop_path=0.1, act_layer=nn.GELU, norm_layer=nn.LayerNorm, attention_type='divided_space_time'):\n",
        "        super().__init__()\n",
        "        self.attention_type = attention_type\n",
        "        assert(attention_type in ['divided_space_time', 'space_only','joint_space_time'])\n",
        "\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.attn = Attention(\n",
        "           dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
        "\n",
        "        ## Temporal Attention Parameters\n",
        "        if self.attention_type == 'divided_space_time':\n",
        "            self.temporal_norm1 = norm_layer(dim)\n",
        "            self.temporal_attn = Attention(\n",
        "              dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
        "            self.temporal_fc = nn.Linear(dim, dim)\n",
        "\n",
        "        ## drop path\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
        "\n",
        "\n",
        "    def forward(self, x, B, T, W):\n",
        "        num_spatial_tokens = (x.size(1) - 1) // T\n",
        "        H = num_spatial_tokens // W\n",
        "\n",
        "        if self.attention_type in ['space_only', 'joint_space_time']:\n",
        "            x = x + self.drop_path(self.attn(self.norm1(x)))\n",
        "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
        "            return x\n",
        "        elif self.attention_type == 'divided_space_time':\n",
        "            ## Temporal\n",
        "            xt = x # xt = x[:,1:,:]\n",
        "            xt = rearrange(xt, 'b (h w t) m -> (b h w) t m',b=B,w=W,t=T)\n",
        "            res_temporal = self.drop_path(self.temporal_attn(self.temporal_norm1(xt)))\n",
        "            res_temporal = rearrange(res_temporal, '(b h w) t m -> b (h w t) m',b=B,w=W,t=T)\n",
        "            res_temporal = self.temporal_fc(res_temporal)\n",
        "            xt = x + res_temporal # xt = x[:,1:,:] + res_temporal\n",
        "\n",
        "            ## Spatial\n",
        "            # init_cls_token = x[:,0,:].unsqueeze(1)\n",
        "            # cls_token = init_cls_token.repeat(1, T, 1)\n",
        "            # cls_token = rearrange(cls_token, 'b t m -> (b t) m',b=B,t=T).unsqueeze(1)\n",
        "            xs = xt\n",
        "            xs = rearrange(xs, 'b (h w t) m -> (b t) (h w) m',b=B,w=W,t=T)\n",
        "            # xs = torch.cat((cls_token, xs), 1)\n",
        "            res_spatial = self.drop_path(self.attn(self.norm1(xs)))\n",
        "\n",
        "            ### Taking care of CLS token\n",
        "            # cls_token = res_spatial[:,0,:]\n",
        "            # cls_token = rearrange(cls_token, '(b t) m -> b t m',b=B,t=T)\n",
        "            # cls_token = torch.mean(cls_token,1,True) ## averaging for every frame\n",
        "            # res_spatial = res_spatial[:,1:,:]\n",
        "            res_spatial = rearrange(res_spatial, '(b t) (h w) m -> b (h w t) m',b=B,w=W,t=T)\n",
        "            res = res_spatial\n",
        "            x = xt\n",
        "\n",
        "            ## Mlp\n",
        "            x = x + res # x = torch.cat((init_cls_token, x), 1) + torch.cat((cls_token, res), 1)\n",
        "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
        "            return x\n",
        "\n",
        "\n",
        "class VisionTransformer(nn.Module):\n",
        "    \"\"\" Vision Transformer\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                embed_dim=768,\n",
        "                depth=12,\n",
        "                num_heads=12,\n",
        "                mlp_ratio=4.,\n",
        "                qkv_bias=False,\n",
        "                qk_scale=None,\n",
        "                drop_rate=0.,\n",
        "                attn_drop_rate=0.,\n",
        "                drop_path_rate=0.1,\n",
        "                norm_layer=nn.LayerNorm,\n",
        "                attention_type='divided_space_time',\n",
        "                dropout=0.):\n",
        "        super().__init__()\n",
        "        self.attention_type = attention_type\n",
        "        self.depth = depth\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.num_features = self.embed_dim = embed_dim\n",
        "\n",
        "        ## Attention Blocks\n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, self.depth)]  # stochastic depth decay rule\n",
        "        self.blocks = nn.ModuleList([\n",
        "            Block(\n",
        "                dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
        "                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=norm_layer, attention_type=self.attention_type)\n",
        "            for i in range(self.depth)])\n",
        "        self.norm = norm_layer(embed_dim)\n",
        "\n",
        "        ## initialization of temporal attention weights\n",
        "        if self.attention_type == 'divided_space_time':\n",
        "            i = 0\n",
        "            for m in self.blocks.modules():\n",
        "                m_str = str(m)\n",
        "                if 'Block' in m_str:\n",
        "                    if i > 0:\n",
        "                      nn.init.constant_(m.temporal_fc.weight, 0)\n",
        "                      nn.init.constant_(m.temporal_fc.bias, 0)\n",
        "                    i += 1\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            trunc_normal_(m.weight, std=.02)\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "\n",
        "    def forward(self, x, B, T, W):\n",
        "\n",
        "        ## Attention blocks\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x, B, T, W)\n",
        "\n",
        "        ### Predictions for space-only baseline\n",
        "        if self.attention_type == 'space_only':\n",
        "            x = rearrange(x, '(b t) n m -> b t n m',b=B,t=T)\n",
        "            x = torch.mean(x, 1) # averaging predictions for every frame\n",
        "\n",
        "        x = self.norm(x)\n",
        "        x = rearrange(x, 'b (h w t) m -> b t (h w) m',b=B,t=T,w=W)\n",
        "        return x\n",
        "\n",
        "\n",
        "class IJEPA_base(nn.Module):\n",
        "    def __init__(self,\n",
        "                img_size=224,\n",
        "                patch_size=16,\n",
        "                in_chans=3,\n",
        "                norm_layer=nn.LayerNorm,\n",
        "                num_frames=22,\n",
        "                attention_type='divided_space_time',\n",
        "                dropout=0.,\n",
        "                mode=\"train\",\n",
        "                M=4,\n",
        "                embed_dim=768,\n",
        "                device='cuda',\n",
        "                # encoder parameters\n",
        "                enc_depth=12,\n",
        "                enc_num_heads=12,\n",
        "                enc_mlp_ratio=4.,\n",
        "                enc_qkv_bias=False,\n",
        "                enc_qk_scale=None,\n",
        "                enc_drop_rate=0.,\n",
        "                enc_attn_drop_rate=0.,\n",
        "                enc_drop_path_rate=0.1,\n",
        "                # predictor parameters\n",
        "                pred_depth=12,\n",
        "                pred_num_heads=12,\n",
        "                pred_mlp_ratio=4.,\n",
        "                pred_qkv_bias=False,\n",
        "                pred_qk_scale=None,\n",
        "                pred_drop_rate=0.,\n",
        "                pred_attn_drop_rate=0.,\n",
        "                pred_drop_path_rate=0.1,\n",
        "                # positional and spacial embedding parameters\n",
        "                pos_drop_rate=0.,\n",
        "                time_drop_rate=0.):\n",
        "        super().__init__()\n",
        "        self.mode = mode\n",
        "        self.dropout = dropout\n",
        "        self.mask_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
        "        nn.init.trunc_normal_(self.mask_token, 0.02)\n",
        "        self.M = M # number of masked frames\n",
        "\n",
        "        self.norm_layer = norm_layer\n",
        "        self.norm = norm_layer(embed_dim)\n",
        "\n",
        "        self.attention_type = attention_type\n",
        "\n",
        "        self.patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
        "        num_patches = self.patch_embed.num_patches\n",
        "        \n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim)) # self.pos_embed = nn.Parameter(torch.zeros(1, num_patches+1, embed_dim))\n",
        "        self.pos_drop = nn.Dropout(p=pos_drop_rate)\n",
        "\n",
        "        if self.attention_type != 'space_only':\n",
        "            self.time_embed = nn.Parameter(torch.zeros(1, num_frames, embed_dim))\n",
        "            self.time_drop = nn.Dropout(p=time_drop_rate)\n",
        "\n",
        "        self.teacher_encoder = VisionTransformer(\n",
        "            embed_dim=embed_dim,\n",
        "            num_heads=enc_num_heads,\n",
        "            depth=enc_depth, \n",
        "            dropout=self.dropout,\n",
        "            norm_layer=self.norm_layer,\n",
        "            mlp_ratio=enc_mlp_ratio,\n",
        "            attention_type=attention_type,\n",
        "            qkv_bias=enc_qkv_bias,\n",
        "            qk_scale=enc_qk_scale,\n",
        "            drop_rate=enc_drop_rate,\n",
        "            attn_drop_rate=enc_attn_drop_rate,\n",
        "            drop_path_rate=enc_drop_path_rate\n",
        "        )\n",
        "\n",
        "        self.student_encoder = copy.deepcopy(self.teacher_encoder)\n",
        "        self.predictor = VisionTransformer(\n",
        "            embed_dim=embed_dim,\n",
        "            num_heads=pred_num_heads,\n",
        "            depth=pred_depth, \n",
        "            dropout=self.dropout,\n",
        "            norm_layer=self.norm_layer,\n",
        "            mlp_ratio=pred_mlp_ratio,\n",
        "            attention_type=attention_type,\n",
        "            qkv_bias=pred_qkv_bias,\n",
        "            qk_scale=pred_qk_scale,\n",
        "            drop_rate=pred_drop_rate,\n",
        "            attn_drop_rate=pred_attn_drop_rate,\n",
        "            drop_path_rate=pred_drop_path_rate\n",
        "        )\n",
        "        \n",
        "\n",
        "    @torch.no_grad() \n",
        "    ### get the target block\n",
        "    def get_target_block(self, target_encoder, x, B, T, W):  \n",
        "        #get the target block\n",
        "        target_encoder = target_encoder.eval()\n",
        "        x = target_encoder(x, B, T, W) # input in format 'b (t h w) m',output in format 'b t (h w) m' (batch frames n_patches embed_dim)\n",
        "        x = self.norm(x)\n",
        "\n",
        "        #randomly select M frames to mask in x\n",
        "        mask_indices = (torch.randperm(11)+11)[:self.M]\n",
        "        \n",
        "        #mask the selected frames in the context block\n",
        "        target_block = x[:,mask_indices] #get 4 random frames from the last 11 frames\n",
        "        #all_patches = x\n",
        "        return target_block, mask_indices\n",
        "\n",
        "    ### get the context block\n",
        "    def get_context_block(self, x, B, T, W, mask_indices):\n",
        "      #reshape x to format 'b t (h w) m'\n",
        "      x = rearrange(x, 'b (t h w) m -> b t (h w) m',b=B,t=T,w=W)\n",
        "      #select all frames which are not masked\n",
        "      index = torch.ones(x.shape[1], dtype=bool)\n",
        "      index[mask_indices] = False\n",
        "      context_block = x[:,index]\n",
        "      context_block = rearrange(context_block, 'b t (h w) m -> b (t h w) m',b=B,t=(T-self.M),w=W)\n",
        "      return context_block\n",
        "    \n",
        "    def get_patch_embeddings(self, x):\n",
        "        B = x.shape[0]\n",
        "        x, T, W = self.patch_embed(x)\n",
        "        x = x + self.pos_embed\n",
        "        x = self.pos_drop(x)\n",
        "\n",
        "        if self.attention_type != 'space_only':\n",
        "            x = rearrange(x, '(b t) n m -> (b n) t m',b=B,t=T)\n",
        "            if T != self.time_embed.size(1):\n",
        "                time_embed = self.time_embed.transpose(1, 2)\n",
        "                new_time_embed = F.interpolate(time_embed, size=(T), mode='nearest')\n",
        "                new_time_embed = new_time_embed.transpose(1, 2)\n",
        "                x = x + new_time_embed\n",
        "            else:\n",
        "                x = x + self.time_embed\n",
        "            x = self.time_drop(x)\n",
        "            x = rearrange(x, '(b n) t m -> b (n t) m',b=B,t=T)\n",
        "            \n",
        "        return x, B, T, W\n",
        "    \n",
        "    def forward(self, x):\n",
        "        #get the patch embeddings\n",
        "        x, B, T, W = self.get_patch_embeddings(x)\n",
        "\n",
        "        #if mode is test, we get return full embedding:\n",
        "        if self.mode == 'test':\n",
        "            encoding = self.student_encoder(x, B, T, W) # input in format 'b (t h w) m',output in format 'b t (h w) m' (batch frames n_patches embed_dim)\n",
        "            encoding = self.norm(encoding)\n",
        "            n = encoding.shape[2]\n",
        "            encoding = rearrange(encoding, 'b t (h w) m -> b (t h w) m',b=B,t=T,w=W)\n",
        "            #add 11 mask tokens to the end of the embedding\n",
        "            target_masks = self.mask_token.repeat(B, 11, n, 1)\n",
        "            target_pos_embedding = self.pos_embed.unsqueeze(1)\n",
        "            target_masks = target_masks + target_pos_embedding\n",
        "            \n",
        "            # Add time embedding\n",
        "            target_time_embed = self.time_embed.unsqueeze(2)[:,11:]\n",
        "            target_masks = target_masks + target_time_embed\n",
        "            \n",
        "            target_masks = rearrange(target_masks, 'b t (h w) m -> b (t h w) m',b=B,t=11,w=W)\n",
        "            encoding = torch.cat((encoding, target_masks), dim=1)\n",
        "            return self.predictor(encoding, B, T+11, W) # predict the masked frames\n",
        "        \n",
        "        # #get target embeddings\n",
        "        # input in format 'b (t h w) m', output in format (1) 'b 11 (h w) m' and (2) 'b t (h w) m'\n",
        "        target_blocks, mask_indices = self.get_target_block(self.teacher_encoder,x,B,T,W)\n",
        "\n",
        "        #get context embeddings\n",
        "        context_block = self.get_context_block(x, B, T, W, mask_indices)\n",
        "\n",
        "        context_encoding = self.student_encoder(context_block, B, T-self.M, W)\n",
        "        context_encoding = self.norm(context_encoding)\n",
        "        context_encoding = rearrange(context_encoding, 'b t (h w) m -> b (t h w) m',b=B,t=T-self.M,w=W)\n",
        "\n",
        "        #n = h x w\n",
        "        n = target_blocks.shape[2]\n",
        "        target_masks = self.mask_token.repeat(B, self.M, n, 1)\n",
        "        target_pos_embedding = self.pos_embed.unsqueeze(1)\n",
        "        target_masks = target_masks + target_pos_embedding\n",
        "        \n",
        "        # Add time embedding\n",
        "        target_time_embed = self.time_embed.unsqueeze(2)[:,mask_indices]\n",
        "        target_masks = target_masks + target_time_embed\n",
        "        \n",
        "        target_masks = rearrange(target_masks, 'b t (h w) m -> b (t h w) m',b=B,t=self.M,w=W)\n",
        "        prediction_cat = torch.cat((context_encoding, target_masks), dim = 1)\n",
        "        # make sure that the preds are actually at the end\n",
        "        prediction_blocks = self.predictor(prediction_cat,B, T, W)\n",
        "\n",
        "        prediction_blocks = prediction_blocks[:,-4:]\n",
        "        return prediction_blocks, target_blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t6lZSMqGH__",
        "outputId": "9e4d6030-8ec0-4097-a504-e19e835b3f91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### Load the encoder\n",
        "encoder = IJEPA_base(img_size=128, patch_size=8, in_chans=3, norm_layer=nn.LayerNorm, num_frames=22, attention_type='divided_space_time', dropout=0.1, mode=\"test\", M=4, embed_dim=384,\n",
        "                      # encoder parameters\n",
        "                      enc_depth=10,\n",
        "                      enc_num_heads=6,\n",
        "                      enc_mlp_ratio=4.,\n",
        "                      enc_qkv_bias=False,\n",
        "                      enc_qk_scale=None,\n",
        "                      enc_drop_rate=0.,\n",
        "                      enc_attn_drop_rate=0.,\n",
        "                      enc_drop_path_rate=0.1,\n",
        "                      # predictor parameters\n",
        "                      pred_depth=10,\n",
        "                      pred_num_heads=6,\n",
        "                      pred_mlp_ratio=4.,\n",
        "                      pred_qkv_bias=False,\n",
        "                      pred_qk_scale=None,\n",
        "                      pred_drop_rate=0.1,\n",
        "                      pred_attn_drop_rate=0.1,\n",
        "                      pred_drop_path_rate=0.1,\n",
        "                      # positional and spacial embedding parameters\n",
        "                      pos_drop_rate=0.1,\n",
        "                      time_drop_rate=0.1)\n",
        "# Leave this to load properly the optimizer dict\n",
        "encoder.to(device)\n",
        "\n",
        "encoder_saved_data = torch.load(\"best_model.pkl\", map_location=device)\n",
        "encoder.load_state_dict(encoder_saved_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ScDgiRHfIqWr"
      },
      "outputs": [],
      "source": [
        "### DECODER\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from einops import rearrange\n",
        "import numpy as np\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerDecoder, TransformerDecoderLayer\n",
        "from typing import Optional\n",
        "import math\n",
        "from functools import partial\n",
        "\n",
        "def trunc_normal_init(module: nn.Module,\n",
        "                      mean: float = 0,\n",
        "                      std: float = 1,\n",
        "                      a: float = -2,\n",
        "                      b: float = 2,\n",
        "                      bias: float = 0) -> None:\n",
        "    if hasattr(module, 'weight') and module.weight is not None:\n",
        "        trunc_normal_(module.weight, mean, std, a, b)  # type: ignore\n",
        "    if hasattr(module, 'bias') and module.bias is not None:\n",
        "        nn.init.constant_(module.bias, bias)  # type: ignore\n",
        "\n",
        "def constant_init(module, val, bias=0):\n",
        "    if hasattr(module, 'weight') and module.weight is not None:\n",
        "        nn.init.constant_(module.weight, val)\n",
        "    if hasattr(module, 'bias') and module.bias is not None:\n",
        "        nn.init.constant_(module.bias, bias)\n",
        "\n",
        "class TPN_Decoder(TransformerDecoder):\n",
        "    def forward(self, tgt: Tensor, memory: Tensor, tgt_mask: Optional[Tensor] = None,\n",
        "                memory_mask: Optional[Tensor] = None, tgt_key_padding_mask: Optional[Tensor] = None,\n",
        "                memory_key_padding_mask: Optional[Tensor] = None):\n",
        "        output = tgt\n",
        "        # attns = []\n",
        "        # for mod in self.layers:\n",
        "        #     output, attn = mod(output, memory, tgt_mask=tgt_mask,\n",
        "        #                  memory_mask=memory_mask,\n",
        "        #                  tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "        #                  memory_key_padding_mask=memory_key_padding_mask)\n",
        "            # attns.append(attn)\n",
        "\n",
        "        output, attn = self.layers[0](output, memory, tgt_mask=tgt_mask,\n",
        "                          memory_mask=memory_mask,\n",
        "                          tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                          memory_key_padding_mask=memory_key_padding_mask)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            output = self.norm(output)\n",
        "\n",
        "        return output, attn\n",
        "\n",
        "class TPN_DecoderLayer(TransformerDecoderLayer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(TPN_DecoderLayer, self).__init__(**kwargs)\n",
        "        del self.multihead_attn\n",
        "        self.multihead_attn = Attention(\n",
        "            kwargs['d_model'], num_heads=kwargs['nhead'], qkv_bias=True, attn_drop=0.1)\n",
        "\n",
        "    def forward(self, tgt: Tensor, memory: Tensor, tgt_mask: Optional[Tensor] = None,\n",
        "                memory_mask: Optional[Tensor] = None,\n",
        "                tgt_key_padding_mask: Optional[Tensor] = None,\n",
        "                memory_key_padding_mask: Optional[Tensor] = None) -> Tensor:\n",
        "        tgt2 = self.self_attn(tgt, tgt, tgt, attn_mask=tgt_mask,\n",
        "                              key_padding_mask=tgt_key_padding_mask)[0]\n",
        "        tgt = tgt + self.dropout1(tgt2)\n",
        "        tgt = self.norm1(tgt)\n",
        "        tgt2, attn2 = self.multihead_attn(\n",
        "            tgt.transpose(0, 1), memory.transpose(0, 1), memory.transpose(0, 1))\n",
        "        tgt = tgt + self.dropout2(tgt2)\n",
        "        tgt = self.norm2(tgt)\n",
        "        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n",
        "        tgt = tgt + self.dropout3(tgt2)\n",
        "        tgt = self.norm3(tgt)\n",
        "        return tgt, attn2\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        # NOTE scale factor was wrong in my original version, can set manually to be compat with prev weights\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "\n",
        "        self.q = nn.Linear(dim, dim, bias=qkv_bias)\n",
        "        self.k = nn.Linear(dim, dim, bias=qkv_bias)\n",
        "        self.v = nn.Linear(dim, dim, bias=qkv_bias)\n",
        "\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "    def forward(self, xq, xk, xv):\n",
        "        B, Nq, C = xq.size()\n",
        "        Nk = xk.size()[1]\n",
        "        Nv = xv.size()[1]\n",
        "\n",
        "        q = self.q(xq).reshape(B, Nq, self.num_heads,\n",
        "                                      C // self.num_heads).permute(0, 2, 1, 3)\n",
        "        k = self.k(xk).reshape(B, Nk, self.num_heads,\n",
        "                                      C // self.num_heads).permute(0, 2, 1, 3)\n",
        "        v = self.v(xv).reshape(B, Nv, self.num_heads,\n",
        "                                      C // self.num_heads).permute(0, 2, 1, 3)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn_save = attn.clone()\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, Nq, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x.transpose(0, 1), attn_save.sum(dim=1) / self.num_heads\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"Very simple multi-layer perceptron (also called FFN)\"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        h = [hidden_dim] * (num_layers - 1)\n",
        "        self.layers = nn.ModuleList(\n",
        "            nn.Linear(n, k) for n, k in zip([input_dim] + h, h + [output_dim])\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            x = F.relu(layer(x)) if i < self.num_layers - 1 else layer(x)\n",
        "        return x\n",
        "    \n",
        "\n",
        "def accuracy(pred, target, topk=1, thresh=None, ignore_index=None):\n",
        "    \"\"\"Calculate accuracy according to the prediction and target.\n",
        "    Args:\n",
        "        pred (torch.Tensor): The model prediction, shape (N, num_class, ...)\n",
        "        target (torch.Tensor): The target of each prediction, shape (N, , ...)\n",
        "        ignore_index (int | None): The label index to be ignored. Default: None\n",
        "        topk (int | tuple[int], optional): If the predictions in ``topk``\n",
        "            matches the target, the predictions will be regarded as\n",
        "            correct ones. Defaults to 1.\n",
        "        thresh (float, optional): If not None, predictions with scores under\n",
        "            this threshold are considered incorrect. Default to None.\n",
        "    Returns:\n",
        "        float | tuple[float]: If the input ``topk`` is a single integer,\n",
        "            the function will return a single float as accuracy. If\n",
        "            ``topk`` is a tuple containing multiple integers, the\n",
        "            function will return a tuple containing accuracies of\n",
        "            each ``topk`` number.\n",
        "    \"\"\"\n",
        "    assert isinstance(topk, (int, tuple))\n",
        "    if isinstance(topk, int):\n",
        "        topk = (topk, )\n",
        "        return_single = True\n",
        "    else:\n",
        "        return_single = False\n",
        "\n",
        "    maxk = max(topk)\n",
        "    if pred.size(0) == 0:\n",
        "        accu = [pred.new_tensor(0.) for i in range(len(topk))]\n",
        "        return accu[0] if return_single else accu\n",
        "    assert pred.ndim == target.ndim + 1\n",
        "    assert pred.size(0) == target.size(0)\n",
        "    assert maxk <= pred.size(1), \\\n",
        "        f'maxk {maxk} exceeds pred dimension {pred.size(1)}'\n",
        "    pred_value, pred_label = pred.topk(maxk, dim=1)\n",
        "    # transpose to shape (maxk, N, ...)\n",
        "    pred_label = pred_label.transpose(0, 1)\n",
        "    correct = pred_label.eq(target.unsqueeze(0).expand_as(pred_label))\n",
        "    if thresh is not None:\n",
        "        # Only prediction values larger than thresh are counted as correct\n",
        "        correct = correct & (pred_value > thresh).t()\n",
        "    if ignore_index is not None:\n",
        "        correct = correct[:, target != ignore_index]\n",
        "    res = []\n",
        "    eps = torch.finfo(torch.float32).eps\n",
        "    for k in topk:\n",
        "        # Avoid causing ZeroDivisionError when all pixels\n",
        "        # of an image are ignored\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True) + eps\n",
        "        if ignore_index is not None:\n",
        "            total_num = target[target != ignore_index].numel() + eps\n",
        "        else:\n",
        "            total_num = target.numel() + eps\n",
        "        res.append(correct_k.mul_(100.0 / total_num))\n",
        "    return res[0] if return_single else res\n",
        "\n",
        "class ATMHead(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            img_size,\n",
        "            H,\n",
        "            W,\n",
        "            in_channels,\n",
        "            embed_dims=768,\n",
        "            num_layers=3,\n",
        "            num_heads=8,\n",
        "            use_stages=3,\n",
        "            use_proj=True,\n",
        "            CE_loss=False,\n",
        "            crop_train=False,\n",
        "            #shrink_ratio=None,\n",
        "            #**kwargs,\n",
        "\n",
        "            num_classes=48\n",
        "    ):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        # super(ATMHead, self).__init__()\n",
        "         #   in_channels=in_channels, **kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.image_size = img_size\n",
        "        self.H = H\n",
        "        self.W = W\n",
        "\n",
        "        self.use_stages = use_stages\n",
        "        self.crop_train = crop_train\n",
        "        nhead = num_heads\n",
        "        dim = embed_dims\n",
        "        input_proj = []\n",
        "        proj_norm = []\n",
        "        atm_decoders = []\n",
        "        for i in range(self.use_stages):\n",
        "            # FC layer to change ch\n",
        "            if use_proj:\n",
        "                proj = nn.Linear(self.in_channels, dim)\n",
        "                trunc_normal_(proj.weight, std=.02)\n",
        "            else:\n",
        "                proj = nn.Identity()\n",
        "            self.add_module(\"input_proj_{}\".format(i + 1), proj)\n",
        "            input_proj.append(proj)\n",
        "            # norm layer\n",
        "            if use_proj:\n",
        "                norm = nn.LayerNorm(dim)\n",
        "            else:\n",
        "                norm = nn.Identity()\n",
        "            self.add_module(\"proj_norm_{}\".format(i + 1), norm)\n",
        "            proj_norm.append(norm)\n",
        "            # decoder layer\n",
        "            decoder_layer = TPN_DecoderLayer(d_model=dim, nhead=nhead, dim_feedforward=dim * 4)\n",
        "            decoder = TPN_Decoder(decoder_layer, num_layers)\n",
        "            self.add_module(\"decoder_{}\".format(i + 1), decoder)\n",
        "            atm_decoders.append(decoder)\n",
        "\n",
        "        self.input_proj = input_proj\n",
        "        self.proj_norm = proj_norm\n",
        "        self.decoder = atm_decoders\n",
        "        self.q = nn.Embedding(self.num_classes + 1, dim) # nn.Embedding(self.num_classes, dim)\n",
        "\n",
        "        self.class_embed = nn.Linear(dim, self.num_classes + 1)\n",
        "        self.CE_loss = CE_loss\n",
        "        # delattr(self, 'conv_seg')\n",
        "\n",
        "    def init_weights(self):\n",
        "        for n, m in self.named_modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                trunc_normal_init(m, std=.02, bias=0)\n",
        "            elif isinstance(m, nn.LayerNorm):\n",
        "                constant_init(m, val=1.0, bias=0.0)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = []\n",
        "        # for stage_ in inputs[:self.use_stages]:\n",
        "        #     x.append(self.d4_to_d3(stage_) if stage_.dim() > 3 else stage_)\n",
        "\n",
        "        x.append(self.d4_to_d3(inputs) if inputs.dim() > 3 else inputs)\n",
        "\n",
        "        x.reverse()\n",
        "        bs = x[0].size()[0]\n",
        "\n",
        "        laterals = []\n",
        "        attns = []\n",
        "        maps_size = []\n",
        "        qs = []\n",
        "        q = self.q.weight.repeat(bs, 1, 1).transpose(0, 1)\n",
        "\n",
        "        for idx, (x_, proj_, norm_, decoder_) in enumerate(zip(x, self.input_proj, self.proj_norm, self.decoder)):\n",
        "            lateral = norm_(proj_(x_))\n",
        "            # if idx == 0:\n",
        "            if True:\n",
        "                laterals.append(lateral)\n",
        "            else:\n",
        "                if laterals[idx - 1].size()[1] == lateral.size()[1]:\n",
        "                    laterals.append(lateral + laterals[idx - 1])\n",
        "                else:\n",
        "                    # nearest interpolate\n",
        "                    l_ = self.d3_to_d4(laterals[idx - 1])\n",
        "                    l_ = F.interpolate(l_, scale_factor=2, mode=\"nearest\")\n",
        "                    l_ = self.d4_to_d3(l_)\n",
        "                    laterals.append(l_ + lateral)\n",
        "\n",
        "            #print(q.shape)\n",
        "            #print(lateral.shape)\n",
        "            \n",
        "            q, attn = decoder_(q, lateral.transpose(0, 1))\n",
        "            attn = attn.transpose(-1, -2)\n",
        "            if self.crop_train and self.training:\n",
        "                blank_attn = torch.zeros_like(attn)\n",
        "                blank_attn = blank_attn[:, 0].unsqueeze(1).repeat(1, (self.image_size//16)**2, 1)\n",
        "                blank_attn[:, inputs[-1]] = attn\n",
        "                attn = blank_attn\n",
        "                self.crop_idx = inputs[-1]\n",
        "            attn = self.d3_to_d4(attn)\n",
        "            maps_size.append(attn.size()[-2:])\n",
        "            qs.append(q.transpose(0, 1))\n",
        "            attns.append(attn)\n",
        "        qs = torch.stack(qs, dim=0)\n",
        "        outputs_class = self.class_embed(qs)\n",
        "        out = {\"pred_logits\": outputs_class[-1]}\n",
        "\n",
        "        outputs_seg_masks = []\n",
        "        size = maps_size[-1]\n",
        "\n",
        "        for i_attn, attn in enumerate(attns):\n",
        "            if i_attn == 0:\n",
        "                outputs_seg_masks.append(F.interpolate(attn, size=size, mode='bilinear', align_corners=False))\n",
        "            else:\n",
        "                outputs_seg_masks.append(outputs_seg_masks[i_attn - 1] +\n",
        "                                         F.interpolate(attn, size=size, mode='bilinear', align_corners=False))\n",
        "\n",
        "        out[\"pred_masks\"] = F.interpolate(outputs_seg_masks[-1],\n",
        "                                          #size=(self.image_size, self.image_size),\n",
        "                                          size=(self.H, self.W),\n",
        "                                          mode='bilinear', align_corners=False)\n",
        "\n",
        "        out[\"pred\"] = self.semantic_inference(out[\"pred_logits\"], out[\"pred_masks\"])\n",
        "\n",
        "        if self.training:\n",
        "            # [l, bs, queries, embed]\n",
        "            outputs_seg_masks = torch.stack(outputs_seg_masks, dim=0)\n",
        "            out[\"aux_outputs\"] = self._set_aux_loss(\n",
        "                outputs_class, outputs_seg_masks\n",
        "            )\n",
        "        else:\n",
        "            return out[\"pred\"]\n",
        "\n",
        "        return out\n",
        "\n",
        "    @torch.jit.unused\n",
        "    def _set_aux_loss(self, outputs_class, outputs_seg_masks):\n",
        "        # this is a workaround to make torchscript happy, as torchscript\n",
        "        # doesn't support dictionary with non-homogeneous values, such\n",
        "        # as a dict having both a Tensor and a list.\n",
        "        return [\n",
        "            {\"pred_logits\": a, \"pred_masks\": b}\n",
        "            for a, b in zip(outputs_class[:-1], outputs_seg_masks[:-1])\n",
        "        ]\n",
        "\n",
        "    def semantic_inference(self, mask_cls, mask_pred):\n",
        "        mask_cls = F.softmax(mask_cls, dim=-1)[..., :-1]\n",
        "        mask_pred = mask_pred.sigmoid()\n",
        "        semseg = torch.einsum(\"bqc,bqhw->bchw\", mask_cls, mask_pred)\n",
        "        return semseg\n",
        "\n",
        "    def d3_to_d4(self, t):\n",
        "        n, hw, c = t.size()\n",
        "        if hw % 2 != 0:\n",
        "            t = t[:, 1:]\n",
        "        h = w = int(math.sqrt(hw))\n",
        "        return t.transpose(1, 2).reshape(n, c, h, w)\n",
        "\n",
        "    def d4_to_d3(self, t):\n",
        "        return t.flatten(-2).transpose(-1, -2)\n",
        "\n",
        "    # @force_fp32(apply_to=('seg_logit',))\n",
        "    def losses(self, seg_logit, seg_label):\n",
        "        \"\"\"Compute segmentation loss.\"\"\"\n",
        "        if self.CE_loss:\n",
        "            return super().losses(seg_logit[\"pred\"], seg_label)\n",
        "\n",
        "        if isinstance(seg_logit, dict):\n",
        "            # atm loss\n",
        "            seg_label = seg_label.squeeze(1)\n",
        "            if self.crop_train:\n",
        "                # mask seg_label by crop_idx\n",
        "                bs, h, w = seg_label.size()\n",
        "                mask_label = seg_label.reshape(bs, h//16, 16, w//16, 16)\\\n",
        "                    .permute(0, 1, 3, 2, 4).reshape(bs, h*w//256, 256)\n",
        "                empty_label = torch.zeros_like(mask_label) + self.ignore_index\n",
        "                empty_label[:, self.crop_idx] = mask_label[:, self.crop_idx]\n",
        "                seg_label = empty_label.reshape(bs, h//16, w//16, 16, 16)\\\n",
        "                    .permute(0, 1, 3, 2, 4).reshape(bs, h, w)\n",
        "            loss = self.loss_decode(\n",
        "                seg_logit,\n",
        "                seg_label,\n",
        "                ignore_index=self.ignore_index)\n",
        "\n",
        "            loss['acc_seg'] = accuracy(seg_logit[\"pred\"], seg_label, ignore_index=self.ignore_index)\n",
        "            return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "1JcrF9w6PsoZ"
      },
      "outputs": [],
      "source": [
        "### ATM Losses\n",
        "from typing import List, Optional\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.distributed as dist\n",
        "import torchvision\n",
        "from torch import Tensor\n",
        "\n",
        "from einops import rearrange\n",
        "# import imageio.v3 as iio\n",
        "import numpy as np\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def _max_by_axis(the_list):\n",
        "    # type: (List[List[int]]) -> List[int]\n",
        "    maxes = the_list[0]\n",
        "    for sublist in the_list[1:]:\n",
        "        for index, item in enumerate(sublist):\n",
        "            maxes[index] = max(maxes[index], item)\n",
        "    return maxes\n",
        "\n",
        "\n",
        "class NestedTensor(object):\n",
        "    def __init__(self, tensors, mask: Optional[Tensor]):\n",
        "        self.tensors = tensors\n",
        "        self.mask = mask\n",
        "\n",
        "    def to(self, device):\n",
        "        # type: (Device) -> NestedTensor # noqa\n",
        "        cast_tensor = self.tensors.to(device)\n",
        "        mask = self.mask\n",
        "        if mask is not None:\n",
        "            assert mask is not None\n",
        "            cast_mask = mask.to(device)\n",
        "        else:\n",
        "            cast_mask = None\n",
        "        return NestedTensor(cast_tensor, cast_mask)\n",
        "\n",
        "    def decompose(self):\n",
        "        return self.tensors, self.mask\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.tensors)\n",
        "\n",
        "\n",
        "def nested_tensor_from_tensor_list(tensor_list: List[Tensor]):\n",
        "    # TODO make this more general\n",
        "    if tensor_list[0].ndim == 3:\n",
        "        if torchvision._is_tracing():\n",
        "            # nested_tensor_from_tensor_list() does not export well to ONNX\n",
        "            # call _onnx_nested_tensor_from_tensor_list() instead\n",
        "            return _onnx_nested_tensor_from_tensor_list(tensor_list)\n",
        "\n",
        "        # TODO make it support different-sized images\n",
        "        max_size = _max_by_axis([list(img.shape) for img in tensor_list])\n",
        "        # min_size = tuple(min(s) for s in zip(*[img.shape for img in tensor_list]))\n",
        "        batch_shape = [len(tensor_list)] + max_size\n",
        "        b, c, h, w = batch_shape\n",
        "        dtype = tensor_list[0].dtype\n",
        "        device = tensor_list[0].device\n",
        "        tensor = torch.zeros(batch_shape, dtype=dtype, device=device)\n",
        "        mask = torch.ones((b, h, w), dtype=torch.bool, device=device)\n",
        "        for img, pad_img, m in zip(tensor_list, tensor, mask):\n",
        "            pad_img[: img.shape[0], : img.shape[1], : img.shape[2]].copy_(img)\n",
        "            m[: img.shape[1], : img.shape[2]] = False\n",
        "    else:\n",
        "        raise ValueError(\"not supported\")\n",
        "    return NestedTensor(tensor, mask)\n",
        "\n",
        "\n",
        "# _onnx_nested_tensor_from_tensor_list() is an implementation of\n",
        "# nested_tensor_from_tensor_list() that is supported by ONNX tracing.\n",
        "@torch.jit.unused\n",
        "def _onnx_nested_tensor_from_tensor_list(tensor_list: List[Tensor]) -> NestedTensor:\n",
        "    max_size = []\n",
        "    for i in range(tensor_list[0].dim()):\n",
        "        max_size_i = torch.max(\n",
        "            torch.stack([img.shape[i] for img in tensor_list]).to(torch.float32)\n",
        "        ).to(torch.int64)\n",
        "        max_size.append(max_size_i)\n",
        "    max_size = tuple(max_size)\n",
        "\n",
        "    # work around for\n",
        "    # pad_img[: img.shape[0], : img.shape[1], : img.shape[2]].copy_(img)\n",
        "    # m[: img.shape[1], :img.shape[2]] = False\n",
        "    # which is not yet supported in onnx\n",
        "    padded_imgs = []\n",
        "    padded_masks = []\n",
        "    for img in tensor_list:\n",
        "        padding = [(s1 - s2) for s1, s2 in zip(max_size, tuple(img.shape))]\n",
        "        padded_img = torch.nn.functional.pad(img, (0, padding[2], 0, padding[1], 0, padding[0]))\n",
        "        padded_imgs.append(padded_img)\n",
        "\n",
        "        m = torch.zeros_like(img[0], dtype=torch.int, device=img.device)\n",
        "        padded_mask = torch.nn.functional.pad(m, (0, padding[2], 0, padding[1]), \"constant\", 1)\n",
        "        padded_masks.append(padded_mask.to(torch.bool))\n",
        "\n",
        "    tensor = torch.stack(padded_imgs)\n",
        "    mask = torch.stack(padded_masks)\n",
        "\n",
        "    return NestedTensor(tensor, mask=mask)\n",
        "\n",
        "\n",
        "def is_dist_avail_and_initialized():\n",
        "    if not dist.is_available():\n",
        "        return False\n",
        "    if not dist.is_initialized():\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def get_world_size() -> int:\n",
        "    if not dist.is_available():\n",
        "        return 1\n",
        "    if not dist.is_initialized():\n",
        "        return 1\n",
        "    return dist.get_world_size()\n",
        "\n",
        "\n",
        "def dice_loss(inputs, targets, num_masks):\n",
        "    \"\"\"\n",
        "    Compute the DICE loss, similar to generalized IOU for masks\n",
        "    Args:\n",
        "        inputs: A float tensor of arbitrary shape.\n",
        "                The predictions for each example.\n",
        "        targets: A float tensor with the same shape as inputs. Stores the binary\n",
        "                 classification label for each element in inputs\n",
        "                (0 for the negative class and 1 for the positive class).\n",
        "    \"\"\"\n",
        "    inputs = inputs.sigmoid()\n",
        "    inputs = inputs.flatten(1)\n",
        "    numerator = 2 * (inputs * targets).sum(-1)\n",
        "    denominator = inputs.sum(-1) + targets.sum(-1)\n",
        "    loss = 1 - (numerator + 1) / (denominator + 1)\n",
        "    return loss.sum() / num_masks\n",
        "\n",
        "\n",
        "def sigmoid_focal_loss(inputs, targets, num_masks, alpha: float = 0.25, gamma: float = 2):\n",
        "    \"\"\"\n",
        "    Loss used in RetinaNet for dense detection: https://arxiv.org/abs/1708.02002.\n",
        "    Args:\n",
        "        inputs: A float tensor of arbitrary shape.\n",
        "                The predictions for each example.\n",
        "        targets: A float tensor with the same shape as inputs. Stores the binary\n",
        "                 classification label for each element in inputs\n",
        "                (0 for the negative class and 1 for the positive class).\n",
        "        alpha: (optional) Weighting factor in range (0,1) to balance\n",
        "                positive vs negative examples. Default = -1 (no weighting).\n",
        "        gamma: Exponent of the modulating factor (1 - p_t) to\n",
        "               balance easy vs hard examples.\n",
        "    Returns:\n",
        "        Loss tensor\n",
        "    \"\"\"\n",
        "    prob = inputs.sigmoid()\n",
        "    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
        "    p_t = prob * targets + (1 - prob) * (1 - targets)\n",
        "    loss = ce_loss * ((1 - p_t) ** gamma)\n",
        "\n",
        "    if alpha >= 0:\n",
        "        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
        "        loss = alpha_t * loss\n",
        "\n",
        "    return loss.mean(1).sum() / num_masks\n",
        "\n",
        "\n",
        "class SetCriterion(nn.Module):\n",
        "    \"\"\"This class computes the loss for DETR.\n",
        "    The process happens in two steps:\n",
        "        1) we compute hungarian assignment between ground truth boxes and the outputs of the model\n",
        "        2) we supervise each pair of matched ground-truth / prediction (supervise class and box)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, weight_dict, losses, eos_coef=0.1):\n",
        "        \"\"\"Create the criterion.\n",
        "        Parameters:\n",
        "            num_classes: number of object categories, omitting the special no-object category\n",
        "            matcher: module able to compute a matching between targets and proposals\n",
        "            weight_dict: dict containing as key the names of the losses and as values their relative weight.\n",
        "            eos_coef: relative classification weight applied to the no-object category\n",
        "            losses: list of all the losses to be applied. See get_loss for list of available losses.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.weight_dict = weight_dict\n",
        "        self.eos_coef = eos_coef\n",
        "        self.losses = losses\n",
        "        empty_weight = torch.ones(self.num_classes + 1)\n",
        "        empty_weight[0] = self.eos_coef\n",
        "        self.register_buffer(\"empty_weight\", empty_weight)\n",
        "\n",
        "    def loss_labels(self, outputs, targets, indices, num_masks):\n",
        "        \"\"\"Classification loss (NLL)\n",
        "        targets dicts must contain the key \"labels\" containing a tensor of dim [nb_target_boxes]\n",
        "        \"\"\"\n",
        "        assert \"pred_logits\" in outputs\n",
        "        src_logits = outputs[\"pred_logits\"]\n",
        "\n",
        "        idx = self._get_src_permutation_idx(indices)\n",
        "        target_classes_o = torch.cat([t[\"labels\"][J] for t, (_, J) in zip(targets, indices)])\n",
        "        target_classes = torch.zeros(\n",
        "            src_logits.shape[:2], dtype=torch.int64, device=src_logits.device\n",
        "        )\n",
        "        target_classes[idx] = target_classes_o.long()\n",
        "\n",
        "        loss_ce = F.cross_entropy(src_logits.transpose(1, 2), target_classes, self.empty_weight)\n",
        "        losses = {\"loss_ce\": loss_ce}\n",
        "        return losses\n",
        "\n",
        "    def loss_masks(self, outputs, targets, indices, num_masks):\n",
        "        \"\"\"Compute the losses related to the masks: the focal loss and the dice loss.\n",
        "        targets dicts must contain the key \"masks\" containing a tensor of dim [nb_target_boxes, h, w]\n",
        "        \"\"\"\n",
        "        assert \"pred_masks\" in outputs\n",
        "\n",
        "        src_idx = self._get_src_permutation_idx(indices)\n",
        "        tgt_idx = self._get_tgt_permutation_idx(indices)\n",
        "        src_masks = outputs[\"pred_masks\"]\n",
        "        if src_masks.dim() != 4:\n",
        "            return {\"no_loss\": 0}\n",
        "        src_masks = src_masks[src_idx]\n",
        "        masks = [t[\"masks\"] for t in targets]\n",
        "        # TODO use valid to mask invalid areas due to padding in loss\n",
        "        target_masks, valid = nested_tensor_from_tensor_list(masks).decompose()\n",
        "        target_masks = target_masks.to(src_masks)\n",
        "        target_masks = target_masks[tgt_idx]\n",
        "\n",
        "        # upsample predictions to the target size\n",
        "        src_masks = F.interpolate(\n",
        "            src_masks[:, None], size=target_masks.shape[-2:], mode=\"bilinear\", align_corners=False\n",
        "        )\n",
        "        src_masks = src_masks[:, 0].flatten(1)\n",
        "\n",
        "        target_masks = target_masks.flatten(1)\n",
        "        target_masks = target_masks.view(src_masks.shape)\n",
        "        losses = {\n",
        "            \"loss_mask\": sigmoid_focal_loss(src_masks, target_masks, num_masks),\n",
        "            \"loss_dice\": dice_loss(src_masks, target_masks, num_masks),\n",
        "        }\n",
        "        return losses\n",
        "\n",
        "    def _get_src_permutation_idx(self, indices):\n",
        "        # permute predictions following indices\n",
        "        batch_idx = torch.cat([torch.full_like(src, i) for i, (src, _) in enumerate(indices)])\n",
        "        src_idx = torch.cat([src for (src, _) in indices])\n",
        "        return batch_idx.long(), src_idx.long()\n",
        "\n",
        "    def _get_tgt_permutation_idx(self, indices):\n",
        "        # permute targets following indices\n",
        "        batch_idx = torch.cat([torch.full_like(tgt, i) for i, (_, tgt) in enumerate(indices)])\n",
        "        tgt_idx = torch.cat([tgt for (_, tgt) in indices])\n",
        "        return batch_idx, tgt_idx\n",
        "\n",
        "    def get_loss(self, loss, outputs, targets, indices, num_masks):\n",
        "        loss_map = {\"labels\": self.loss_labels, \"masks\": self.loss_masks}\n",
        "        assert loss in loss_map, f\"do you really want to compute {loss} loss?\"\n",
        "        return loss_map[loss](outputs, targets, indices, num_masks)\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        \"\"\"This performs the loss computation.\n",
        "        Parameters:\n",
        "             outputs: dict of tensors, see the output specification of the model for the format\n",
        "             targets: list of dicts, such that len(targets) == batch_size.\n",
        "                      The expected keys in each dict depends on the losses applied, see each loss' doc\n",
        "        \"\"\"\n",
        "        # outputs_without_aux = {k: v for k, v in outputs.items() if k != \"aux_outputs\"}\n",
        "\n",
        "        # Retrieve the matching between the outputs of the last layer and the targets\n",
        "\n",
        "        labels = [x['labels'] for x in targets]\n",
        "        indices_new = []\n",
        "        for label in labels:\n",
        "            t = torch.arange(len(label))\n",
        "            indices_new.append([label, t])\n",
        "        indices = indices_new\n",
        "        # Compute the average number of target boxes accross all nodes, for normalization purposes\n",
        "        num_masks = sum(len(t[\"labels\"]) for t in targets)\n",
        "        num_masks = torch.as_tensor(\n",
        "            [num_masks], dtype=torch.float, device=next(iter(outputs.values())).device\n",
        "        )\n",
        "        if is_dist_avail_and_initialized():\n",
        "            torch.distributed.all_reduce(num_masks)\n",
        "        num_masks = torch.clamp(num_masks / get_world_size(), min=1).item()\n",
        "\n",
        "        # Compute all the requested losses\n",
        "        losses = {}\n",
        "        for loss in self.losses:\n",
        "            losses.update(self.get_loss(loss, outputs, targets, indices, num_masks))\n",
        "\n",
        "        # In case of auxiliary losses, we repeat this process with the output of each intermediate layer.\n",
        "        if \"aux_outputs\" in outputs:\n",
        "            for i, aux_outputs in enumerate(outputs[\"aux_outputs\"]):\n",
        "                # use the indices as the last stage\n",
        "                for loss in self.losses:\n",
        "                    l_dict = self.get_loss(loss, aux_outputs, targets, indices, num_masks)\n",
        "                    l_dict = {k + f\"_{i}\": v for k, v in l_dict.items()}\n",
        "                    losses.update(l_dict)\n",
        "\n",
        "        return losses\n",
        "    \n",
        "\n",
        "class ATMLoss(nn.Module):\n",
        "    \"\"\"ATMLoss.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_classes,\n",
        "                 dec_layers,\n",
        "                 mask_weight=20.0,\n",
        "                 dice_weight=1.0,\n",
        "                 cls_weight=1.0,\n",
        "                 loss_weight=1.0):\n",
        "        super(ATMLoss, self).__init__()\n",
        "        weight_dict = {\"loss_ce\": cls_weight, \"loss_mask\": mask_weight, \"loss_dice\": dice_weight}\n",
        "        aux_weight_dict = {}\n",
        "        for i in range(dec_layers - 1):\n",
        "            aux_weight_dict.update({k + f\"_{i}\": v for k, v in weight_dict.items()})\n",
        "        weight_dict.update(aux_weight_dict)\n",
        "        \n",
        "        self.criterion = SetCriterion(\n",
        "                num_classes,\n",
        "                weight_dict=weight_dict,\n",
        "                losses=[\"labels\", \"masks\"],\n",
        "            )\n",
        "        self.loss_weight = loss_weight\n",
        "\n",
        "    def forward(self,\n",
        "                outputs,\n",
        "                label,\n",
        "                ignore_index,\n",
        "                ):\n",
        "        \"\"\"Forward function.\"\"\"\n",
        "        self.ignore_index = ignore_index\n",
        "        targets = self.prepare_targets(label)\n",
        "        losses = self.criterion(outputs, targets)\n",
        "        loss = 0\n",
        "\n",
        "        for k in list(losses.keys()):\n",
        "            if k in self.criterion.weight_dict:\n",
        "                # losses[k] = losses[k] * self.criterion.weight_dict[k] * self.loss_weight\n",
        "                loss += losses[k] * self.criterion.weight_dict[k] * self.loss_weight\n",
        "            else:\n",
        "                # remove this loss if not specified in `weight_dict`\n",
        "                losses.pop(k)\n",
        "\n",
        "        return loss #, losses\n",
        "\n",
        "    def prepare_targets(self, targets):\n",
        "        new_targets = []\n",
        "        for targets_per_image in targets:\n",
        "            # gt_cls\n",
        "            gt_cls = targets_per_image.unique()\n",
        "            gt_cls = gt_cls[gt_cls != self.ignore_index]\n",
        "            masks = []\n",
        "            for cls in gt_cls:\n",
        "                masks.append(targets_per_image == cls)\n",
        "            if len(gt_cls) == 0:\n",
        "                masks.append(targets_per_image == self.ignore_index)\n",
        "\n",
        "            masks = torch.stack(masks, dim=0)\n",
        "            new_targets.append(\n",
        "                {\n",
        "                    \"labels\": gt_cls,\n",
        "                    \"masks\": masks,\n",
        "                }\n",
        "            )\n",
        "        return new_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "iw9N8F9wUjlX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIpHkJy4Qjeh",
        "outputId": "7a79dc66-4d84-46b8-b5a1-0863b1d00e29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "50SLH26hUP_B"
      },
      "outputs": [],
      "source": [
        "### Dataloader method\n",
        "def load_data(root, annotation_file, batch_size=2):\n",
        "    preprocess = transforms.Compose([\n",
        "            ImglistToTensor(),  # list of PIL images to (FRAMES x CHANNELS x HEIGHT x WIDTH) tensor\n",
        "            # transforms.Resize(299),  # image batch, resize smaller edge to 299\n",
        "            transforms.Resize((128,128)),\n",
        "            # transforms.CenterCrop(299),  # image batch, center crop to square 299x299\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "    dataset = VideoFrameDataset(\n",
        "        root_path=root,\n",
        "        annotationfile_path=annotation_file,\n",
        "        num_segments=1,\n",
        "        frames_per_segment=22,\n",
        "        imagefile_template='image_{:d}.png',\n",
        "        transform=preprocess,\n",
        "        mask=True,\n",
        "        test_mode=False\n",
        "    )\n",
        "\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "            dataset=dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=2, # arbitrarily chosen\n",
        "            pin_memory=True\n",
        "        )\n",
        "    return dataloader\n",
        "\n",
        "### Load the train and validation datasets\n",
        "batch_size = 2\n",
        "trainloader = load_data('Dataset_Student/train/data/', 'Dataset_Student/train/annotations.txt', batch_size)\n",
        "valloader = load_data('Dataset_Student/val/data/', 'Dataset_Student/val/annotations.txt', batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wKPw-zKrlsI",
        "outputId": "684f0d70-88b9-4bee-e926-3e547688b416"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ATMHead(\n",
              "  (input_proj_1): Linear(in_features=384, out_features=768, bias=True)\n",
              "  (proj_norm_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (decoder_1): TPN_Decoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x TPN_DecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        (multihead_attn): Attention(\n",
              "          (q): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (k): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (q): Embedding(49, 768)\n",
              "  (class_embed): Linear(in_features=768, out_features=49, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### Initialize Decoder\n",
        "decoder = ATMHead(img_size=128, H=160, W=240, in_channels=384, use_stages=1)\n",
        "decoder.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "mIIEW0DDMDtl"
      },
      "outputs": [],
      "source": [
        "### Epochs, Optimizer, Criterion and Scheduler\n",
        "\n",
        "criterion = ATMLoss(48, 1) ## 48 classes + 1 background which will be added in the loss\n",
        "criterion.to(device)\n",
        "\n",
        "initial_lr = 0.00001\n",
        "final_lr = 0.0000001\n",
        "optimizer = torch.optim.AdamW(decoder.parameters(), lr=initial_lr, weight_decay=0.05)\n",
        "\n",
        "num_epochs = 2\n",
        "total_steps = num_epochs * len(trainloader)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=final_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "8cHNecAcjhIs"
      },
      "outputs": [],
      "source": [
        "### Jaccard method\n",
        "def compute_jaccard(ground_truth_mask, predicted_mask, device):\n",
        "  jaccard = torchmetrics.JaccardIndex(task=\"multiclass\", num_classes=49).to(device)\n",
        "  jaccard(torch.Tensor(ground_truth_mask), torch.Tensor(predicted_mask))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RHW1vNPaceXd",
        "outputId": "b24999a4-a591-4b45-f516-a2295f1dd8fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.766320824623108\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8092014789581299\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8070554733276367\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8738319873809814\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.7692005634307861\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.7925456762313843\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8689721822738647\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8500585556030273\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8011784553527832\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.7955384254455566\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.885838270187378\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8110105991363525\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.773496150970459\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.7736713886260986\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.811694860458374\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.7879700660705566\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8007773160934448\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8320825099945068\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8338847160339355\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.818265438079834\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8833715915679932\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8341751098632812\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.778495192527771\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8478957414627075\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.7650128602981567\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8572968244552612\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.7901113033294678\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8366823196411133\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8110040426254272\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8325221538543701\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.7868309020996094\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.769742727279663\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8199472427368164\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.7644991874694824\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.7686777114868164\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8527103662490845\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8244240283966064\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.7138112783432007\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8060216903686523\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.7764201164245605\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.7349413633346558\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8019051551818848\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.7307310104370117\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.794150948524475\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.7237141132354736\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.7325115203857422\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8120975494384766\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8298594951629639\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8355636596679688\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "Current loss: 1.8172252178192139\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n",
            "torch.Size([44, 49, 160, 240])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([44, 48, 160, 240])\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-2015c91550d2>\u001b[0m in \u001b[0;36m<cell line: 116>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;31m# run full evaluation at this point?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Decoder training finshed at epoch {results[\"epoch\"]}, trainig loss: {results[\"train_loss\"]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-2015c91550d2>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epoch, decoder, encoder, criterion, optimizer, scheduler, dataloader, validationloader, num_epochs, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred_masks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;31m##ouput is batch * frames x num_classes x height x width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 4"
          ]
        }
      ],
      "source": [
        "### Training loop\n",
        "def train_model(epoch, decoder, encoder, criterion, optimizer, scheduler, dataloader, validationloader, num_epochs, device):\n",
        "    while epoch < num_epochs:\n",
        "        decoder.train()\n",
        "        encoder.eval()\n",
        "\n",
        "        train_loss = 0\n",
        "\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            inputs, labels, target_masks = data \n",
        "            inputs, labels, target_masks = inputs.to(device), labels.to(device), target_masks.to(device)\n",
        "\n",
        "            inputs = inputs[:, :11] #Remove depending on preference\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            ### forward pass through encoder to get the embeddings\n",
        "            predicted_embeddings = encoder(inputs.transpose(1, 2))\n",
        "\n",
        "            # Reshape predicted embeddings to (b t) (h w) m\n",
        "            predicted_embeddings = rearrange(predicted_embeddings, 'b t n m -> (b t) n m')\n",
        "            target_masks = rearrange(target_masks, 'b t n m -> (b t) n m')\n",
        "\n",
        "            ### forward pass through decoder to get the masks\n",
        "            outputs = decoder(predicted_embeddings)\n",
        "\n",
        "            print(outputs['pred_masks'].shape)\n",
        "\n",
        "            # the target_mask tensor is of shape b f h w\n",
        "\n",
        "            ### compute the loss and step\n",
        "            loss = criterion(outputs, target_masks, -1)\n",
        "            train_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the scheduler learning rate\n",
        "            scheduler.step()\n",
        "\n",
        "            if i % 10 == 0 and epoch < 5:\n",
        "                print(f\"Current loss: {loss.item()}\") # we can just take a sample, don't need to average it\n",
        "        \n",
        "        avg_epoch_loss = train_loss / len(dataloader)\n",
        "\n",
        "        # Validation loss\n",
        "        decoder.eval()\n",
        "        #total_val_loss = 0\n",
        "        predictions = []\n",
        "        targets = []\n",
        "        with torch.no_grad():\n",
        "            for data in validationloader:\n",
        "                inputs, labels, target_masks = data\n",
        "                inputs, labels, target_masks = inputs.to(device), labels.to(device), target_masks.to(device)\n",
        "\n",
        "                inputs = inputs[:, :11]\n",
        "\n",
        "                ### compute predictions\n",
        "                predicted_embeddings = encoder(inputs.transpose(1, 2))\n",
        "\n",
        "                # Reshape predicted embeddings to (b t) (h w) m\n",
        "                predicted_embeddings = rearrange(predicted_embeddings, 'b t n m -> (b t) n m')\n",
        "                target_masks = rearrange(target_masks, 'b t n m -> (b t) n m')\n",
        "\n",
        "                ### forward pass through decoder to get the masks\n",
        "                outputs = decoder(predicted_embeddings)\n",
        "\n",
        "                # compute loss\n",
        "                #val_loss = criterion(outputs, target_masks, -1)\n",
        "                #total_val_loss += val_loss.item()\n",
        "\n",
        "                print(outputs.shape)\n",
        "                print(outputs['pred_masks'].keys)\n",
        "\n",
        "                ##ouput is batch * frames x num_classes x height x width\n",
        "\n",
        "                ## want to go from batch * frames x height x width x num_classes with logits to batch * frames x height x width with class predictions\n",
        "                predicted = torch.argmax(outputs['pred_masks'], 1)\n",
        "                print(predicted.shape)\n",
        "                print(target_masks.shape)\n",
        "\n",
        "                predictions.append(predicted)\n",
        "                targets.append(target_masks)\n",
        "\n",
        "        # Concatenate all predicted masks and target masks from batches\n",
        "        predictions_tensor = torch.cat(predictions, 0)\n",
        "        targets_tensor = torch.cat(targets, 0)\n",
        "\n",
        "        print(predictions_tensor.shape)\n",
        "        print(targets_tensor.shape)\n",
        "\n",
        "        # Compute Jaccard score using accumulated predictions and targets\n",
        "        jaccard_score = compute_jaccard(predictions_tensor, targets_tensor, device)\n",
        "        #avg_val_loss = val_loss / len(dataloader)\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Epoch: {epoch + 1}, Learning Rate: {current_lr:.6f}, Avg train loss: {avg_epoch_loss:.4f}, Avg val loss: {avg_val_loss:.4f}, Jaccard: {jaccard_score:.4f}\")\n",
        "\n",
        "        # Used this approach (while and epoch increase) so that we can get back to training the loaded model from checkpoint\n",
        "        epoch += 1\n",
        "\n",
        "        # Checkpoint\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': decoder.module.state_dict() if torch.cuda.device_count() > 1 else decoder.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict()\n",
        "            }, \"models/decoder/checkpoint_decoder.pkl\")\n",
        "\n",
        "    return {\n",
        "        \"epochs\": epoch,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"model\": decoder\n",
        "            }\n",
        "\n",
        "epoch = 0\n",
        "results = train_model(epoch, decoder, encoder, criterion, optimizer, scheduler, trainloader, valloader, num_epochs, device)\n",
        "# run full evaluation at this point?\n",
        "print(f'Decoder training finshed at epoch {results[\"epoch\"]}, trainig loss: {results[\"train_loss\"]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7gpClNIPOIR",
        "outputId": "74790cc2-01b6-44da-8708-1a8c96f75580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1j6WOMJ_gpTl2--ddt9htMAW8ObPH-T0h\n",
            "To: /content/hidden.zip\n",
            "100% 664M/664M [00:02<00:00, 288MB/s]\n",
            "Archive:  hidden.zip\n",
            "replace __MACOSX/._hidden? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "### Download and unzip hidden data set for leaderboard\n",
        "!gdown https://drive.google.com/uc?id=1j6WOMJ_gpTl2--ddt9htMAW8ObPH-T0h\n",
        "!unzip hidden.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "fUJ6aauS_VRP"
      },
      "outputs": [],
      "source": [
        "!mv hidden/ data/\n",
        "!mkdir hidden/\n",
        "!mv data/ hidden/data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ToBNvUWOP-GS"
      },
      "outputs": [],
      "source": [
        "### Annotate the hidden set\n",
        "import sys\n",
        "\n",
        "def annotate(min_i,max_i,output_dir):\n",
        "    with open(output_dir + 'annotations.txt', 'w') as f:\n",
        "        for i in range(min_i, max_i):\n",
        "            f.write(f'video_{i} 0 10 0 \\n') #should be 11 frames instead of 22\n",
        "\n",
        "\n",
        "annotate(15000, 17000, 'hidden/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "h5WYcaIHQz53"
      },
      "outputs": [],
      "source": [
        "### Dataloader method\n",
        "# are these the correct settings? Cannot reuse previous load_data method unless we add mask and shuffle as passable params\n",
        "def load_hidden_data(root, annotation_file, batch_size=2):\n",
        "    preprocess = transforms.Compose([\n",
        "            ImglistToTensor(),  # list of PIL images to (FRAMES x CHANNELS x HEIGHT x WIDTH) tensor\n",
        "            # transforms.Resize(299),  # image batch, resize smaller edge to 299\n",
        "            transforms.Resize((128,128)),\n",
        "            # transforms.CenterCrop(299),  # image batch, center crop to square 299x299\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "    dataset = VideoFrameDataset(\n",
        "        root_path=root,\n",
        "        annotationfile_path=annotation_file,\n",
        "        num_segments=1,\n",
        "        frames_per_segment=11,\n",
        "        imagefile_template='image_{:d}.png',\n",
        "        transform=preprocess,\n",
        "        mask=False,\n",
        "        test_mode=False\n",
        "    )\n",
        "\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "            dataset=dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=2,\n",
        "            pin_memory=True\n",
        "        )\n",
        "    return dataloader\n",
        "\n",
        "### Load the train and validation datasets\n",
        "batch_size = 1\n",
        "hiddenloader = load_hidden_data('hidden/data/', 'hidden/annotations.txt', batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "SG3e2TZiNC01",
        "outputId": "b06bb515-1c49-40a8-a841-53e9ed76609a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([22, 48, 160, 240])\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-025077578bd6>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults_hidden_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_masks_for_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddenloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'results_hidden_tensor.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-025077578bd6>\u001b[0m in \u001b[0;36mpredict_masks_for_hidden\u001b[0;34m(encoder, decoder, hiddenloader)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# use argmax to go from logits to classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred_masks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mhidden_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this only works when batch_size = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 4"
          ]
        }
      ],
      "source": [
        "### Use Encoder and Decoder to predict the hidden set\n",
        "\n",
        "# From brightspace:\n",
        "# There are 2000 videos with 11 frames each in the hidden dataset.\n",
        "# You need to submit a saved pytorch tensor or numpy array with the size (2000, 160, 240) \n",
        "# that each (160, 240) matrix corresponding to the mask of 22nd frame of each video in the hidden set.\n",
        "\n",
        "#predicted mask for frame 22, in order\n",
        "def predict_masks_for_hidden(encoder, decoder, hiddenloader):\n",
        "    hidden_results = []\n",
        "\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    for i, data in enumerate(hiddenloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass through encoder to get the embeddings\n",
        "        predicted_embeddings = encoder(inputs.transpose(1, 2))\n",
        "\n",
        "        # Reshape predicted embeddings to (b t) (h w) m\n",
        "        predicted_embeddings = rearrange(predicted_embeddings, 'b t n m -> (b t) n m')\n",
        "\n",
        "        # forward pass through decoder to get the masks\n",
        "        outputs = decoder(predicted_embeddings)\n",
        "\n",
        "        print(outputs.shape)\n",
        "\n",
        "        # use argmax to go from logits to classes\n",
        "        prediction = torch.argmax(outputs['pred_masks'], 1)\n",
        "\n",
        "        hidden_results.append(prediction[21]) # this only works when batch_size = 1\n",
        "\n",
        "    results_hidden_tensor = torch.stack(hidden_results)\n",
        "    return results_hidden_tensor\n",
        "\n",
        "results = predict_masks_for_hidden(encoder, decoder, hiddenloader)\n",
        "torch.save(results, 'results_hidden_tensor.pt')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
