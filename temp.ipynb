{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "# import imageio.v3 as iio\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "from video_dataset import VideoFrameDataset, ImglistToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /Users/luiginoto/opt/miniconda3/envs/pDL/lib/python3.9/site-packages (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/Users/luiginoto/Downloads/Dataset_Student/unlabeled/data/'\n",
    "annotation_file = '/Users/luiginoto/Downloads/Dataset_Student/unlabeled/annotations.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform_train = transforms.Compose([\n",
    "#     #transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.Resize((128,128)),\n",
    "#     #transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "        ImglistToTensor(),  # list of PIL images to (FRAMES x CHANNELS x HEIGHT x WIDTH) tensor\n",
    "        # transforms.Resize(299),  # image batch, resize smaller edge to 299\n",
    "        transforms.Resize((128,128)),\n",
    "        # transforms.CenterCrop(299),  # image batch, center crop to square 299x299\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoFrameDataset(\n",
    "    root_path=root,\n",
    "    annotationfile_path=annotation_file,\n",
    "    num_segments=1,\n",
    "    frames_per_segment=22,\n",
    "    imagefile_template='image_{:d}.png',\n",
    "    transform=preprocess,\n",
    "    test_mode=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[0] \n",
    "frames = sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 3, 128, 128])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.3391, -0.3377, -0.3108,  ..., -0.2282, -0.2327, -0.2576],\n",
       "          [-0.3363, -0.3217, -0.3166,  ..., -0.2282, -0.2268, -0.2500],\n",
       "          [-0.3088, -0.2675, -0.2631,  ..., -0.2282, -0.2342, -0.2466],\n",
       "          ...,\n",
       "          [ 0.2624,  0.2742,  0.2723,  ...,  0.1414,  0.1299,  0.1426],\n",
       "          [ 0.2671,  0.2669,  0.2743,  ...,  0.1521,  0.1406,  0.1426],\n",
       "          [ 0.2784,  0.2671,  0.2796,  ...,  0.1503,  0.1529,  0.1575]],\n",
       "\n",
       "         [[-0.2172, -0.2158, -0.1883,  ..., -0.1038, -0.1238, -0.1339],\n",
       "          [-0.2143, -0.1994, -0.1942,  ..., -0.1038, -0.1024, -0.1261],\n",
       "          [-0.1801, -0.1440, -0.1395,  ..., -0.1038, -0.1099, -0.1227],\n",
       "          ...,\n",
       "          [ 0.3627,  0.3748,  0.3729,  ...,  0.2686,  0.2622,  0.2752],\n",
       "          [ 0.3675,  0.3673,  0.3749,  ...,  0.2577,  0.2547,  0.2704],\n",
       "          [ 0.3790,  0.3675,  0.3803,  ...,  0.2606,  0.2562,  0.2589]],\n",
       "\n",
       "         [[ 0.0014,  0.0074,  0.0347,  ...,  0.1189,  0.1095,  0.0889],\n",
       "          [-0.0143,  0.0237,  0.0289,  ...,  0.1189,  0.1203,  0.0967],\n",
       "          [ 0.0429,  0.0789,  0.0834,  ...,  0.1189,  0.1128,  0.1001],\n",
       "          ...,\n",
       "          [ 0.5136,  0.5256,  0.5237,  ...,  0.4427,  0.4310,  0.4439],\n",
       "          [ 0.5184,  0.5256,  0.5258,  ...,  0.4427,  0.4310,  0.4439],\n",
       "          [ 0.5603,  0.5199,  0.5339,  ...,  0.4344,  0.4370,  0.4439]]],\n",
       "\n",
       "\n",
       "        [[[-0.3391, -0.3377, -0.3108,  ..., -0.2282, -0.2327, -0.2576],\n",
       "          [-0.3363, -0.3217, -0.3166,  ..., -0.2282, -0.2268, -0.2500],\n",
       "          [-0.3088, -0.2675, -0.2631,  ..., -0.2282, -0.2342, -0.2466],\n",
       "          ...,\n",
       "          [ 0.2624,  0.2742,  0.2624,  ...,  0.1478,  0.1299,  0.1426],\n",
       "          [ 0.2624,  0.2669,  0.2711,  ...,  0.1585,  0.1406,  0.1426],\n",
       "          [ 0.2774,  0.2671,  0.2642,  ...,  0.1597,  0.1529,  0.1575]],\n",
       "\n",
       "         [[-0.2172, -0.2158, -0.1883,  ..., -0.1038, -0.1238, -0.1339],\n",
       "          [-0.2143, -0.1994, -0.1942,  ..., -0.1038, -0.1024, -0.1261],\n",
       "          [-0.1801, -0.1440, -0.1395,  ..., -0.1038, -0.1099, -0.1227],\n",
       "          ...,\n",
       "          [ 0.3627,  0.3748,  0.3627,  ...,  0.2699,  0.2622,  0.2752],\n",
       "          [ 0.3627,  0.3673,  0.3716,  ...,  0.2610,  0.2547,  0.2704],\n",
       "          [ 0.3781,  0.3675,  0.3645,  ...,  0.2581,  0.2514,  0.2589]],\n",
       "\n",
       "         [[ 0.0014,  0.0074,  0.0347,  ...,  0.1189,  0.1095,  0.0889],\n",
       "          [-0.0143,  0.0237,  0.0289,  ...,  0.1189,  0.1203,  0.0967],\n",
       "          [ 0.0429,  0.0789,  0.0834,  ...,  0.1189,  0.1128,  0.1001],\n",
       "          ...,\n",
       "          [ 0.5173,  0.5256,  0.5149,  ...,  0.4439,  0.4310,  0.4439],\n",
       "          [ 0.5391,  0.5399,  0.5455,  ...,  0.4439,  0.4310,  0.4439],\n",
       "          [ 0.5637,  0.5437,  0.5503,  ...,  0.4439,  0.4370,  0.4439]]],\n",
       "\n",
       "\n",
       "        [[[-0.3391, -0.3377, -0.3108,  ..., -0.2282, -0.2327, -0.2576],\n",
       "          [-0.3363, -0.3217, -0.3166,  ..., -0.2282, -0.2268, -0.2500],\n",
       "          [-0.3088, -0.2675, -0.2631,  ..., -0.2282, -0.2342, -0.2466],\n",
       "          ...,\n",
       "          [ 0.2624,  0.2742,  0.2624,  ...,  0.1426,  0.1332,  0.1426],\n",
       "          [ 0.2624,  0.2669,  0.2711,  ...,  0.1533,  0.1406,  0.1426],\n",
       "          [ 0.2774,  0.2624,  0.2642,  ...,  0.1475,  0.1575,  0.1575]],\n",
       "\n",
       "         [[-0.2172, -0.2158, -0.1883,  ..., -0.1038, -0.1238, -0.1339],\n",
       "          [-0.2143, -0.1994, -0.1942,  ..., -0.1038, -0.1024, -0.1261],\n",
       "          [-0.1801, -0.1440, -0.1395,  ..., -0.1038, -0.1099, -0.1227],\n",
       "          ...,\n",
       "          [ 0.3627,  0.3748,  0.3627,  ...,  0.2752,  0.2622,  0.2752],\n",
       "          [ 0.3627,  0.3673,  0.3716,  ...,  0.2663,  0.2547,  0.2704],\n",
       "          [ 0.3781,  0.3627,  0.3645,  ...,  0.2457,  0.2514,  0.2589]],\n",
       "\n",
       "         [[ 0.0014,  0.0074,  0.0347,  ...,  0.1189,  0.1095,  0.0889],\n",
       "          [-0.0143,  0.0237,  0.0289,  ...,  0.1189,  0.1203,  0.0967],\n",
       "          [ 0.0429,  0.0789,  0.0834,  ...,  0.1189,  0.1128,  0.1001],\n",
       "          ...,\n",
       "          [ 0.5239,  0.5390,  0.5391,  ...,  0.4439,  0.4344,  0.4439],\n",
       "          [ 0.5456,  0.5465,  0.5520,  ...,  0.4439,  0.4310,  0.4439],\n",
       "          [ 0.5637,  0.5485,  0.5503,  ...,  0.4315,  0.4417,  0.4439]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.3391, -0.3377, -0.3108,  ..., -0.2282, -0.2327, -0.2576],\n",
       "          [-0.3363, -0.3217, -0.3166,  ..., -0.2282, -0.2268, -0.2500],\n",
       "          [-0.3088, -0.2675, -0.2631,  ..., -0.2282, -0.2342, -0.2466],\n",
       "          ...,\n",
       "          [ 0.2517,  0.2698,  0.2604,  ...,  0.1361,  0.1299,  0.1426],\n",
       "          [ 0.2624,  0.2624,  0.2711,  ...,  0.1468,  0.1406,  0.1426],\n",
       "          [ 0.2774,  0.2624,  0.2642,  ...,  0.1475,  0.1529,  0.1575]],\n",
       "\n",
       "         [[-0.2172, -0.2158, -0.1883,  ..., -0.1038, -0.1238, -0.1339],\n",
       "          [-0.2143, -0.1994, -0.1942,  ..., -0.1038, -0.1024, -0.1261],\n",
       "          [-0.1801, -0.1440, -0.1395,  ..., -0.1038, -0.1099, -0.1227],\n",
       "          ...,\n",
       "          [ 0.3518,  0.3703,  0.3648,  ...,  0.2686,  0.2622,  0.2752],\n",
       "          [ 0.3627,  0.3627,  0.3716,  ...,  0.2598,  0.2513,  0.2704],\n",
       "          [ 0.3781,  0.3627,  0.3645,  ...,  0.2581,  0.2555,  0.2589]],\n",
       "\n",
       "         [[ 0.0014,  0.0074,  0.0347,  ...,  0.1189,  0.1095,  0.0889],\n",
       "          [-0.0143,  0.0237,  0.0289,  ...,  0.1189,  0.1203,  0.0967],\n",
       "          [ 0.0429,  0.0789,  0.0834,  ...,  0.1189,  0.1128,  0.1001],\n",
       "          ...,\n",
       "          [ 0.5315,  0.5390,  0.5313,  ...,  0.4374,  0.4310,  0.4439],\n",
       "          [ 0.5485,  0.5465,  0.5443,  ...,  0.4374,  0.4310,  0.4439],\n",
       "          [ 0.5637,  0.5485,  0.5503,  ...,  0.4439,  0.4370,  0.4439]]],\n",
       "\n",
       "\n",
       "        [[[-0.3391, -0.3377, -0.3108,  ..., -0.2282, -0.2327, -0.2576],\n",
       "          [-0.3363, -0.3217, -0.3166,  ..., -0.2282, -0.2268, -0.2500],\n",
       "          [-0.3088, -0.2675, -0.2631,  ..., -0.2282, -0.2342, -0.2466],\n",
       "          ...,\n",
       "          [ 0.2517,  0.2698,  0.2604,  ...,  0.1361,  0.1299,  0.1472],\n",
       "          [ 0.2624,  0.2624,  0.2711,  ...,  0.1468,  0.1406,  0.1426],\n",
       "          [ 0.2774,  0.2624,  0.2642,  ...,  0.1475,  0.1529,  0.1510]],\n",
       "\n",
       "         [[-0.2172, -0.2158, -0.1883,  ..., -0.1038, -0.1238, -0.1339],\n",
       "          [-0.2143, -0.1994, -0.1942,  ..., -0.1038, -0.1024, -0.1261],\n",
       "          [-0.1801, -0.1440, -0.1395,  ..., -0.1038, -0.1099, -0.1227],\n",
       "          ...,\n",
       "          [ 0.3518,  0.3703,  0.3648,  ...,  0.2686,  0.2622,  0.2704],\n",
       "          [ 0.3627,  0.3627,  0.3716,  ...,  0.2598,  0.2513,  0.2704],\n",
       "          [ 0.3781,  0.3627,  0.3645,  ...,  0.2581,  0.2555,  0.2522]],\n",
       "\n",
       "         [[ 0.0014,  0.0074,  0.0347,  ...,  0.1189,  0.1095,  0.0889],\n",
       "          [-0.0143,  0.0237,  0.0289,  ...,  0.1189,  0.1203,  0.0967],\n",
       "          [ 0.0429,  0.0789,  0.0834,  ...,  0.1189,  0.1128,  0.1001],\n",
       "          ...,\n",
       "          [ 0.5315,  0.5390,  0.5313,  ...,  0.4374,  0.4310,  0.4439],\n",
       "          [ 0.5485,  0.5465,  0.5443,  ...,  0.4374,  0.4310,  0.4392],\n",
       "          [ 0.5637,  0.5485,  0.5503,  ...,  0.4439,  0.4370,  0.4363]]],\n",
       "\n",
       "\n",
       "        [[[-0.3391, -0.3377, -0.3108,  ..., -0.2282, -0.2327, -0.2576],\n",
       "          [-0.3363, -0.3217, -0.3166,  ..., -0.2282, -0.2268, -0.2500],\n",
       "          [-0.3088, -0.2675, -0.2631,  ..., -0.2282, -0.2342, -0.2466],\n",
       "          ...,\n",
       "          [ 0.2564,  0.2698,  0.2604,  ...,  0.1361,  0.1299,  0.1426],\n",
       "          [ 0.2624,  0.2624,  0.2711,  ...,  0.1468,  0.1406,  0.1426],\n",
       "          [ 0.2774,  0.2624,  0.2642,  ...,  0.1475,  0.1529,  0.1510]],\n",
       "\n",
       "         [[-0.2172, -0.2158, -0.1883,  ..., -0.1038, -0.1238, -0.1339],\n",
       "          [-0.2143, -0.1994, -0.1942,  ..., -0.1038, -0.1024, -0.1261],\n",
       "          [-0.1801, -0.1440, -0.1395,  ..., -0.1038, -0.1099, -0.1227],\n",
       "          ...,\n",
       "          [ 0.3566,  0.3703,  0.3648,  ...,  0.2686,  0.2622,  0.2752],\n",
       "          [ 0.3627,  0.3627,  0.3716,  ...,  0.2598,  0.2513,  0.2704],\n",
       "          [ 0.3781,  0.3627,  0.3645,  ...,  0.2581,  0.2555,  0.2522]],\n",
       "\n",
       "         [[ 0.0014,  0.0074,  0.0347,  ...,  0.1189,  0.1095,  0.0889],\n",
       "          [-0.0143,  0.0237,  0.0289,  ...,  0.1189,  0.1203,  0.0967],\n",
       "          [ 0.0429,  0.0789,  0.0834,  ...,  0.1189,  0.1128,  0.1001],\n",
       "          ...,\n",
       "          [ 0.5239,  0.5390,  0.5313,  ...,  0.4374,  0.4310,  0.4439],\n",
       "          [ 0.5456,  0.5465,  0.5443,  ...,  0.4374,  0.4310,  0.4392],\n",
       "          [ 0.5637,  0.5485,  0.5503,  ...,  0.4439,  0.4370,  0.4363]]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x12601eeb0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[[-0.3562, -0.3227, -0.2955,  ..., -0.2282, -0.2327, -0.2576],\n",
       "            [-0.3498, -0.3281, -0.3146,  ..., -0.2282, -0.2268, -0.2500],\n",
       "            [-0.3056, -0.2739, -0.2631,  ..., -0.2282, -0.2342, -0.2466],\n",
       "            ...,\n",
       "            [ 0.2578,  0.2742,  0.2624,  ...,  0.1286,  0.1299,  0.1462],\n",
       "            [ 0.2624,  0.2669,  0.2711,  ...,  0.1480,  0.1406,  0.1522],\n",
       "            [ 0.2774,  0.2624,  0.2792,  ...,  0.1597,  0.1529,  0.1672]],\n",
       " \n",
       "           [[-0.2414, -0.2325, -0.2032,  ..., -0.1038, -0.1238, -0.1339],\n",
       "            [-0.2281, -0.2128, -0.1921,  ..., -0.1038, -0.1024, -0.1261],\n",
       "            [-0.1830, -0.1506, -0.1395,  ..., -0.1038, -0.1099, -0.1227],\n",
       "            ...,\n",
       "            [ 0.3675,  0.3748,  0.3627,  ...,  0.2598,  0.2622,  0.2654],\n",
       "            [ 0.3627,  0.3673,  0.3716,  ...,  0.2577,  0.2513,  0.2606],\n",
       "            [ 0.3781,  0.3627,  0.3798,  ...,  0.2577,  0.2507,  0.2663]],\n",
       " \n",
       "           [[-0.0181,  0.0067,  0.0352,  ...,  0.1189,  0.1095,  0.0889],\n",
       "            [-0.0049,  0.0138,  0.0309,  ...,  0.1189,  0.1203,  0.0967],\n",
       "            [ 0.0401,  0.0723,  0.0834,  ...,  0.1189,  0.1128,  0.1001],\n",
       "            ...,\n",
       "            [ 0.5136,  0.5345,  0.5420,  ...,  0.4285,  0.4310,  0.4439],\n",
       "            [ 0.5354,  0.5420,  0.5549,  ...,  0.4374,  0.4310,  0.4439],\n",
       "            [ 0.5504,  0.5485,  0.5474,  ...,  0.4439,  0.4370,  0.4525]]],\n",
       " \n",
       " \n",
       "          [[[-0.3316, -0.3063, -0.2749,  ..., -0.2282, -0.2327, -0.2576],\n",
       "            [-0.3409, -0.3187, -0.3146,  ..., -0.2282, -0.2268, -0.2500],\n",
       "            [-0.3135, -0.2719, -0.2718,  ..., -0.2282, -0.2342, -0.2466],\n",
       "            ...,\n",
       "            [ 0.2624,  0.2742,  0.2656,  ...,  0.1286,  0.1299,  0.1462],\n",
       "            [ 0.2685,  0.2669,  0.2743,  ...,  0.1480,  0.1406,  0.1522],\n",
       "            [ 0.2871,  0.2671,  0.2796,  ...,  0.1597,  0.1529,  0.1672]],\n",
       " \n",
       "           [[-0.3173, -0.3170, -0.2507,  ..., -0.1038, -0.1238, -0.1339],\n",
       "            [-0.2467, -0.2348, -0.2140,  ..., -0.1038, -0.1024, -0.1261],\n",
       "            [-0.1968, -0.1692, -0.1504,  ..., -0.1038, -0.1099, -0.1227],\n",
       "            ...,\n",
       "            [ 0.3627,  0.3748,  0.3660,  ...,  0.2598,  0.2622,  0.2654],\n",
       "            [ 0.3689,  0.3673,  0.3749,  ...,  0.2577,  0.2513,  0.2606],\n",
       "            [ 0.3879,  0.3675,  0.3803,  ...,  0.2577,  0.2507,  0.2663]],\n",
       " \n",
       "           [[-0.1066, -0.0866, -0.0260,  ...,  0.1189,  0.1095,  0.0889],\n",
       "            [-0.0423, -0.0234,  0.0160,  ...,  0.1189,  0.1203,  0.0967],\n",
       "            [ 0.0292,  0.0678,  0.0874,  ...,  0.1189,  0.1128,  0.1001],\n",
       "            ...,\n",
       "            [ 0.5136,  0.5331,  0.5222,  ...,  0.4298,  0.4310,  0.4439],\n",
       "            [ 0.5293,  0.5365,  0.5508,  ...,  0.4386,  0.4310,  0.4439],\n",
       "            [ 0.5473,  0.5422,  0.5407,  ...,  0.4439,  0.4370,  0.4525]]],\n",
       " \n",
       " \n",
       "          [[[-0.3210, -0.5735, -0.5059,  ..., -0.2282, -0.2327, -0.2576],\n",
       "            [-0.3072, -0.3149, -0.4543,  ..., -0.2282, -0.2268, -0.2500],\n",
       "            [-0.2892, -0.2526, -0.2415,  ..., -0.2282, -0.2342, -0.2466],\n",
       "            ...,\n",
       "            [ 0.2931,  0.3105,  0.3054,  ...,  0.1286,  0.1299,  0.1462],\n",
       "            [ 0.2917,  0.3031,  0.3054,  ...,  0.1480,  0.1406,  0.1522],\n",
       "            [ 0.3133,  0.2967,  0.2834,  ...,  0.1597,  0.1529,  0.1672]],\n",
       " \n",
       "           [[-0.3150, -0.9839, -1.2933,  ..., -0.1038, -0.1238, -0.1339],\n",
       "            [-0.2817, -0.4182, -0.9428,  ..., -0.1038, -0.1024, -0.1261],\n",
       "            [-0.2209, -0.2042, -0.2432,  ..., -0.1038, -0.1099, -0.1227],\n",
       "            ...,\n",
       "            [ 0.3969,  0.4118,  0.4066,  ...,  0.2686,  0.2622,  0.2654],\n",
       "            [ 0.3956,  0.4043,  0.4066,  ...,  0.2577,  0.2513,  0.2606],\n",
       "            [ 0.4147,  0.3978,  0.3842,  ...,  0.2577,  0.2507,  0.2663]],\n",
       " \n",
       "           [[-0.1011, -0.7573, -1.0649,  ...,  0.1189,  0.1095,  0.0889],\n",
       "            [-0.0709, -0.1942, -0.7143,  ...,  0.1189,  0.1203,  0.0967],\n",
       "            [ 0.0067,  0.0298, -0.0199,  ...,  0.1189,  0.1128,  0.1001],\n",
       "            ...,\n",
       "            [ 0.5358,  0.5625,  0.5573,  ...,  0.4285,  0.4310,  0.4439],\n",
       "            [ 0.5406,  0.5550,  0.5573,  ...,  0.4374,  0.4310,  0.4439],\n",
       "            [ 0.5654,  0.5485,  0.5350,  ...,  0.4439,  0.4370,  0.4525]]],\n",
       " \n",
       " \n",
       "          ...,\n",
       " \n",
       " \n",
       "          [[[-0.3391, -0.3377, -0.3108,  ..., -0.2282, -0.2327, -0.2576],\n",
       "            [-0.3363, -0.3217, -0.3166,  ..., -0.2282, -0.2268, -0.2500],\n",
       "            [-0.3088, -0.2675, -0.2631,  ..., -0.2282, -0.2342, -0.2466],\n",
       "            ...,\n",
       "            [ 0.2564,  0.2742,  0.2604,  ...,  0.1286,  0.1299,  0.1462],\n",
       "            [ 0.2624,  0.2669,  0.2711,  ...,  0.1480,  0.1406,  0.1522],\n",
       "            [ 0.2709,  0.2624,  0.2642,  ...,  0.1597,  0.1529,  0.1672]],\n",
       " \n",
       "           [[-0.2172, -0.2158, -0.1883,  ..., -0.1038, -0.1238, -0.1339],\n",
       "            [-0.2143, -0.1994, -0.1942,  ..., -0.1038, -0.1024, -0.1261],\n",
       "            [-0.1801, -0.1440, -0.1395,  ..., -0.1038, -0.1099, -0.1227],\n",
       "            ...,\n",
       "            [ 0.3566,  0.3748,  0.3648,  ...,  0.2686,  0.2622,  0.2654],\n",
       "            [ 0.3627,  0.3673,  0.3716,  ...,  0.2577,  0.2513,  0.2606],\n",
       "            [ 0.3714,  0.3627,  0.3645,  ...,  0.2577,  0.2507,  0.2663]],\n",
       " \n",
       "           [[ 0.0014,  0.0074,  0.0347,  ...,  0.1189,  0.1095,  0.0889],\n",
       "            [-0.0143,  0.0237,  0.0289,  ...,  0.1189,  0.1203,  0.0967],\n",
       "            [ 0.0429,  0.0789,  0.0834,  ...,  0.1189,  0.1128,  0.1001],\n",
       "            ...,\n",
       "            [ 0.5213,  0.5410,  0.5367,  ...,  0.4285,  0.4310,  0.4439],\n",
       "            [ 0.5383,  0.5485,  0.5496,  ...,  0.4374,  0.4310,  0.4439],\n",
       "            [ 0.5571,  0.5485,  0.5503,  ...,  0.4439,  0.4370,  0.4525]]],\n",
       " \n",
       " \n",
       "          [[[-0.3391, -0.3377, -0.3108,  ..., -0.2282, -0.2327, -0.2576],\n",
       "            [-0.3363, -0.3217, -0.3166,  ..., -0.2282, -0.2268, -0.2500],\n",
       "            [-0.3088, -0.2675, -0.2631,  ..., -0.2282, -0.2342, -0.2466],\n",
       "            ...,\n",
       "            [ 0.2564,  0.2742,  0.2604,  ...,  0.1286,  0.1299,  0.1462],\n",
       "            [ 0.2624,  0.2669,  0.2711,  ...,  0.1480,  0.1406,  0.1522],\n",
       "            [ 0.2774,  0.2624,  0.2642,  ...,  0.1597,  0.1529,  0.1672]],\n",
       " \n",
       "           [[-0.2172, -0.2158, -0.1883,  ..., -0.1038, -0.1238, -0.1339],\n",
       "            [-0.2143, -0.1994, -0.1942,  ..., -0.1038, -0.1024, -0.1261],\n",
       "            [-0.1801, -0.1440, -0.1395,  ..., -0.1038, -0.1099, -0.1227],\n",
       "            ...,\n",
       "            [ 0.3566,  0.3748,  0.3648,  ...,  0.2686,  0.2622,  0.2654],\n",
       "            [ 0.3627,  0.3673,  0.3716,  ...,  0.2577,  0.2513,  0.2606],\n",
       "            [ 0.3781,  0.3627,  0.3645,  ...,  0.2577,  0.2507,  0.2663]],\n",
       " \n",
       "           [[ 0.0014,  0.0074,  0.0347,  ...,  0.1189,  0.1095,  0.0889],\n",
       "            [-0.0143,  0.0237,  0.0289,  ...,  0.1189,  0.1203,  0.0967],\n",
       "            [ 0.0429,  0.0789,  0.0834,  ...,  0.1189,  0.1128,  0.1001],\n",
       "            ...,\n",
       "            [ 0.5213,  0.5410,  0.5367,  ...,  0.4285,  0.4310,  0.4439],\n",
       "            [ 0.5383,  0.5485,  0.5496,  ...,  0.4374,  0.4310,  0.4439],\n",
       "            [ 0.5637,  0.5485,  0.5503,  ...,  0.4439,  0.4370,  0.4525]]],\n",
       " \n",
       " \n",
       "          [[[-0.3391, -0.3377, -0.3108,  ..., -0.2282, -0.2327, -0.2576],\n",
       "            [-0.3363, -0.3217, -0.3166,  ..., -0.2282, -0.2268, -0.2500],\n",
       "            [-0.3088, -0.2675, -0.2631,  ..., -0.2282, -0.2342, -0.2466],\n",
       "            ...,\n",
       "            [ 0.2564,  0.2742,  0.2604,  ...,  0.1286,  0.1299,  0.1462],\n",
       "            [ 0.2624,  0.2669,  0.2711,  ...,  0.1480,  0.1406,  0.1522],\n",
       "            [ 0.2774,  0.2624,  0.2642,  ...,  0.1597,  0.1529,  0.1672]],\n",
       " \n",
       "           [[-0.2172, -0.2158, -0.1883,  ..., -0.1038, -0.1238, -0.1339],\n",
       "            [-0.2143, -0.1994, -0.1942,  ..., -0.1038, -0.1024, -0.1261],\n",
       "            [-0.1801, -0.1440, -0.1395,  ..., -0.1038, -0.1099, -0.1227],\n",
       "            ...,\n",
       "            [ 0.3566,  0.3748,  0.3648,  ...,  0.2686,  0.2622,  0.2654],\n",
       "            [ 0.3627,  0.3673,  0.3716,  ...,  0.2577,  0.2513,  0.2606],\n",
       "            [ 0.3781,  0.3627,  0.3645,  ...,  0.2577,  0.2507,  0.2663]],\n",
       " \n",
       "           [[ 0.0014,  0.0074,  0.0347,  ...,  0.1189,  0.1095,  0.0889],\n",
       "            [-0.0143,  0.0237,  0.0289,  ...,  0.1189,  0.1203,  0.0967],\n",
       "            [ 0.0429,  0.0789,  0.0834,  ...,  0.1189,  0.1128,  0.1001],\n",
       "            ...,\n",
       "            [ 0.5213,  0.5410,  0.5367,  ...,  0.4285,  0.4310,  0.4439],\n",
       "            [ 0.5383,  0.5485,  0.5496,  ...,  0.4374,  0.4310,  0.4439],\n",
       "            [ 0.5637,  0.5485,  0.5503,  ...,  0.4439,  0.4370,  0.4525]]]],\n",
       " \n",
       " \n",
       " \n",
       "         [[[[-0.3391, -0.3377, -0.3108,  ..., -0.2282, -0.2374, -0.2576],\n",
       "            [-0.3363, -0.3217, -0.3166,  ..., -0.2282, -0.2268, -0.2500],\n",
       "            [-0.3088, -0.2675, -0.2631,  ..., -0.2282, -0.2342, -0.2466],\n",
       "            ...,\n",
       "            [ 0.2564,  0.2698,  0.2624,  ...,  0.1426,  0.1363,  0.1426],\n",
       "            [ 0.2624,  0.2624,  0.2711,  ...,  0.1533,  0.1470,  0.1472],\n",
       "            [ 0.2774,  0.2624,  0.2642,  ...,  0.1475,  0.1529,  0.1585]],\n",
       " \n",
       "           [[-0.2172, -0.2158, -0.1883,  ..., -0.1038, -0.1132, -0.1339],\n",
       "            [-0.2143, -0.1994, -0.1942,  ..., -0.1038, -0.1024, -0.1261],\n",
       "            [-0.1801, -0.1440, -0.1395,  ..., -0.1038, -0.1099, -0.1227],\n",
       "            ...,\n",
       "            [ 0.3566,  0.3703,  0.3627,  ...,  0.2740,  0.2622,  0.2752],\n",
       "            [ 0.3627,  0.3627,  0.3716,  ...,  0.2651,  0.2547,  0.2704],\n",
       "            [ 0.3781,  0.3627,  0.3645,  ...,  0.2581,  0.2562,  0.2589]],\n",
       " \n",
       "           [[ 0.0014,  0.0074,  0.0347,  ...,  0.1189,  0.1095,  0.0889],\n",
       "            [-0.0143,  0.0237,  0.0289,  ...,  0.1189,  0.1203,  0.0967],\n",
       "            [ 0.0429,  0.0789,  0.0834,  ...,  0.1189,  0.1128,  0.1001],\n",
       "            ...,\n",
       "            [ 0.5286,  0.5256,  0.5225,  ...,  0.4427,  0.4310,  0.4439],\n",
       "            [ 0.5456,  0.5399,  0.5443,  ...,  0.4427,  0.4310,  0.4439],\n",
       "            [ 0.5637,  0.5485,  0.5503,  ...,  0.4439,  0.4370,  0.4439]]],\n",
       " \n",
       " \n",
       "          [[[-0.3391, -0.3377, -0.3108,  ..., -0.2282, -0.2374, -0.2576],\n",
       "            [-0.3363, -0.3217, -0.3166,  ..., -0.2282, -0.2268, -0.2500],\n",
       "            [-0.3088, -0.2675, -0.2631,  ..., -0.2282, -0.2342, -0.2466],\n",
       "            ...,\n",
       "            [ 0.2624,  0.2698,  0.2604,  ...,  0.1426,  0.1343,  0.1472],\n",
       "            [ 0.2624,  0.2624,  0.2711,  ...,  0.1553,  0.1450,  0.1426],\n",
       "            [ 0.2774,  0.2624,  0.2642,  ...,  0.1479,  0.1529,  0.1575]],\n",
       " \n",
       "           [[-0.2172, -0.2158, -0.1883,  ..., -0.1038, -0.1132, -0.1339],\n",
       "            [-0.2143, -0.1994, -0.1942,  ..., -0.1038, -0.1024, -0.1261],\n",
       "            [-0.1801, -0.1440, -0.1395,  ..., -0.1038, -0.1099, -0.1227],\n",
       "            ...,\n",
       "            [ 0.3627,  0.3703,  0.3648,  ...,  0.2740,  0.2611,  0.2676],\n",
       "            [ 0.3627,  0.3627,  0.3716,  ...,  0.2651,  0.2502,  0.2676],\n",
       "            [ 0.3781,  0.3627,  0.3645,  ...,  0.2610,  0.2562,  0.2589]],\n",
       " \n",
       "           [[ 0.0014,  0.0074,  0.0347,  ...,  0.1189,  0.1095,  0.0889],\n",
       "            [-0.0143,  0.0237,  0.0289,  ...,  0.1189,  0.1203,  0.0967],\n",
       "            [ 0.0429,  0.0789,  0.0834,  ...,  0.1189,  0.1128,  0.1001],\n",
       "            ...,\n",
       "            [ 0.5286,  0.5324,  0.5225,  ...,  0.4427,  0.4310,  0.4439],\n",
       "            [ 0.5456,  0.5399,  0.5443,  ...,  0.4447,  0.4310,  0.4439],\n",
       "            [ 0.5637,  0.5485,  0.5503,  ...,  0.4319,  0.4417,  0.4439]]],\n",
       " \n",
       " \n",
       "          [[[-0.3391, -0.3377, -0.3108,  ..., -0.2282, -0.2374, -0.2576],\n",
       "            [-0.3363, -0.3217, -0.3166,  ..., -0.2282, -0.2268, -0.2500],\n",
       "            [-0.3088, -0.2675, -0.2631,  ..., -0.2282, -0.2342, -0.2466],\n",
       "            ...,\n",
       "            [ 0.2564,  0.2698,  0.2604,  ...,  0.1414,  0.1343,  0.1472],\n",
       "            [ 0.2624,  0.2624,  0.2711,  ...,  0.1521,  0.1450,  0.1426],\n",
       "            [ 0.2774,  0.2624,  0.2642,  ...,  0.1503,  0.1426,  0.1575]],\n",
       " \n",
       "           [[-0.2172, -0.2158, -0.1883,  ..., -0.1038, -0.1132, -0.1339],\n",
       "            [-0.2143, -0.1994, -0.1942,  ..., -0.1038, -0.1024, -0.1261],\n",
       "            [-0.1801, -0.1440, -0.1395,  ..., -0.1038, -0.1099, -0.1227],\n",
       "            ...,\n",
       "            [ 0.3566,  0.3703,  0.3648,  ...,  0.2740,  0.2611,  0.2704],\n",
       "            [ 0.3627,  0.3627,  0.3716,  ...,  0.2671,  0.2577,  0.2704],\n",
       "            [ 0.3781,  0.3627,  0.3645,  ...,  0.2614,  0.2577,  0.2589]],\n",
       " \n",
       "           [[-0.0091,  0.0074,  0.0347,  ...,  0.1189,  0.1095,  0.0889],\n",
       "            [-0.0238,  0.0237,  0.0289,  ...,  0.1189,  0.1203,  0.0967],\n",
       "            [ 0.0429,  0.0789,  0.0834,  ...,  0.1189,  0.1128,  0.1001],\n",
       "            ...,\n",
       "            [ 0.5286,  0.5324,  0.5225,  ...,  0.4427,  0.4310,  0.4439],\n",
       "            [ 0.5456,  0.5324,  0.5443,  ...,  0.4447,  0.4310,  0.4439],\n",
       "            [ 0.5637,  0.5470,  0.5503,  ...,  0.4472,  0.4370,  0.4439]]],\n",
       " \n",
       " \n",
       "          ...,\n",
       " \n",
       " \n",
       "          [[[-0.3391, -0.3377, -0.3108,  ..., -0.2282, -0.2374, -0.2576],\n",
       "            [-0.3363, -0.3217, -0.3166,  ..., -0.2282, -0.2268, -0.2500],\n",
       "            [-0.3088, -0.2675, -0.2631,  ..., -0.2282, -0.2342, -0.2466],\n",
       "            ...,\n",
       "            [ 0.2588,  0.2698,  0.2624,  ...,  0.1426,  0.1299,  0.1472],\n",
       "            [ 0.2528,  0.2591,  0.2624,  ...,  0.1553,  0.1406,  0.1426],\n",
       "            [ 0.2612,  0.2618,  0.2624,  ...,  0.1479,  0.1529,  0.1575]],\n",
       " \n",
       "           [[-0.2172, -0.2158, -0.1883,  ..., -0.1038, -0.1132, -0.1339],\n",
       "            [-0.2143, -0.1994, -0.1942,  ..., -0.1038, -0.1024, -0.1261],\n",
       "            [-0.1801, -0.1440, -0.1395,  ..., -0.1038, -0.1099, -0.1227],\n",
       "            ...,\n",
       "            [ 0.3591,  0.3703,  0.3627,  ...,  0.2740,  0.2656,  0.2704],\n",
       "            [ 0.3529,  0.3593,  0.3627,  ...,  0.2651,  0.2547,  0.2704],\n",
       "            [ 0.3615,  0.3621,  0.3627,  ...,  0.2581,  0.2562,  0.2589]],\n",
       " \n",
       "           [[ 0.0014,  0.0074,  0.0347,  ...,  0.1189,  0.1095,  0.0889],\n",
       "            [-0.0143,  0.0237,  0.0289,  ...,  0.1189,  0.1203,  0.0967],\n",
       "            [ 0.0429,  0.0789,  0.0834,  ...,  0.1189,  0.1128,  0.1001],\n",
       "            ...,\n",
       "            [ 0.5401,  0.5519,  0.5473,  ...,  0.4427,  0.4310,  0.4439],\n",
       "            [ 0.5387,  0.5410,  0.5473,  ...,  0.4447,  0.4310,  0.4439],\n",
       "            [ 0.5473,  0.5478,  0.5485,  ...,  0.4443,  0.4370,  0.4439]]],\n",
       " \n",
       " \n",
       "          [[[-0.3391, -0.3377, -0.3108,  ..., -0.2282, -0.2374, -0.2576],\n",
       "            [-0.3363, -0.3217, -0.3166,  ..., -0.2282, -0.2268, -0.2500],\n",
       "            [-0.3088, -0.2675, -0.2631,  ..., -0.2282, -0.2342, -0.2466],\n",
       "            ...,\n",
       "            [ 0.2588,  0.2698,  0.2624,  ...,  0.1426,  0.1363,  0.1472],\n",
       "            [ 0.2528,  0.2591,  0.2624,  ...,  0.1553,  0.1470,  0.1426],\n",
       "            [ 0.2612,  0.2618,  0.2624,  ...,  0.1479,  0.1529,  0.1575]],\n",
       " \n",
       "           [[-0.2172, -0.2158, -0.1883,  ..., -0.1038, -0.1132, -0.1339],\n",
       "            [-0.2143, -0.1994, -0.1942,  ..., -0.1038, -0.1024, -0.1261],\n",
       "            [-0.1801, -0.1440, -0.1395,  ..., -0.1038, -0.1099, -0.1227],\n",
       "            ...,\n",
       "            [ 0.3591,  0.3703,  0.3627,  ...,  0.2740,  0.2611,  0.2704],\n",
       "            [ 0.3529,  0.3593,  0.3627,  ...,  0.2651,  0.2502,  0.2704],\n",
       "            [ 0.3615,  0.3621,  0.3627,  ...,  0.2581,  0.2562,  0.2589]],\n",
       " \n",
       "           [[ 0.0014,  0.0074,  0.0347,  ...,  0.1189,  0.1095,  0.0889],\n",
       "            [-0.0143,  0.0237,  0.0289,  ...,  0.1189,  0.1203,  0.0967],\n",
       "            [ 0.0429,  0.0789,  0.0834,  ...,  0.1189,  0.1128,  0.1001],\n",
       "            ...,\n",
       "            [ 0.5448,  0.5560,  0.5485,  ...,  0.4427,  0.4310,  0.4439],\n",
       "            [ 0.5387,  0.5451,  0.5485,  ...,  0.4447,  0.4310,  0.4439],\n",
       "            [ 0.5473,  0.5478,  0.5485,  ...,  0.4443,  0.4370,  0.4439]]],\n",
       " \n",
       " \n",
       "          [[[-0.3391, -0.3377, -0.3108,  ..., -0.2282, -0.2374, -0.2576],\n",
       "            [-0.3363, -0.3217, -0.3166,  ..., -0.2282, -0.2268, -0.2500],\n",
       "            [-0.3088, -0.2675, -0.2631,  ..., -0.2282, -0.2342, -0.2466],\n",
       "            ...,\n",
       "            [ 0.2513,  0.2591,  0.2624,  ...,  0.1426,  0.1299,  0.1472],\n",
       "            [ 0.2500,  0.2591,  0.2711,  ...,  0.1553,  0.1406,  0.1426],\n",
       "            [ 0.2612,  0.2618,  0.2642,  ...,  0.1479,  0.1529,  0.1575]],\n",
       " \n",
       "           [[-0.2172, -0.2158, -0.1883,  ..., -0.1038, -0.1132, -0.1339],\n",
       "            [-0.2143, -0.1994, -0.1942,  ..., -0.1038, -0.1024, -0.1261],\n",
       "            [-0.1801, -0.1440, -0.1395,  ..., -0.1038, -0.1099, -0.1227],\n",
       "            ...,\n",
       "            [ 0.3514,  0.3593,  0.3627,  ...,  0.2740,  0.2622,  0.2704],\n",
       "            [ 0.3500,  0.3593,  0.3716,  ...,  0.2651,  0.2547,  0.2704],\n",
       "            [ 0.3615,  0.3621,  0.3645,  ...,  0.2734,  0.2562,  0.2589]],\n",
       " \n",
       "           [[ 0.0014,  0.0074,  0.0347,  ...,  0.1189,  0.1095,  0.0889],\n",
       "            [-0.0143,  0.0237,  0.0289,  ...,  0.1189,  0.1203,  0.0967],\n",
       "            [ 0.0429,  0.0789,  0.0834,  ...,  0.1189,  0.1128,  0.1001],\n",
       "            ...,\n",
       "            [ 0.5372,  0.5451,  0.5485,  ...,  0.4427,  0.4310,  0.4439],\n",
       "            [ 0.5358,  0.5451,  0.5573,  ...,  0.4447,  0.4310,  0.4439],\n",
       "            [ 0.5473,  0.5478,  0.5503,  ...,  0.4472,  0.4370,  0.4439]]]]]),\n",
       " tensor([0, 0])]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 22, 3, 128, 128])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ntuple(n):\n",
    "    def parse(x):\n",
    "        if isinstance(x, container_abcs.Iterable):\n",
    "            return x\n",
    "        return tuple(repeat(x, n))\n",
    "    return parse\n",
    "to_2tuple = _ntuple(2)\n",
    "\n",
    "def _no_grad_trunc_normal_(tensor, mean, std, a, b):\n",
    "    def norm_cdf(x):\n",
    "        # Computes standard normal cumulative distribution function\n",
    "        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n",
    "\n",
    "    if (mean < a - 2 * std) or (mean > b + 2 * std):\n",
    "        warnings.warn(\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"\n",
    "                      \"The distribution of values may be incorrect.\",\n",
    "                      stacklevel=2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Values are generated by using a truncated uniform distribution and\n",
    "        # then using the inverse CDF for the normal distribution.\n",
    "        # Get upper and lower cdf values\n",
    "        l = norm_cdf((a - mean) / std)\n",
    "        u = norm_cdf((b - mean) / std)\n",
    "\n",
    "        # Uniformly fill tensor with values from [l, u], then translate to\n",
    "        # [2l-1, 2u-1].\n",
    "        tensor.uniform_(2 * l - 1, 2 * u - 1)\n",
    "\n",
    "        # Use inverse cdf transform for normal distribution to get truncated\n",
    "        # standard normal\n",
    "        tensor.erfinv_()\n",
    "\n",
    "        # Transform to proper mean, std\n",
    "        tensor.mul_(std * math.sqrt(2.))\n",
    "        tensor.add_(mean)\n",
    "\n",
    "        # Clamp to ensure it's in the proper range\n",
    "        tensor.clamp_(min=a, max=b)\n",
    "        return tensor\n",
    "    \n",
    "def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n",
    "    # type: (Tensor, float, float, float, float) -> Tensor\n",
    "    r\"\"\"Fills the input Tensor with values drawn from a truncated\n",
    "    normal distribution. The values are effectively drawn from the\n",
    "    normal distribution :math:`\\mathcal{N}(\\text{mean}, \\text{std}^2)`\n",
    "    with values outside :math:`[a, b]` redrawn until they are within\n",
    "    the bounds. The method used for generating the random values works\n",
    "    best when :math:`a \\leq \\text{mean} \\leq b`.\n",
    "    Args:\n",
    "        tensor: an n-dimensional `torch.Tensor`\n",
    "        mean: the mean of the normal distribution\n",
    "        std: the standard deviation of the normal distribution\n",
    "        a: the minimum cutoff value\n",
    "        b: the maximum cutoff value\n",
    "    Examples:\n",
    "        >>> w = torch.empty(3, 5)\n",
    "        >>> nn.init.trunc_normal_(w)\n",
    "    \"\"\"\n",
    "    return _no_grad_trunc_normal_(tensor, mean, std, a, b)\n",
    "\n",
    "def drop_path(x, drop_prob: float = 0., training: bool = False):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n",
    "    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n",
    "    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n",
    "    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n",
    "    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n",
    "    'survival rate' as the argument.\n",
    "    \"\"\"\n",
    "    if drop_prob == 0. or not training:\n",
    "        return x\n",
    "    keep_prob = 1 - drop_prob\n",
    "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
    "    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
    "    random_tensor.floor_()  # binarize\n",
    "    output = x.div(keep_prob) * random_tensor\n",
    "    return output\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
    "    \"\"\"\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training)\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    \"\"\" Image to Patch Embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        img_size = img_size, img_size\n",
    "        patch_size = patch_size, patch_size\n",
    "        num_patches = (img_size[1] // patch_size[1]) * (img_size[0] // patch_size[0])\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, T, H, W = x.shape\n",
    "        x = rearrange(x, 'b c t h w -> (b t) c h w')\n",
    "        x = self.proj(x)\n",
    "        W = x.size(-1)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        return x, T, W\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0., with_qkv=True):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "        self.with_qkv = with_qkv\n",
    "        if self.with_qkv:\n",
    "           self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "           self.proj = nn.Linear(dim, dim)\n",
    "           self.proj_drop = nn.Dropout(proj_drop)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        if self.with_qkv:\n",
    "           qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "           q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        else:\n",
    "           qkv = x.reshape(B, N, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)\n",
    "           q, k, v  = qkv, qkv, qkv\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        if self.with_qkv:\n",
    "           x = self.proj(x)\n",
    "           x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0.1, act_layer=nn.GELU, norm_layer=nn.LayerNorm, attention_type='divided_space_time'):\n",
    "        super().__init__()\n",
    "        self.attention_type = attention_type\n",
    "        assert(attention_type in ['divided_space_time', 'space_only','joint_space_time'])\n",
    "\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = Attention(\n",
    "           dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "\n",
    "        ## Temporal Attention Parameters\n",
    "        if self.attention_type == 'divided_space_time':\n",
    "            self.temporal_norm1 = norm_layer(dim)\n",
    "            self.temporal_attn = Attention(\n",
    "              dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "            self.temporal_fc = nn.Linear(dim, dim)\n",
    "\n",
    "        ## drop path\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "\n",
    "    def forward(self, x, B, T, W):\n",
    "        num_spatial_tokens = (x.size(1) - 1) // T\n",
    "        H = num_spatial_tokens // W\n",
    "\n",
    "        if self.attention_type in ['space_only', 'joint_space_time']:\n",
    "            x = x + self.drop_path(self.attn(self.norm1(x)))\n",
    "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "            return x\n",
    "        elif self.attention_type == 'divided_space_time':\n",
    "            ## Temporal\n",
    "            xt = x # xt = x[:,1:,:]\n",
    "            xt = rearrange(xt, 'b (h w t) m -> (b h w) t m',b=B,h=H,w=W,t=T)\n",
    "            res_temporal = self.drop_path(self.temporal_attn(self.temporal_norm1(xt)))\n",
    "            res_temporal = rearrange(res_temporal, '(b h w) t m -> b (h w t) m',b=B,h=H,w=W,t=T)\n",
    "            res_temporal = self.temporal_fc(res_temporal)\n",
    "            xt = x + res_temporal # xt = x[:,1:,:] + res_temporal\n",
    "\n",
    "            ## Spatial\n",
    "            # init_cls_token = x[:,0,:].unsqueeze(1)\n",
    "            # cls_token = init_cls_token.repeat(1, T, 1)\n",
    "            # cls_token = rearrange(cls_token, 'b t m -> (b t) m',b=B,t=T).unsqueeze(1)\n",
    "            xs = xt\n",
    "            xs = rearrange(xs, 'b (h w t) m -> (b t) (h w) m',b=B,h=H,w=W,t=T)\n",
    "            # xs = torch.cat((cls_token, xs), 1)\n",
    "            res_spatial = self.drop_path(self.attn(self.norm1(xs)))\n",
    "\n",
    "            ### Taking care of CLS token\n",
    "            # cls_token = res_spatial[:,0,:]\n",
    "            # cls_token = rearrange(cls_token, '(b t) m -> b t m',b=B,t=T)\n",
    "            # cls_token = torch.mean(cls_token,1,True) ## averaging for every frame\n",
    "            # res_spatial = res_spatial[:,1:,:]\n",
    "            res_spatial = rearrange(res_spatial, '(b t) (h w) m -> b (h w t) m',b=B,h=H,w=W,t=T)\n",
    "            res = res_spatial\n",
    "            x = xt\n",
    "\n",
    "            ## Mlp\n",
    "            x = x + res # x = torch.cat((init_cls_token, x), 1) + torch.cat((cls_token, res), 1)\n",
    "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionTransformer(nn.Module):\n",
    "    \"\"\" Vision Transformere\n",
    "    \"\"\"\n",
    "    # def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000, embed_dim=768, depth=12,\n",
    "    #              num_heads=12, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop_rate=0., attn_drop_rate=0.,\n",
    "    #              drop_path_rate=0.1, hybrid_backbone=None, norm_layer=nn.LayerNorm, num_frames=8, attention_type='divided_space_time', dropout=0.):\n",
    "    def __init__(self, embed_dim=768, depth=12,\n",
    "                    num_heads=12, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop_rate=0., attn_drop_rate=0.,\n",
    "                  drop_path_rate=0.1, hybrid_backbone=None, norm_layer=nn.LayerNorm, num_frames=8, attention_type='divided_space_time', dropout=0.):\n",
    "        super().__init__()\n",
    "        self.attention_type = attention_type\n",
    "        self.depth = depth\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # self.num_classes = num_classes\n",
    "        self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n",
    "        # self.patch_embed = PatchEmbed(\n",
    "        #     img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        # num_patches = self.patch_embed.num_patches\n",
    "\n",
    "        ## Positional Embeddings\n",
    "        # self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        # self.pos_embed = nn.Parameter(torch.zeros(1, num_patches+1, embed_dim))\n",
    "        # self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "        # if self.attention_type != 'space_only':\n",
    "        #     self.time_embed = nn.Parameter(torch.zeros(1, num_frames, embed_dim))\n",
    "        #     self.time_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        ## Attention Blocks\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, self.depth)]  # stochastic depth decay rule\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(\n",
    "                dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=norm_layer, attention_type=self.attention_type)\n",
    "            for i in range(self.depth)])\n",
    "        self.norm = norm_layer(embed_dim)\n",
    "\n",
    "        # Classifier head\n",
    "        # self.head = nn.Linear(embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "        # trunc_normal_(self.pos_embed, std=.02)\n",
    "        # trunc_normal_(self.cls_token, std=.02)\n",
    "        # self.apply(self._init_weights)\n",
    "\n",
    "        ## initialization of temporal attention weights\n",
    "        if self.attention_type == 'divided_space_time':\n",
    "            i = 0\n",
    "            for m in self.blocks.modules():\n",
    "                m_str = str(m)\n",
    "                if 'Block' in m_str:\n",
    "                    if i > 0:\n",
    "                      nn.init.constant_(m.temporal_fc.weight, 0)\n",
    "                      nn.init.constant_(m.temporal_fc.bias, 0)\n",
    "                    i += 1\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    # @torch.jit.ignore\n",
    "    # def no_weight_decay(self):\n",
    "    #     return {'pos_embed', 'cls_token', 'time_embed'}\n",
    "\n",
    "    # def get_classifier(self):\n",
    "    #     return self.head\n",
    "\n",
    "    # def reset_classifier(self, num_classes, global_pool=''):\n",
    "    #     self.num_classes = num_classes\n",
    "    #     self.head = nn.Linear(self.embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        # B = x.shape[0]\n",
    "        # x, T, W = self.patch_embed(x)\n",
    "        # cls_tokens = self.cls_token.expand(x.size(0), -1, -1)\n",
    "        # x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        # ## resizing the positional embeddings in case they don't match the input at inference\n",
    "        # if x.size(1) != self.pos_embed.size(1):\n",
    "        #     pos_embed = self.pos_embed\n",
    "        #     cls_pos_embed = pos_embed[0,0,:].unsqueeze(0).unsqueeze(1)\n",
    "        #     other_pos_embed = pos_embed[0,1:,:].unsqueeze(0).transpose(1, 2)\n",
    "        #     P = int(other_pos_embed.size(2) ** 0.5)\n",
    "        #     H = x.size(1) // W\n",
    "        #     other_pos_embed = other_pos_embed.reshape(1, x.size(2), P, P)\n",
    "        #     new_pos_embed = F.interpolate(other_pos_embed, size=(H, W), mode='nearest')\n",
    "        #     new_pos_embed = new_pos_embed.flatten(2)\n",
    "        #     new_pos_embed = new_pos_embed.transpose(1, 2)\n",
    "        #     new_pos_embed = torch.cat((cls_pos_embed, new_pos_embed), 1)\n",
    "        #     x = x + new_pos_embed\n",
    "        # else:\n",
    "        #     x = x + self.pos_embed\n",
    "        # x = self.pos_drop(x)\n",
    "\n",
    "\n",
    "        # ## Time Embeddings\n",
    "        # if self.attention_type != 'space_only':\n",
    "        #     cls_tokens = x[:B, 0, :].unsqueeze(1)\n",
    "        #     x = x[:,1:]\n",
    "        #     x = rearrange(x, '(b t) n m -> (b n) t m',b=B,t=T)\n",
    "        #     ## Resizing time embeddings in case they don't match\n",
    "        #     if T != self.time_embed.size(1):\n",
    "        #         time_embed = self.time_embed.transpose(1, 2)\n",
    "        #         new_time_embed = F.interpolate(time_embed, size=(T), mode='nearest')\n",
    "        #         new_time_embed = new_time_embed.transpose(1, 2)\n",
    "        #         x = x + new_time_embed\n",
    "        #     else:\n",
    "        #         x = x + self.time_embed\n",
    "        #     x = self.time_drop(x)\n",
    "        #     x = rearrange(x, '(b n) t m -> b (n t) m',b=B,t=T)\n",
    "        #     x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        ## Attention blocks\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x, B, T, W)\n",
    "\n",
    "        ### Predictions for space-only baseline\n",
    "        if self.attention_type == 'space_only':\n",
    "            x = rearrange(x, '(b t) n m -> b t n m',b=B,t=T)\n",
    "            x = torch.mean(x, 1) # averaging predictions for every frame\n",
    "\n",
    "        x = self.norm(x)\n",
    "        \n",
    "        # return x[:, 0]\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        # x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IJEPA_base(nn.Module):\n",
    "    # def __init__(self, img_size, patch_size, in_chans, embed_dim,\n",
    "    #              enc_depth, pred_depth, num_heads,\n",
    "    #              post_emb_norm=False, M = 4, mode=\"train\", layer_dropout=0., drop_rate=0.):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768, enc_depth=12, pred_depth=12, num_heads=12,\n",
    "                  mlp_ratio=4., qkv_bias=False, qk_scale=None, drop_rate=0., attn_drop_rate=0.,\n",
    "                 drop_path_rate=0.1, hybrid_backbone=None, norm_layer=nn.LayerNorm, num_frames=8, attention_type='divided_space_time', dropout=0.,\n",
    "                 mode=\"train\"):\n",
    "        super().__init__()\n",
    "        # self.M = M\n",
    "        self.mode = mode\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # #define the patch embedding and positional embedding\n",
    "        # self.patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        # self.patch_dim  = (self.patch_embed.patch_shape[0], self.patch_embed.patch_shape[1])\n",
    "        # self.num_tokens = self.patch_embed.patch_shape[0] * self.patch_embed.patch_shape[1]\n",
    "        # self.pos_embedding = nn.Parameter(torch.randn(1, self.num_tokens, embed_dim))\n",
    "\n",
    "        #define the cls and mask tokens\n",
    "        self.mask_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
    "        nn.init.trunc_normal_(self.mask_token, 0.02)\n",
    "\n",
    "        # #define the encoder and decoder, as well as the layer normalization and dropout\n",
    "        # self.post_emb_norm = nn.LayerNorm(embed_dim) if post_emb_norm else nn.Identity()\n",
    "        # self.norm = nn.LayerNorm(embed_dim)\n",
    "        # self.teacher_encoder = Encoder(\n",
    "        #     dim=embed_dim,\n",
    "        #     heads=num_heads,\n",
    "        #     depth=enc_depth, \n",
    "        #     layer_dropout=self.layer_dropout,\n",
    "        # )  \n",
    "        # self.student_encoder = copy.deepcopy(self.teacher_encoder).cuda()\n",
    "\n",
    "        # self.predictor = Predictor(embed_dim, num_heads, pred_depth)\n",
    "\n",
    "        ####\n",
    "\n",
    "        self.norm_layer = norm_layer\n",
    "\n",
    "        self.attention_type = attention_type\n",
    "\n",
    "        self.patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "        \n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim)) # self.pos_embed = nn.Parameter(torch.zeros(1, num_patches+1, embed_dim))\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        if self.attention_type != 'space_only':\n",
    "            self.time_embed = nn.Parameter(torch.zeros(1, num_frames, embed_dim))\n",
    "            self.time_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        self.teacher_encoder = VisionTransformer(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            depth=enc_depth, \n",
    "            dropout=self.dropout,\n",
    "            norm_layer=self.norm_layer\n",
    "        )\n",
    "\n",
    "        self.student_encoder = copy.deepcopy(self.teacher_encoder).cpu()\n",
    "        self.predictor = VisionTransformer(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            depth=enc_depth, \n",
    "            dropout=self.dropout,\n",
    "            norm_layer=self.norm_layer\n",
    "        )\n",
    "        \n",
    "\n",
    "    @torch.no_grad() \n",
    "    def get_target_block(self, target_encoder, x, patch_dim, aspect_ratio, scale, M):  \n",
    "        #get the target block\n",
    "        target_encoder = target_encoder.eval()\n",
    "        x = target_encoder(x)\n",
    "        x = self.norm(x)\n",
    "        #get the patch dimensions\n",
    "        patch_h, patch_w = patch_dim\n",
    "        #get the number of patches\n",
    "        num_patches = patch_h * patch_w\n",
    "        #get the number of patches in the target block\n",
    "        num_patches_block = int(patch_h * patch_w * scale)\n",
    "        #get the height and width of the target block with aspect ratio\n",
    "        block_h = int(torch.sqrt(torch.tensor(num_patches_block / aspect_ratio)))\n",
    "        block_w = int(aspect_ratio * block_h)\n",
    "        #get the patches in the target block\n",
    "        target_block = torch.zeros((M, x.shape[0], block_h*block_w, x.shape[2]))\n",
    "        target_patches = []\n",
    "        all_patches = []\n",
    "        for z in range(M):\n",
    "            #get the starting patch\n",
    "            start_patch_h = torch.randint(0, patch_h - block_h+1, (1,)).item()\n",
    "            start_patch_w = torch.randint(0, patch_w - block_w+1, (1,)).item()\n",
    "            start_patch = start_patch_h * patch_w + start_patch_w\n",
    "\n",
    "            patches = []\n",
    "            #get the patches in the target block\n",
    "            for i in range(block_h):\n",
    "                for j in range(block_w):\n",
    "                    patches.append(start_patch + i * patch_w + j)\n",
    "                    if start_patch + i * patch_w + j not in all_patches:\n",
    "                        all_patches.append(start_patch + i * patch_w + j)\n",
    "                    \n",
    "            #get the target block\n",
    "            target_patches.append(patches)\n",
    "            target_block[z] = x[:, patches, :]\n",
    "        return target_block.cuda(), target_patches, all_patches\n",
    "\n",
    "    def get_context_block(self, x, patch_dim, aspect_ratio, scale, target_patches):\n",
    "        patch_h, patch_w = patch_dim\n",
    "        #get the number of patches in the target block\n",
    "        num_patches_block = int(patch_h * patch_w * scale)\n",
    "        #get the height and width of the target block with aspect ratio\n",
    "        block_h = int(torch.sqrt(torch.tensor(num_patches_block / aspect_ratio)))\n",
    "        block_w = int(aspect_ratio * block_h)\n",
    "        #get the starting patch\n",
    "        start_patch_h = torch.randint(0, patch_h - block_h+1, (1,)).item()\n",
    "        start_patch_w = torch.randint(0, patch_w - block_w+1, (1,)).item()\n",
    "        start_patch = start_patch_h * patch_w + start_patch_w\n",
    "        #get the patches in the context_block\n",
    "        patches = []\n",
    "        for i in range(block_h):\n",
    "            for j in range(block_w):\n",
    "                if start_patch + i * patch_w + j not in target_patches: #remove the target patches\n",
    "                    patches.append(start_patch + i * patch_w + j)\n",
    "        return x[:, patches, :]\n",
    "    \n",
    "    def get_patch_embeddings(self, x):\n",
    "        B = x.shape[0]\n",
    "        x, T, W = self.patch_embed(x)\n",
    "        print(x.shape)\n",
    "        print(self.pos_embed.shape)\n",
    "        print(self.patch_embed.num_patches)\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        if self.attention_type != 'space_only':\n",
    "            x = rearrange(x, '(b t) n m -> (b n) t m',b=B,t=T)\n",
    "            if T != self.time_embed.size(1):\n",
    "                time_embed = self.time_embed.transpose(1, 2)\n",
    "                new_time_embed = F.interpolate(time_embed, size=(T), mode='nearest')\n",
    "                new_time_embed = new_time_embed.transpose(1, 2)\n",
    "                x = x + new_time_embed\n",
    "            else:\n",
    "                x = x + self.time_embed\n",
    "            x = self.time_drop(x)\n",
    "            x = rearrange(x, '(b n) t m -> b (n t) m',b=B,t=T)\n",
    "            \n",
    "        return x\n",
    "\n",
    "\n",
    "    def forward(self, x, target_aspect_ratio=1, target_scale=1, context_aspect_ratio=1, context_scale=1):\n",
    "        #get the patch embeddings\n",
    "        B = x.shape[0]\n",
    "        x, T, W = self.patch_embed(x)\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        if self.attention_type != 'space_only':\n",
    "            x = rearrange(x, '(b t) n m -> (b n) t m',b=B,t=T)\n",
    "            if T != self.time_embed.size(1):\n",
    "                time_embed = self.time_embed.transpose(1, 2)\n",
    "                new_time_embed = F.interpolate(time_embed, size=(T), mode='nearest')\n",
    "                new_time_embed = new_time_embed.transpose(1, 2)\n",
    "                x = x + new_time_embed\n",
    "            else:\n",
    "                x = x + self.time_embed\n",
    "            x = self.time_drop(x)\n",
    "            x = rearrange(x, '(b n) t m -> b (n t) m',b=B,t=T)\n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "        # b, n, e = x.shape\n",
    "        # x = x + self.pos_embedding[:, :n]\n",
    "        # #add the positional embeddings\n",
    "        # x = x + self.pos_embedding\n",
    "        # #normalize the embeddings\n",
    "        # x = self.post_emb_norm(x)\n",
    "\n",
    "\n",
    "        #if mode is test, we get return full embedding:\n",
    "        if self.mode == 'test':\n",
    "            return self.student_encoder(x)\n",
    "        # #get target embeddings\n",
    "        target_blocks, target_patches, all_patches = self.get_target_block(self.teacher_encoder, x, self.patch_dim, target_aspect_ratio, target_scale, self.M)\n",
    "        m, b, n, e = target_blocks.shape\n",
    "        #get context embedding\n",
    "\n",
    "        context_block = self.get_context_block(x, self.patch_dim, context_aspect_ratio, context_scale, all_patches)\n",
    "        context_encoding = self.student_encoder(context_block)\n",
    "        context_encoding = self.norm(context_encoding)\n",
    "\n",
    "\n",
    "        prediction_blocks = torch.zeros((m, b, n, e)).cpu()\n",
    "        #get the prediction blocks, predict each target block separately\n",
    "        for i in range(m):\n",
    "            target_masks = self.mask_token.repeat(b, n, 1)\n",
    "            target_pos_embedding = self.pos_embedding[:, target_patches[i], :]\n",
    "            target_masks = target_masks + target_pos_embedding\n",
    "            prediction_blocks[i] = self.predictor(context_encoding, target_masks)\n",
    "\n",
    "        return prediction_blocks, target_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 3, 128, 128])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IJEPA_base(img_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([44, 64, 768])\n",
      "torch.Size([1, 64, 768])\n",
      "64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1408, 768])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_patch_embeddings(data.transpose(1, 2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 22, 299, 299])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.transpose(1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 65, 2])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1, 64+1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
