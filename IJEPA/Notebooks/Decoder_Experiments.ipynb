{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iuwurgcxfiRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31398ff8-7c18-4af7-a95d-d383b960f40b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import imageio.v3 as iio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "!pip install torchmetrics\n",
        "import torchmetrics\n",
        "\n",
        "!pip install einops\n",
        "import einops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1PHlqeEjte_ZvBdnpFAZiQXaaycqb5Ul1\n",
        "#!mv Dataset_Student_annot_copy.zip Dataset_Student_annot.zip\n",
        "!unzip Dataset_Student_annot.zip\n",
        "#https://drive.google.com/file/d/1lWTIkjK53YfXHy8HoOH4spNyvAEiDxI2/view?usp=share_link\n",
        "#https://drive.google.com/file/d/1PHlqeEjte_ZvBdnpFAZiQXaaycqb5Ul1/view?usp=share_link non copy version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQyigSZEGUxi",
        "outputId": "6d92f443-7970-4146-dd75-f438af1d37d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PHlqeEjte_ZvBdnpFAZiQXaaycqb5Ul1\n",
            "To: /content/Dataset_Student_annot.zip\n",
            " 14% 1.39G/10.1G [00:09<00:50, 172MB/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "7K3pbtqjF4Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os.path\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "from typing import List, Union, Tuple, Any\n",
        "\n",
        "\n",
        "class VideoRecord(object):\n",
        "    \"\"\"\n",
        "    Helper class for class VideoFrameDataset. This class\n",
        "    represents a video sample's metadata.\n",
        "\n",
        "    Args:\n",
        "        root_datapath: the system path to the root folder\n",
        "                       of the videos.\n",
        "        row: A list with four or more elements where 1) The first\n",
        "             element is the path to the video sample's frames excluding\n",
        "             the root_datapath prefix 2) The  second element is the starting frame id of the video\n",
        "             3) The third element is the inclusive ending frame id of the video\n",
        "             4) The fourth element is the label index.\n",
        "             5) any following elements are labels in the case of multi-label classification\n",
        "    \"\"\"\n",
        "    def __init__(self, row, root_datapath):\n",
        "        self._data = row\n",
        "        self._path = os.path.join(root_datapath, row[0])\n",
        "\n",
        "\n",
        "    @property\n",
        "    def path(self) -> str:\n",
        "        return self._path\n",
        "\n",
        "    @property\n",
        "    def num_frames(self) -> int:\n",
        "        return self.end_frame - self.start_frame + 1  # +1 because end frame is inclusive\n",
        "    @property\n",
        "    def start_frame(self) -> int:\n",
        "        return int(self._data[1])\n",
        "\n",
        "    @property\n",
        "    def end_frame(self) -> int:\n",
        "        return int(self._data[2])\n",
        "\n",
        "    @property\n",
        "    def label(self) -> Union[int, List[int]]:\n",
        "        # just one label_id\n",
        "        if len(self._data) == 4:\n",
        "            return int(self._data[3])\n",
        "        # sample associated with multiple labels\n",
        "        else:\n",
        "            return [int(label_id) for label_id in self._data[3:]]\n",
        "\n",
        "class VideoFrameDataset(torch.utils.data.Dataset):\n",
        "    r\"\"\"\n",
        "    A highly efficient and adaptable dataset class for videos.\n",
        "    Instead of loading every frame of a video,\n",
        "    loads x RGB frames of a video (sparse temporal sampling) and evenly\n",
        "    chooses those frames from start to end of the video, returning\n",
        "    a list of x PIL images or ``FRAMES x CHANNELS x HEIGHT x WIDTH``\n",
        "    tensors where FRAMES=x if the ``ImglistToTensor()``\n",
        "    transform is used.\n",
        "\n",
        "    More specifically, the frame range [START_FRAME, END_FRAME] is divided into NUM_SEGMENTS\n",
        "    segments and FRAMES_PER_SEGMENT consecutive frames are taken from each segment.\n",
        "\n",
        "    Note:\n",
        "        A demonstration of using this class can be seen\n",
        "        in ``demo.py``\n",
        "        https://github.com/RaivoKoot/Video-Dataset-Loading-Pytorch\n",
        "\n",
        "    Note:\n",
        "        This dataset broadly corresponds to the frame sampling technique\n",
        "        introduced in ``Temporal Segment Networks`` at ECCV2016\n",
        "        https://arxiv.org/abs/1608.00859.\n",
        "\n",
        "\n",
        "    Note:\n",
        "        This class relies on receiving video data in a structure where\n",
        "        inside a ``ROOT_DATA`` folder, each video lies in its own folder,\n",
        "        where each video folder contains the frames of the video as\n",
        "        individual files with a naming convention such as\n",
        "        img_001.jpg ... img_059.jpg.\n",
        "        For enumeration and annotations, this class expects to receive\n",
        "        the path to a .txt file where each video sample has a row with four\n",
        "        (or more in the case of multi-label, see README on Github)\n",
        "        space separated values:\n",
        "        ``VIDEO_FOLDER_PATH     START_FRAME      END_FRAME      LABEL_INDEX``.\n",
        "        ``VIDEO_FOLDER_PATH`` is expected to be the path of a video folder\n",
        "        excluding the ``ROOT_DATA`` prefix. For example, ``ROOT_DATA`` might\n",
        "        be ``home\\data\\datasetxyz\\videos\\``, inside of which a ``VIDEO_FOLDER_PATH``\n",
        "        might be ``jumping\\0052\\`` or ``sample1\\`` or ``00053\\``.\n",
        "\n",
        "    Args:\n",
        "        root_path: The root path in which video folders lie.\n",
        "                   this is ROOT_DATA from the description above.\n",
        "        annotationfile_path: The .txt annotation file containing\n",
        "                             one row per video sample as described above.\n",
        "        num_segments: The number of segments the video should\n",
        "                      be divided into to sample frames from.\n",
        "        frames_per_segment: The number of frames that should\n",
        "                            be loaded per segment. For each segment's\n",
        "                            frame-range, a random start index or the\n",
        "                            center is chosen, from which frames_per_segment\n",
        "                            consecutive frames are loaded.\n",
        "        imagefile_template: The image filename template that video frame files\n",
        "                            have inside of their video folders as described above.\n",
        "        transform: Transform pipeline that receives a list of PIL images/frames.\n",
        "        test_mode: If True, frames are taken from the center of each\n",
        "                   segment, instead of a random location in each segment.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 root_path: str,\n",
        "                 annotationfile_path: str,\n",
        "                 num_segments: int = 3,\n",
        "                 frames_per_segment: int = 1,\n",
        "                 imagefile_template: str='image_{:d}.png',\n",
        "                 transform = None,\n",
        "                 mask: bool =False,\n",
        "                 mask_template: str='mask.npy',\n",
        "                 test_mode: bool = False):\n",
        "        super(VideoFrameDataset, self).__init__()\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.annotationfile_path = annotationfile_path\n",
        "        self.num_segments = num_segments\n",
        "        self.frames_per_segment = frames_per_segment\n",
        "        self.imagefile_template = imagefile_template\n",
        "        self.transform = transform\n",
        "        self.mask = mask\n",
        "        self.mask_template = mask_template\n",
        "        self.test_mode = test_mode\n",
        "\n",
        "        self._parse_annotationfile()\n",
        "        self._sanity_check_samples()\n",
        "\n",
        "    def _load_image(self, directory: str, idx: int) -> Image.Image:\n",
        "        return Image.open(os.path.join(directory, self.imagefile_template.format(idx))).convert('RGB')\n",
        "    \n",
        "    def _load_mask(self, directory: str) -> torch.Tensor:\n",
        "        return torch.Tensor(np.load(os.path.join(directory, self.mask_template)))\n",
        "\n",
        "    def _parse_annotationfile(self):\n",
        "        self.video_list = [VideoRecord(x.strip().split(), self.root_path) for x in open(self.annotationfile_path)]\n",
        "\n",
        "    def _sanity_check_samples(self):\n",
        "        for record in self.video_list:\n",
        "            if record.num_frames <= 0 or record.start_frame == record.end_frame:\n",
        "                print(f\"\\nDataset Warning: video {record.path} seems to have zero RGB frames on disk!\\n\")\n",
        "\n",
        "            elif record.num_frames < (self.num_segments * self.frames_per_segment):\n",
        "                print(f\"\\nDataset Warning: video {record.path} has {record.num_frames} frames \"\n",
        "                      f\"but the dataloader is set up to load \"\n",
        "                      f\"(num_segments={self.num_segments})*(frames_per_segment={self.frames_per_segment})\"\n",
        "                      f\"={self.num_segments * self.frames_per_segment} frames. Dataloader will throw an \"\n",
        "                      f\"error when trying to load this video.\\n\")\n",
        "\n",
        "    def _get_start_indices(self, record: VideoRecord) -> 'np.ndarray[int]':\n",
        "        \"\"\"\n",
        "        For each segment, choose a start index from where frames\n",
        "        are to be loaded from.\n",
        "\n",
        "        Args:\n",
        "            record: VideoRecord denoting a video sample.\n",
        "        Returns:\n",
        "            List of indices of where the frames of each\n",
        "            segment are to be loaded from.\n",
        "        \"\"\"\n",
        "        # choose start indices that are perfectly evenly spread across the video frames.\n",
        "        if self.test_mode:\n",
        "            distance_between_indices = (record.num_frames - self.frames_per_segment + 1) / float(self.num_segments)\n",
        "\n",
        "            start_indices = np.array([int(distance_between_indices / 2.0 + distance_between_indices * x)\n",
        "                                      for x in range(self.num_segments)])\n",
        "        # randomly sample start indices that are approximately evenly spread across the video frames.\n",
        "        else:\n",
        "            max_valid_start_index = (record.num_frames - self.frames_per_segment + 1) // self.num_segments\n",
        "\n",
        "            start_indices = np.multiply(list(range(self.num_segments)), max_valid_start_index) + \\\n",
        "                      np.random.randint(max_valid_start_index, size=self.num_segments)\n",
        "\n",
        "        return start_indices\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Union[\n",
        "        Tuple[List[Image.Image], Union[int, List[int]]],\n",
        "        Tuple['torch.Tensor[num_frames, channels, height, width]', Union[int, List[int]]],\n",
        "        Tuple[Any, Union[int, List[int]]],\n",
        "        ]:\n",
        "        \"\"\"\n",
        "        For video with id idx, loads self.NUM_SEGMENTS * self.FRAMES_PER_SEGMENT\n",
        "        frames from evenly chosen locations across the video.\n",
        "\n",
        "        Args:\n",
        "            idx: Video sample index.\n",
        "        Returns:\n",
        "            A tuple of (video, label). Label is either a single\n",
        "            integer or a list of integers in the case of multiple labels.\n",
        "            Video is either 1) a list of PIL images if no transform is used\n",
        "            2) a batch of shape (NUM_IMAGES x CHANNELS x HEIGHT x WIDTH) in the range [0,1]\n",
        "            if the transform \"ImglistToTensor\" is used\n",
        "            3) or anything else if a custom transform is used.\n",
        "        \"\"\"\n",
        "        record: VideoRecord = self.video_list[idx]\n",
        "\n",
        "        frame_start_indices: 'np.ndarray[int]' = self._get_start_indices(record)\n",
        "\n",
        "        return self._get(record, frame_start_indices)\n",
        "\n",
        "    def _get(self, record: VideoRecord, frame_start_indices: 'np.ndarray[int]') -> Union[\n",
        "        Tuple[List[Image.Image], Union[int, List[int]]],\n",
        "        Tuple['torch.Tensor[num_frames, channels, height, width]', Union[int, List[int]]],\n",
        "        Tuple[Any, Union[int, List[int]]],\n",
        "        ]:\n",
        "        \"\"\"\n",
        "        Loads the frames of a video at the corresponding\n",
        "        indices.\n",
        "\n",
        "        Args:\n",
        "            record: VideoRecord denoting a video sample.\n",
        "            frame_start_indices: Indices from which to load consecutive frames from.\n",
        "        Returns:\n",
        "            A tuple of (video, label). Label is either a single\n",
        "            integer or a list of integers in the case of multiple labels.\n",
        "            Video is either 1) a list of PIL images if no transform is used\n",
        "            2) a batch of shape (NUM_IMAGES x CHANNELS x HEIGHT x WIDTH) in the range [0,1]\n",
        "            if the transform \"ImglistToTensor\" is used\n",
        "            3) or anything else if a custom transform is used.\n",
        "        \"\"\"\n",
        "\n",
        "        frame_start_indices = frame_start_indices + record.start_frame\n",
        "        images = list()\n",
        "\n",
        "        # from each start_index, load self.frames_per_segment\n",
        "        # consecutive frames\n",
        "        for start_index in frame_start_indices:\n",
        "            frame_index = int(start_index)\n",
        "\n",
        "            # load self.frames_per_segment consecutive frames\n",
        "            for _ in range(self.frames_per_segment):\n",
        "                image = self._load_image(record.path, frame_index)\n",
        "                images.append(image)\n",
        "\n",
        "                if frame_index < record.end_frame:\n",
        "                    frame_index += 1\n",
        "\n",
        "        if self.transform is not None:\n",
        "            images = self.transform(images)\n",
        "\n",
        "        if self.mask:\n",
        "            mask = self._load_mask(record.path)\n",
        "            return images, record.label, mask\n",
        "\n",
        "        return images, record.label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.video_list)\n",
        "\n",
        "class ImglistToTensor(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Converts a list of PIL images in the range [0,255] to a torch.FloatTensor\n",
        "    of shape (NUM_IMAGES x CHANNELS x HEIGHT x WIDTH) in the range [0,1].\n",
        "    Can be used as first transform for ``VideoFrameDataset``.\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def forward(img_list: List[Image.Image]) -> 'torch.Tensor[NUM_IMAGES, CHANNELS, HEIGHT, WIDTH]':\n",
        "        \"\"\"\n",
        "        Converts each PIL image in a list to\n",
        "        a torch Tensor and stacks them into\n",
        "        a single tensor.\n",
        "\n",
        "        Args:\n",
        "            img_list: list of PIL images.\n",
        "        Returns:\n",
        "            tensor of size ``NUM_IMAGES x CHANNELS x HEIGHT x WIDTH``\n",
        "        \"\"\"\n",
        "        return torch.stack([transforms.functional.to_tensor(pic) for pic in img_list])"
      ],
      "metadata": {
        "id": "-MVbXJMZHIJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## IJEPA Model\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from einops import rearrange\n",
        "import numpy as np\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "\n",
        "\n",
        "def _no_grad_trunc_normal_(tensor, mean, std, a, b):\n",
        "    def norm_cdf(x):\n",
        "        # Computes standard normal cumulative distribution function\n",
        "        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n",
        "\n",
        "    if (mean < a - 2 * std) or (mean > b + 2 * std):\n",
        "        warnings.warn(\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"\n",
        "                      \"The distribution of values may be incorrect.\",\n",
        "                      stacklevel=2)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Values are generated by using a truncated uniform distribution and\n",
        "        # then using the inverse CDF for the normal distribution.\n",
        "        # Get upper and lower cdf values\n",
        "        l = norm_cdf((a - mean) / std)\n",
        "        u = norm_cdf((b - mean) / std)\n",
        "\n",
        "        # Uniformly fill tensor with values from [l, u], then translate to\n",
        "        # [2l-1, 2u-1].\n",
        "        tensor.uniform_(2 * l - 1, 2 * u - 1)\n",
        "\n",
        "        # Use inverse cdf transform for normal distribution to get truncated\n",
        "        # standard normal\n",
        "        tensor.erfinv_()\n",
        "\n",
        "        # Transform to proper mean, std\n",
        "        tensor.mul_(std * math.sqrt(2.))\n",
        "        tensor.add_(mean)\n",
        "\n",
        "        # Clamp to ensure it's in the proper range\n",
        "        tensor.clamp_(min=a, max=b)\n",
        "        return tensor\n",
        "\n",
        " \n",
        "def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n",
        "    # type: (Tensor, float, float, float, float) -> Tensor\n",
        "    r\"\"\"Fills the input Tensor with values drawn from a truncated\n",
        "    normal distribution. The values are effectively drawn from the\n",
        "    normal distribution :math:`\\mathcal{N}(\\text{mean}, \\text{std}^2)`\n",
        "    with values outside :math:`[a, b]` redrawn until they are within\n",
        "    the bounds. The method used for generating the random values works\n",
        "    best when :math:`a \\leq \\text{mean} \\leq b`.\n",
        "    Args:\n",
        "        tensor: an n-dimensional `torch.Tensor`\n",
        "        mean: the mean of the normal distribution\n",
        "        std: the standard deviation of the normal distribution\n",
        "        a: the minimum cutoff value\n",
        "        b: the maximum cutoff value\n",
        "    Examples:\n",
        "        >>> w = torch.empty(3, 5)\n",
        "        >>> nn.init.trunc_normal_(w)\n",
        "    \"\"\"\n",
        "    return _no_grad_trunc_normal_(tensor, mean, std, a, b)\n",
        "\n",
        "\n",
        "def drop_path(x, drop_prob: float = 0., training: bool = False):\n",
        "    \"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n",
        "    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n",
        "    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n",
        "    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n",
        "    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n",
        "    'survival rate' as the argument.\n",
        "    \"\"\"\n",
        "    if drop_prob == 0. or not training:\n",
        "        return x\n",
        "    keep_prob = 1 - drop_prob\n",
        "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
        "    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
        "    random_tensor.floor_()  # binarize\n",
        "    output = x.div(keep_prob) * random_tensor\n",
        "    return output\n",
        "\n",
        "class EarlyStop:\n",
        "    def __init__(self, patience, loss=False):\n",
        "        self.patience = patience\n",
        "        self.best_value = np.inf if loss else 0\n",
        "        self.best_epoch = 0\n",
        "        self.loss = loss\n",
        "\n",
        "    def step(self, current_value, current_epoch):\n",
        "        print(\"Current:{} Best:{}\".format(current_value, self.best_value))\n",
        "        if self.loss:\n",
        "            if current_value < self.best_value:\n",
        "                self.best_value = current_value\n",
        "                self.best_epoch = current_epoch\n",
        "        else:\n",
        "            if current_value > self.best_value:\n",
        "                self.best_value = current_value\n",
        "                self.best_epoch = current_epoch\n",
        "\n",
        "    def stop_training(self, current_epoch) -> bool:\n",
        "        return current_epoch - self.best_epoch > self.patience\n",
        "\n",
        "\n",
        "class CustomDataParallel(nn.DataParallel):\n",
        "    \"\"\"\n",
        "    Wrapper for scoring with nn.DataParallel object containing LTRModel.\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.module.forward(x)  # type: ignore\n",
        "\n",
        "\n",
        "class DropPath(nn.Module):\n",
        "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
        "    \"\"\"\n",
        "    def __init__(self, drop_prob=None):\n",
        "        super(DropPath, self).__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def forward(self, x):\n",
        "        return drop_path(x, self.drop_prob, self.training)\n",
        "\n",
        "\n",
        "class PatchEmbed(nn.Module):\n",
        "    \"\"\" Image to Patch Embedding\n",
        "    \"\"\"\n",
        "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
        "        super().__init__()\n",
        "        img_size = img_size, img_size\n",
        "        patch_size = patch_size, patch_size\n",
        "        num_patches = (img_size[1] // patch_size[1]) * (img_size[0] // patch_size[0])\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = num_patches\n",
        "\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, T, H, W = x.shape\n",
        "        x = rearrange(x, 'b c t h w -> (b t) c h w')\n",
        "        x = self.proj(x)\n",
        "        W = x.size(-1)\n",
        "        x = x.flatten(2).transpose(1, 2)\n",
        "        return x, T, W\n",
        "\n",
        "class Mlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = act_layer()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0., with_qkv=True):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "        self.with_qkv = with_qkv\n",
        "        if self.with_qkv:\n",
        "           self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "           self.proj = nn.Linear(dim, dim)\n",
        "           self.proj_drop = nn.Dropout(proj_drop)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        if self.with_qkv:\n",
        "           qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "           q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        else:\n",
        "           qkv = x.reshape(B, N, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)\n",
        "           q, k, v  = qkv, qkv, qkv\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        if self.with_qkv:\n",
        "           x = self.proj(x)\n",
        "           x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
        "                 drop_path=0.1, act_layer=nn.GELU, norm_layer=nn.LayerNorm, attention_type='divided_space_time'):\n",
        "        super().__init__()\n",
        "        self.attention_type = attention_type\n",
        "        assert(attention_type in ['divided_space_time', 'space_only','joint_space_time'])\n",
        "\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.attn = Attention(\n",
        "           dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
        "\n",
        "        ## Temporal Attention Parameters\n",
        "        if self.attention_type == 'divided_space_time':\n",
        "            self.temporal_norm1 = norm_layer(dim)\n",
        "            self.temporal_attn = Attention(\n",
        "              dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
        "            self.temporal_fc = nn.Linear(dim, dim)\n",
        "\n",
        "        ## drop path\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
        "\n",
        "\n",
        "    def forward(self, x, B, T, W):\n",
        "        num_spatial_tokens = (x.size(1) - 1) // T\n",
        "        H = num_spatial_tokens // W\n",
        "\n",
        "        if self.attention_type in ['space_only', 'joint_space_time']:\n",
        "            x = x + self.drop_path(self.attn(self.norm1(x)))\n",
        "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
        "            return x\n",
        "        elif self.attention_type == 'divided_space_time':\n",
        "            ## Temporal\n",
        "            xt = x # xt = x[:,1:,:]\n",
        "            xt = rearrange(xt, 'b (h w t) m -> (b h w) t m',b=B,w=W,t=T)\n",
        "            res_temporal = self.drop_path(self.temporal_attn(self.temporal_norm1(xt)))\n",
        "            res_temporal = rearrange(res_temporal, '(b h w) t m -> b (h w t) m',b=B,w=W,t=T)\n",
        "            res_temporal = self.temporal_fc(res_temporal)\n",
        "            xt = x + res_temporal # xt = x[:,1:,:] + res_temporal\n",
        "\n",
        "            ## Spatial\n",
        "            # init_cls_token = x[:,0,:].unsqueeze(1)\n",
        "            # cls_token = init_cls_token.repeat(1, T, 1)\n",
        "            # cls_token = rearrange(cls_token, 'b t m -> (b t) m',b=B,t=T).unsqueeze(1)\n",
        "            xs = xt\n",
        "            xs = rearrange(xs, 'b (h w t) m -> (b t) (h w) m',b=B,w=W,t=T)\n",
        "            # xs = torch.cat((cls_token, xs), 1)\n",
        "            res_spatial = self.drop_path(self.attn(self.norm1(xs)))\n",
        "\n",
        "            ### Taking care of CLS token\n",
        "            # cls_token = res_spatial[:,0,:]\n",
        "            # cls_token = rearrange(cls_token, '(b t) m -> b t m',b=B,t=T)\n",
        "            # cls_token = torch.mean(cls_token,1,True) ## averaging for every frame\n",
        "            # res_spatial = res_spatial[:,1:,:]\n",
        "            res_spatial = rearrange(res_spatial, '(b t) (h w) m -> b (h w t) m',b=B,w=W,t=T)\n",
        "            res = res_spatial\n",
        "            x = xt\n",
        "\n",
        "            ## Mlp\n",
        "            x = x + res # x = torch.cat((init_cls_token, x), 1) + torch.cat((cls_token, res), 1)\n",
        "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
        "            return x\n",
        "\n",
        "\n",
        "class VisionTransformer(nn.Module):\n",
        "    \"\"\" Vision Transformer\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                embed_dim=768,\n",
        "                depth=12,\n",
        "                num_heads=12,\n",
        "                mlp_ratio=4.,\n",
        "                qkv_bias=False,\n",
        "                qk_scale=None,\n",
        "                drop_rate=0.,\n",
        "                attn_drop_rate=0.,\n",
        "                drop_path_rate=0.1,\n",
        "                norm_layer=nn.LayerNorm,\n",
        "                attention_type='divided_space_time',\n",
        "                dropout=0.):\n",
        "        super().__init__()\n",
        "        self.attention_type = attention_type\n",
        "        self.depth = depth\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.num_features = self.embed_dim = embed_dim\n",
        "\n",
        "        ## Attention Blocks\n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, self.depth)]  # stochastic depth decay rule\n",
        "        self.blocks = nn.ModuleList([\n",
        "            Block(\n",
        "                dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
        "                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=norm_layer, attention_type=self.attention_type)\n",
        "            for i in range(self.depth)])\n",
        "        self.norm = norm_layer(embed_dim)\n",
        "\n",
        "        ## initialization of temporal attention weights\n",
        "        if self.attention_type == 'divided_space_time':\n",
        "            i = 0\n",
        "            for m in self.blocks.modules():\n",
        "                m_str = str(m)\n",
        "                if 'Block' in m_str:\n",
        "                    if i > 0:\n",
        "                      nn.init.constant_(m.temporal_fc.weight, 0)\n",
        "                      nn.init.constant_(m.temporal_fc.bias, 0)\n",
        "                    i += 1\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            trunc_normal_(m.weight, std=.02)\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "\n",
        "    def forward(self, x, B, T, W):\n",
        "\n",
        "        ## Attention blocks\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x, B, T, W)\n",
        "\n",
        "        ### Predictions for space-only baseline\n",
        "        if self.attention_type == 'space_only':\n",
        "            x = rearrange(x, '(b t) n m -> b t n m',b=B,t=T)\n",
        "            x = torch.mean(x, 1) # averaging predictions for every frame\n",
        "\n",
        "        x = self.norm(x)\n",
        "        # x = rearrange(x, 'b (h w t) m -> b t (h w) m',b=B,t=T,w=W)\n",
        "        return x\n",
        "    \n",
        "    \n",
        "class IJEPA_base(nn.Module):\n",
        "    def __init__(self,\n",
        "                img_size=224,\n",
        "                patch_size=16,\n",
        "                in_chans=3,\n",
        "                norm_layer=nn.LayerNorm,\n",
        "                num_frames=22,\n",
        "                attention_type='joint_space_time',\n",
        "                dropout=0.,\n",
        "                mode=\"train\",\n",
        "                r=0.5,\n",
        "                embed_dim=768,\n",
        "                device='cuda',\n",
        "                # encoder parameters\n",
        "                enc_depth=12,\n",
        "                enc_num_heads=12,\n",
        "                enc_mlp_ratio=4.,\n",
        "                enc_qkv_bias=False,\n",
        "                enc_qk_scale=None,\n",
        "                enc_drop_rate=0.,\n",
        "                enc_attn_drop_rate=0.,\n",
        "                enc_drop_path_rate=0.1,\n",
        "                # predictor parameters\n",
        "                pred_depth=12,\n",
        "                pred_num_heads=12,\n",
        "                pred_mlp_ratio=4.,\n",
        "                pred_qkv_bias=False,\n",
        "                pred_qk_scale=None,\n",
        "                pred_drop_rate=0.,\n",
        "                pred_attn_drop_rate=0.,\n",
        "                pred_drop_path_rate=0.1,\n",
        "                # positional and spacial embedding parameters\n",
        "                pos_drop_rate=0.,\n",
        "                time_drop_rate=0.):\n",
        "        super().__init__()\n",
        "        self.mode = mode\n",
        "        self.dropout = dropout\n",
        "        self.mask_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
        "        nn.init.trunc_normal_(self.mask_token, 0.02)\n",
        "        self.r = r # number of masked frames\n",
        "\n",
        "        self.norm_layer = norm_layer\n",
        "        self.norm = norm_layer(embed_dim)\n",
        "\n",
        "        self.attention_type = attention_type\n",
        "\n",
        "        self.patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
        "        num_patches = self.patch_embed.num_patches\n",
        "        \n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim)) # self.pos_embed = nn.Parameter(torch.zeros(1, num_patches+1, embed_dim))\n",
        "        self.pos_drop = nn.Dropout(p=pos_drop_rate)\n",
        "\n",
        "        if self.attention_type != 'space_only':\n",
        "            self.time_embed = nn.Parameter(torch.zeros(1, num_frames, embed_dim))\n",
        "            self.time_drop = nn.Dropout(p=time_drop_rate)\n",
        "\n",
        "        self.teacher_encoder = VisionTransformer(\n",
        "            embed_dim=embed_dim,\n",
        "            num_heads=enc_num_heads,\n",
        "            depth=enc_depth, \n",
        "            dropout=self.dropout,\n",
        "            norm_layer=self.norm_layer,\n",
        "            mlp_ratio=enc_mlp_ratio,\n",
        "            attention_type=attention_type,\n",
        "            qkv_bias=enc_qkv_bias,\n",
        "            qk_scale=enc_qk_scale,\n",
        "            drop_rate=enc_drop_rate,\n",
        "            attn_drop_rate=enc_attn_drop_rate,\n",
        "            drop_path_rate=enc_drop_path_rate\n",
        "        )\n",
        "\n",
        "        self.student_encoder = copy.deepcopy(self.teacher_encoder)\n",
        "        self.predictor = VisionTransformer(\n",
        "            embed_dim=embed_dim,\n",
        "            num_heads=pred_num_heads,\n",
        "            depth=pred_depth, \n",
        "            dropout=self.dropout,\n",
        "            norm_layer=self.norm_layer,\n",
        "            mlp_ratio=pred_mlp_ratio,\n",
        "            attention_type=attention_type,\n",
        "            qkv_bias=pred_qkv_bias,\n",
        "            qk_scale=pred_qk_scale,\n",
        "            drop_rate=pred_drop_rate,\n",
        "            attn_drop_rate=pred_attn_drop_rate,\n",
        "            drop_path_rate=pred_drop_path_rate\n",
        "        )\n",
        "        \n",
        "\n",
        "    @torch.no_grad() \n",
        "    ### get the target block\n",
        "    def get_target_block(self, target_encoder, x, B, T, W):  \n",
        "        #get the target block\n",
        "        target_encoder = target_encoder.eval()\n",
        "        x = target_encoder(x, B, T, W) # input in format 'b (t h w) m',output in format 'b (t h w) m' (batch frames n_patches embed_dim)\n",
        "        x = self.norm(x)\n",
        "        tn = x.shape[1]\n",
        "\n",
        "        #randomly select M frames to mask in x\n",
        "        p = int(tn * self.r)\n",
        "        mask_indices = (torch.randperm(tn))[:p]\n",
        "        \n",
        "        #mask the selected frames in the context block\n",
        "        target_block = x[:,mask_indices] #get portion of random patches from rnadom frames\n",
        "        #all_patches = x\n",
        "        return target_block, mask_indices\n",
        "\n",
        "    ### get the context block\n",
        "    def get_context_block(self, x, mask_indices):\n",
        "      #reshape x to format 'b t (h w) m'\n",
        "      # x = rearrange(x, 'b (t h w) m -> b t (h w) m',b=B,t=T,w=W)\n",
        "      #select all frames which are not masked\n",
        "      index = torch.ones(x.shape[1], dtype=bool)\n",
        "      index[mask_indices] = False\n",
        "      context_block = x[:,index]\n",
        "      # context_block = rearrange(context_block, 'b t (h w) m -> b (t h w) m',b=B,t=(T-self.M),w=W)\n",
        "      return context_block\n",
        "    \n",
        "    def get_patch_embeddings(self, x):\n",
        "        B = x.shape[0]\n",
        "        x, T, W = self.patch_embed(x)\n",
        "        x = x + self.pos_embed\n",
        "        x = self.pos_drop(x)\n",
        "\n",
        "        if self.attention_type != 'space_only':\n",
        "            x = rearrange(x, '(b t) n m -> (b n) t m',b=B,t=T)\n",
        "            if T != self.time_embed.size(1):\n",
        "                time_embed = self.time_embed.transpose(1, 2)\n",
        "                new_time_embed = F.interpolate(time_embed, size=(T), mode='nearest')\n",
        "                new_time_embed = new_time_embed.transpose(1, 2)\n",
        "                x = x + new_time_embed\n",
        "            else:\n",
        "                x = x + self.time_embed\n",
        "            x = self.time_drop(x)\n",
        "            x = rearrange(x, '(b n) t m -> b (n t) m',b=B,t=T)\n",
        "            \n",
        "        return x, B, T, W\n",
        "    \n",
        "    def forward(self, x):\n",
        "        #get the patch embeddings\n",
        "        x, B, T, W = self.get_patch_embeddings(x)\n",
        "\n",
        "        #if mode is test, we get return full embedding:\n",
        "        if self.mode == 'test':\n",
        "            encoding = self.student_encoder(x, B, T, W) # input in format 'b (t h w) m',output in format 'b t (h w) m' (batch frames n_patches embed_dim)\n",
        "            encoding = self.norm(encoding)\n",
        "            b, n, m = encoding.shape\n",
        "            # encoding = rearrange(encoding, 'b t (h w) m -> b (t h w) m',b=B,t=T,w=W)\n",
        "            #add 11 mask tokens to the end of the embedding\n",
        "            target_masks = self.mask_token.repeat(B, n, 1)\n",
        "            target_pos_embedding = self.pos_embed.unsqueeze(1)\n",
        "            # Add time embedding\n",
        "            target_time_embed = self.time_embed.unsqueeze(2)[:,11:]\n",
        "\n",
        "            target_embeddings = target_pos_embedding + target_time_embed\n",
        "            target_embeddings = rearrange(target_embeddings, 'b t n m -> b (t n) m')\n",
        "            target_masks = target_masks + target_embeddings\n",
        "            \n",
        "            # target_masks = rearrange(target_masks, 'b t (h w) m -> b (t h w) m',b=B,t=11,w=W)\n",
        "            encoding = torch.cat((encoding, target_masks), dim=1)\n",
        "            encodings_plus_predicted = self.predictor(encoding, B, T+11, W)\n",
        "            return encodings_plus_predicted # predict the masked frames\n",
        "        \n",
        "        # #get target embeddings\n",
        "        # input in format 'b (t h w) m', output in format (1) 'b 11 (h w) m' and (2) 'b t (h w) m'\n",
        "        target_blocks, mask_indices = self.get_target_block(self.teacher_encoder,x,B,T,W)\n",
        "\n",
        "        #get context embeddings\n",
        "        context_block = self.get_context_block(x, mask_indices)\n",
        "\n",
        "        context_encoding = self.student_encoder(context_block, B, T, W)\n",
        "        context_encoding = self.norm(context_encoding)\n",
        "        # context_encoding = rearrange(context_encoding, 'b t (h w) m -> b (t h w) m',b=B,t=T-self.M,w=W)\n",
        "\n",
        "        #n = h x w\n",
        "        b, p, m = target_blocks.shape\n",
        "        target_masks = self.mask_token.repeat(B, p, 1)\n",
        "\n",
        "        # Add time embedding and position embedding\n",
        "        target_pos_embedding = self.pos_embed.unsqueeze(1)\n",
        "        target_time_embed = self.time_embed.unsqueeze(2)\n",
        "        target_embeddings = target_pos_embedding + target_time_embed\n",
        "        target_embeddings = rearrange(target_embeddings, 'b t n m -> b (t n) m')[:, mask_indices]\n",
        "\n",
        "\n",
        "        target_masks = target_masks + target_embeddings\n",
        "        # target_masks = rearrange(target_masks, 'b t (h w) m -> b (t h w) m',b=B,t=self.M,w=W)\n",
        "        prediction_cat = torch.cat((context_encoding, target_masks), dim = 1)\n",
        "        # make sure that the preds are actually at the end\n",
        "        prediction_blocks = self.predictor(prediction_cat,B, T, W)\n",
        "\n",
        "        prediction_blocks = prediction_blocks[:,-p:]\n",
        "        return prediction_blocks, target_blocks, context_encoding"
      ],
      "metadata": {
        "id": "C_DC8vKZHZWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Load the encoder\n",
        "encoder = IJEPA_base(img_size=128, patch_size=16, in_chans=3, norm_layer=nn.LayerNorm, num_frames=22, attention_type='joint_space_time', dropout=0.1, mode=\"train\", r=0.5, embed_dim=768, device=device,\n",
        "                        # encoder parameters\n",
        "                        enc_depth=4,\n",
        "                        enc_num_heads=6,\n",
        "                        enc_mlp_ratio=4.,\n",
        "                        enc_qkv_bias=False,\n",
        "                        enc_qk_scale=None,\n",
        "                        enc_drop_rate=0.,\n",
        "                        enc_attn_drop_rate=0.,\n",
        "                        enc_drop_path_rate=0.1,\n",
        "                        # predictor parameters\n",
        "                        pred_depth=4,\n",
        "                        pred_num_heads=6,\n",
        "                        pred_mlp_ratio=4.,\n",
        "                        pred_qkv_bias=False,\n",
        "                        pred_qk_scale=None,\n",
        "                        pred_drop_rate=0.1,\n",
        "                        pred_attn_drop_rate=0.1,\n",
        "                        pred_drop_path_rate=0.1,\n",
        "                        # positional and spacial embedding parameters\n",
        "                        pos_drop_rate=0.1,\n",
        "                        time_drop_rate=0.1)\n",
        "# Leave this to load properly the optimizer dict\n",
        "encoder.to(device)\n",
        "\n",
        "encoder_saved_data = torch.load(\"best_model.pkl\", map_location=device)\n",
        "encoder.load_state_dict(encoder_saved_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t6lZSMqGH__",
        "outputId": "1ae3cd00-a3dc-4544-d472-522c6cc04b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### DECODER\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from einops import rearrange\n",
        "import numpy as np\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerDecoder, TransformerDecoderLayer\n",
        "from typing import Optional\n",
        "import math\n",
        "from functools import partial\n",
        "\n",
        "def trunc_normal_init(module: nn.Module,\n",
        "                      mean: float = 0,\n",
        "                      std: float = 1,\n",
        "                      a: float = -2,\n",
        "                      b: float = 2,\n",
        "                      bias: float = 0) -> None:\n",
        "    if hasattr(module, 'weight') and module.weight is not None:\n",
        "        trunc_normal_(module.weight, mean, std, a, b)  # type: ignore\n",
        "    if hasattr(module, 'bias') and module.bias is not None:\n",
        "        nn.init.constant_(module.bias, bias)  # type: ignore\n",
        "\n",
        "def constant_init(module, val, bias=0):\n",
        "    if hasattr(module, 'weight') and module.weight is not None:\n",
        "        nn.init.constant_(module.weight, val)\n",
        "    if hasattr(module, 'bias') and module.bias is not None:\n",
        "        nn.init.constant_(module.bias, bias)\n",
        "\n",
        "class TPN_Decoder(TransformerDecoder):\n",
        "    def forward(self, tgt: Tensor, memory: Tensor, tgt_mask: Optional[Tensor] = None,\n",
        "                memory_mask: Optional[Tensor] = None, tgt_key_padding_mask: Optional[Tensor] = None,\n",
        "                memory_key_padding_mask: Optional[Tensor] = None):\n",
        "        output = tgt\n",
        "        # attns = []\n",
        "        # for mod in self.layers:\n",
        "        #     output, attn = mod(output, memory, tgt_mask=tgt_mask,\n",
        "        #                  memory_mask=memory_mask,\n",
        "        #                  tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "        #                  memory_key_padding_mask=memory_key_padding_mask)\n",
        "            # attns.append(attn)\n",
        "\n",
        "        output, attn = self.layers[0](output, memory, tgt_mask=tgt_mask,\n",
        "                          memory_mask=memory_mask,\n",
        "                          tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                          memory_key_padding_mask=memory_key_padding_mask)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            output = self.norm(output)\n",
        "\n",
        "        return output, attn\n",
        "\n",
        "class TPN_DecoderLayer(TransformerDecoderLayer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(TPN_DecoderLayer, self).__init__(**kwargs)\n",
        "        del self.multihead_attn\n",
        "        self.multihead_attn = Attention(\n",
        "            kwargs['d_model'], num_heads=kwargs['nhead'], qkv_bias=True, attn_drop=0.1)\n",
        "\n",
        "    def forward(self, tgt: Tensor, memory: Tensor, tgt_mask: Optional[Tensor] = None,\n",
        "                memory_mask: Optional[Tensor] = None,\n",
        "                tgt_key_padding_mask: Optional[Tensor] = None,\n",
        "                memory_key_padding_mask: Optional[Tensor] = None) -> Tensor:\n",
        "        tgt2 = self.self_attn(tgt, tgt, tgt, attn_mask=tgt_mask,\n",
        "                              key_padding_mask=tgt_key_padding_mask)[0]\n",
        "        tgt = tgt + self.dropout1(tgt2)\n",
        "        tgt = self.norm1(tgt)\n",
        "        tgt2, attn2 = self.multihead_attn(\n",
        "            tgt.transpose(0, 1), memory.transpose(0, 1), memory.transpose(0, 1))\n",
        "        tgt = tgt + self.dropout2(tgt2)\n",
        "        tgt = self.norm2(tgt)\n",
        "        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n",
        "        tgt = tgt + self.dropout3(tgt2)\n",
        "        tgt = self.norm3(tgt)\n",
        "        return tgt, attn2\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        # NOTE scale factor was wrong in my original version, can set manually to be compat with prev weights\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "\n",
        "        self.q = nn.Linear(dim, dim, bias=qkv_bias)\n",
        "        self.k = nn.Linear(dim, dim, bias=qkv_bias)\n",
        "        self.v = nn.Linear(dim, dim, bias=qkv_bias)\n",
        "\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "    def forward(self, xq, xk, xv):\n",
        "        B, Nq, C = xq.size()\n",
        "        Nk = xk.size()[1]\n",
        "        Nv = xv.size()[1]\n",
        "\n",
        "        q = self.q(xq).reshape(B, Nq, self.num_heads,\n",
        "                                      C // self.num_heads).permute(0, 2, 1, 3)\n",
        "        k = self.k(xk).reshape(B, Nk, self.num_heads,\n",
        "                                      C // self.num_heads).permute(0, 2, 1, 3)\n",
        "        v = self.v(xv).reshape(B, Nv, self.num_heads,\n",
        "                                      C // self.num_heads).permute(0, 2, 1, 3)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn_save = attn.clone()\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, Nq, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x.transpose(0, 1), attn_save.sum(dim=1) / self.num_heads\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"Very simple multi-layer perceptron (also called FFN)\"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        h = [hidden_dim] * (num_layers - 1)\n",
        "        self.layers = nn.ModuleList(\n",
        "            nn.Linear(n, k) for n, k in zip([input_dim] + h, h + [output_dim])\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            x = F.relu(layer(x)) if i < self.num_layers - 1 else layer(x)\n",
        "        return x\n",
        "    \n",
        "\n",
        "def accuracy(pred, target, topk=1, thresh=None, ignore_index=None):\n",
        "    \"\"\"Calculate accuracy according to the prediction and target.\n",
        "    Args:\n",
        "        pred (torch.Tensor): The model prediction, shape (N, num_class, ...)\n",
        "        target (torch.Tensor): The target of each prediction, shape (N, , ...)\n",
        "        ignore_index (int | None): The label index to be ignored. Default: None\n",
        "        topk (int | tuple[int], optional): If the predictions in ``topk``\n",
        "            matches the target, the predictions will be regarded as\n",
        "            correct ones. Defaults to 1.\n",
        "        thresh (float, optional): If not None, predictions with scores under\n",
        "            this threshold are considered incorrect. Default to None.\n",
        "    Returns:\n",
        "        float | tuple[float]: If the input ``topk`` is a single integer,\n",
        "            the function will return a single float as accuracy. If\n",
        "            ``topk`` is a tuple containing multiple integers, the\n",
        "            function will return a tuple containing accuracies of\n",
        "            each ``topk`` number.\n",
        "    \"\"\"\n",
        "    assert isinstance(topk, (int, tuple))\n",
        "    if isinstance(topk, int):\n",
        "        topk = (topk, )\n",
        "        return_single = True\n",
        "    else:\n",
        "        return_single = False\n",
        "\n",
        "    maxk = max(topk)\n",
        "    if pred.size(0) == 0:\n",
        "        accu = [pred.new_tensor(0.) for i in range(len(topk))]\n",
        "        return accu[0] if return_single else accu\n",
        "    assert pred.ndim == target.ndim + 1\n",
        "    assert pred.size(0) == target.size(0)\n",
        "    assert maxk <= pred.size(1), \\\n",
        "        f'maxk {maxk} exceeds pred dimension {pred.size(1)}'\n",
        "    pred_value, pred_label = pred.topk(maxk, dim=1)\n",
        "    # transpose to shape (maxk, N, ...)\n",
        "    pred_label = pred_label.transpose(0, 1)\n",
        "    correct = pred_label.eq(target.unsqueeze(0).expand_as(pred_label))\n",
        "    if thresh is not None:\n",
        "        # Only prediction values larger than thresh are counted as correct\n",
        "        correct = correct & (pred_value > thresh).t()\n",
        "    if ignore_index is not None:\n",
        "        correct = correct[:, target != ignore_index]\n",
        "    res = []\n",
        "    eps = torch.finfo(torch.float32).eps\n",
        "    for k in topk:\n",
        "        # Avoid causing ZeroDivisionError when all pixels\n",
        "        # of an image are ignored\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True) + eps\n",
        "        if ignore_index is not None:\n",
        "            total_num = target[target != ignore_index].numel() + eps\n",
        "        else:\n",
        "            total_num = target.numel() + eps\n",
        "        res.append(correct_k.mul_(100.0 / total_num))\n",
        "    return res[0] if return_single else res\n",
        "\n",
        "class ATMHead(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            img_size,\n",
        "            H,\n",
        "            W,\n",
        "            in_channels,\n",
        "            embed_dims=768,\n",
        "            num_layers=3,\n",
        "            num_heads=8,\n",
        "            use_stages=3,\n",
        "            use_proj=True,\n",
        "            CE_loss=False,\n",
        "            crop_train=False,\n",
        "            #shrink_ratio=None,\n",
        "            #**kwargs,\n",
        "\n",
        "            num_classes=48\n",
        "    ):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        # super(ATMHead, self).__init__()\n",
        "         #   in_channels=in_channels, **kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.image_size = img_size\n",
        "        self.H = H\n",
        "        self.W = W\n",
        "\n",
        "        self.use_stages = use_stages\n",
        "        self.crop_train = crop_train\n",
        "        nhead = num_heads\n",
        "        dim = embed_dims\n",
        "        input_proj = []\n",
        "        proj_norm = []\n",
        "        atm_decoders = []\n",
        "        for i in range(self.use_stages):\n",
        "            # FC layer to change ch\n",
        "            if use_proj:\n",
        "                proj = nn.Linear(self.in_channels, dim)\n",
        "                trunc_normal_(proj.weight, std=.02)\n",
        "            else:\n",
        "                proj = nn.Identity()\n",
        "            self.add_module(\"input_proj_{}\".format(i + 1), proj)\n",
        "            input_proj.append(proj)\n",
        "            # norm layer\n",
        "            if use_proj:\n",
        "                norm = nn.LayerNorm(dim)\n",
        "            else:\n",
        "                norm = nn.Identity()\n",
        "            self.add_module(\"proj_norm_{}\".format(i + 1), norm)\n",
        "            proj_norm.append(norm)\n",
        "            # decoder layer\n",
        "            decoder_layer = TPN_DecoderLayer(d_model=dim, nhead=nhead, dim_feedforward=dim * 4)\n",
        "            decoder = TPN_Decoder(decoder_layer, num_layers)\n",
        "            self.add_module(\"decoder_{}\".format(i + 1), decoder)\n",
        "            atm_decoders.append(decoder)\n",
        "\n",
        "        self.input_proj = input_proj\n",
        "        self.proj_norm = proj_norm\n",
        "        self.decoder = atm_decoders\n",
        "        self.q = nn.Embedding(self.num_classes + 1, dim) # nn.Embedding(self.num_classes, dim)\n",
        "\n",
        "        self.class_embed = nn.Linear(dim, self.num_classes + 1)\n",
        "        self.CE_loss = CE_loss\n",
        "        # delattr(self, 'conv_seg')\n",
        "\n",
        "    def init_weights(self):\n",
        "        for n, m in self.named_modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                trunc_normal_init(m, std=.02, bias=0)\n",
        "            elif isinstance(m, nn.LayerNorm):\n",
        "                constant_init(m, val=1.0, bias=0.0)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = []\n",
        "        # for stage_ in inputs[:self.use_stages]:\n",
        "        #     x.append(self.d4_to_d3(stage_) if stage_.dim() > 3 else stage_)\n",
        "\n",
        "        x.append(self.d4_to_d3(inputs) if inputs.dim() > 3 else inputs)\n",
        "\n",
        "        x.reverse()\n",
        "        bs = x[0].size()[0]\n",
        "\n",
        "        laterals = []\n",
        "        attns = []\n",
        "        maps_size = []\n",
        "        qs = []\n",
        "        q = self.q.weight.repeat(bs, 1, 1).transpose(0, 1)\n",
        "\n",
        "        for idx, (x_, proj_, norm_, decoder_) in enumerate(zip(x, self.input_proj, self.proj_norm, self.decoder)):\n",
        "            lateral = norm_(proj_(x_))\n",
        "            # if idx == 0:\n",
        "            if True:\n",
        "                laterals.append(lateral)\n",
        "            else:\n",
        "                if laterals[idx - 1].size()[1] == lateral.size()[1]:\n",
        "                    laterals.append(lateral + laterals[idx - 1])\n",
        "                else:\n",
        "                    # nearest interpolate\n",
        "                    l_ = self.d3_to_d4(laterals[idx - 1])\n",
        "                    l_ = F.interpolate(l_, scale_factor=2, mode=\"nearest\")\n",
        "                    l_ = self.d4_to_d3(l_)\n",
        "                    laterals.append(l_ + lateral)\n",
        "\n",
        "            #print(q.shape)\n",
        "            #print(lateral.shape)\n",
        "            \n",
        "            q, attn = decoder_(q, lateral.transpose(0, 1))\n",
        "            attn = attn.transpose(-1, -2)\n",
        "            if self.crop_train and self.training:\n",
        "                blank_attn = torch.zeros_like(attn)\n",
        "                blank_attn = blank_attn[:, 0].unsqueeze(1).repeat(1, (self.image_size//16)**2, 1)\n",
        "                blank_attn[:, inputs[-1]] = attn\n",
        "                attn = blank_attn\n",
        "                self.crop_idx = inputs[-1]\n",
        "            attn = self.d3_to_d4(attn)\n",
        "            maps_size.append(attn.size()[-2:])\n",
        "            qs.append(q.transpose(0, 1))\n",
        "            attns.append(attn)\n",
        "        qs = torch.stack(qs, dim=0)\n",
        "        outputs_class = self.class_embed(qs)\n",
        "        out = {\"pred_logits\": outputs_class[-1]}\n",
        "\n",
        "        outputs_seg_masks = []\n",
        "        size = maps_size[-1]\n",
        "\n",
        "        for i_attn, attn in enumerate(attns):\n",
        "            if i_attn == 0:\n",
        "                outputs_seg_masks.append(F.interpolate(attn, size=size, mode='bilinear', align_corners=False))\n",
        "            else:\n",
        "                outputs_seg_masks.append(outputs_seg_masks[i_attn - 1] +\n",
        "                                         F.interpolate(attn, size=size, mode='bilinear', align_corners=False))\n",
        "\n",
        "        out[\"pred_masks\"] = F.interpolate(outputs_seg_masks[-1],\n",
        "                                          #size=(self.image_size, self.image_size),\n",
        "                                          size=(self.H, self.W),\n",
        "                                          mode='bilinear', align_corners=False)\n",
        "\n",
        "        out[\"pred\"] = self.semantic_inference(out[\"pred_logits\"], out[\"pred_masks\"])\n",
        "\n",
        "        if self.training:\n",
        "            # [l, bs, queries, embed]\n",
        "            outputs_seg_masks = torch.stack(outputs_seg_masks, dim=0)\n",
        "            out[\"aux_outputs\"] = self._set_aux_loss(\n",
        "                outputs_class, outputs_seg_masks\n",
        "            )\n",
        "        else:\n",
        "            return out[\"pred\"]\n",
        "\n",
        "        return out\n",
        "\n",
        "    @torch.jit.unused\n",
        "    def _set_aux_loss(self, outputs_class, outputs_seg_masks):\n",
        "        # this is a workaround to make torchscript happy, as torchscript\n",
        "        # doesn't support dictionary with non-homogeneous values, such\n",
        "        # as a dict having both a Tensor and a list.\n",
        "        return [\n",
        "            {\"pred_logits\": a, \"pred_masks\": b}\n",
        "            for a, b in zip(outputs_class[:-1], outputs_seg_masks[:-1])\n",
        "        ]\n",
        "\n",
        "    def semantic_inference(self, mask_cls, mask_pred):\n",
        "        mask_cls = F.softmax(mask_cls, dim=-1)[..., :]\n",
        "        mask_pred = mask_pred.sigmoid()\n",
        "        semseg = torch.einsum(\"bqc,bqhw->bchw\", mask_cls, mask_pred)\n",
        "        return semseg\n",
        "\n",
        "    def d3_to_d4(self, t):\n",
        "        n, hw, c = t.size()\n",
        "        if hw % 2 != 0:\n",
        "            t = t[:, 1:]\n",
        "        h = w = int(math.sqrt(hw))\n",
        "        return t.transpose(1, 2).reshape(n, c, h, w)\n",
        "\n",
        "    def d4_to_d3(self, t):\n",
        "        return t.flatten(-2).transpose(-1, -2)\n",
        "\n",
        "    # @force_fp32(apply_to=('seg_logit',))\n",
        "    def losses(self, seg_logit, seg_label):\n",
        "        \"\"\"Compute segmentation loss.\"\"\"\n",
        "        if self.CE_loss:\n",
        "            return super().losses(seg_logit[\"pred\"], seg_label)\n",
        "\n",
        "        if isinstance(seg_logit, dict):\n",
        "            # atm loss\n",
        "            seg_label = seg_label.squeeze(1)\n",
        "            if self.crop_train:\n",
        "                # mask seg_label by crop_idx\n",
        "                bs, h, w = seg_label.size()\n",
        "                mask_label = seg_label.reshape(bs, h//16, 16, w//16, 16)\\\n",
        "                    .permute(0, 1, 3, 2, 4).reshape(bs, h*w//256, 256)\n",
        "                empty_label = torch.zeros_like(mask_label) + self.ignore_index\n",
        "                empty_label[:, self.crop_idx] = mask_label[:, self.crop_idx]\n",
        "                seg_label = empty_label.reshape(bs, h//16, w//16, 16, 16)\\\n",
        "                    .permute(0, 1, 3, 2, 4).reshape(bs, h, w)\n",
        "            loss = self.loss_decode(\n",
        "                seg_logit,\n",
        "                seg_label,\n",
        "                ignore_index=self.ignore_index)\n",
        "\n",
        "            loss['acc_seg'] = accuracy(seg_logit[\"pred\"], seg_label, ignore_index=self.ignore_index)\n",
        "            return loss"
      ],
      "metadata": {
        "id": "ScDgiRHfIqWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### ATM Losses\n",
        "from typing import List, Optional\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.distributed as dist\n",
        "import torchvision\n",
        "from torch import Tensor\n",
        "\n",
        "from einops import rearrange\n",
        "# import imageio.v3 as iio\n",
        "import numpy as np\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def _max_by_axis(the_list):\n",
        "    # type: (List[List[int]]) -> List[int]\n",
        "    maxes = the_list[0]\n",
        "    for sublist in the_list[1:]:\n",
        "        for index, item in enumerate(sublist):\n",
        "            maxes[index] = max(maxes[index], item)\n",
        "    return maxes\n",
        "\n",
        "\n",
        "class NestedTensor(object):\n",
        "    def __init__(self, tensors, mask: Optional[Tensor]):\n",
        "        self.tensors = tensors\n",
        "        self.mask = mask\n",
        "\n",
        "    def to(self, device):\n",
        "        # type: (Device) -> NestedTensor # noqa\n",
        "        cast_tensor = self.tensors.to(device)\n",
        "        mask = self.mask\n",
        "        if mask is not None:\n",
        "            assert mask is not None\n",
        "            cast_mask = mask.to(device)\n",
        "        else:\n",
        "            cast_mask = None\n",
        "        return NestedTensor(cast_tensor, cast_mask)\n",
        "\n",
        "    def decompose(self):\n",
        "        return self.tensors, self.mask\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.tensors)\n",
        "\n",
        "\n",
        "def nested_tensor_from_tensor_list(tensor_list: List[Tensor]):\n",
        "    # TODO make this more general\n",
        "    if tensor_list[0].ndim == 3:\n",
        "        if torchvision._is_tracing():\n",
        "            # nested_tensor_from_tensor_list() does not export well to ONNX\n",
        "            # call _onnx_nested_tensor_from_tensor_list() instead\n",
        "            return _onnx_nested_tensor_from_tensor_list(tensor_list)\n",
        "\n",
        "        # TODO make it support different-sized images\n",
        "        max_size = _max_by_axis([list(img.shape) for img in tensor_list])\n",
        "        # min_size = tuple(min(s) for s in zip(*[img.shape for img in tensor_list]))\n",
        "        batch_shape = [len(tensor_list)] + max_size\n",
        "        b, c, h, w = batch_shape\n",
        "        dtype = tensor_list[0].dtype\n",
        "        device = tensor_list[0].device\n",
        "        tensor = torch.zeros(batch_shape, dtype=dtype, device=device)\n",
        "        mask = torch.ones((b, h, w), dtype=torch.bool, device=device)\n",
        "        for img, pad_img, m in zip(tensor_list, tensor, mask):\n",
        "            pad_img[: img.shape[0], : img.shape[1], : img.shape[2]].copy_(img)\n",
        "            m[: img.shape[1], : img.shape[2]] = False\n",
        "    else:\n",
        "        raise ValueError(\"not supported\")\n",
        "    return NestedTensor(tensor, mask)\n",
        "\n",
        "\n",
        "# _onnx_nested_tensor_from_tensor_list() is an implementation of\n",
        "# nested_tensor_from_tensor_list() that is supported by ONNX tracing.\n",
        "@torch.jit.unused\n",
        "def _onnx_nested_tensor_from_tensor_list(tensor_list: List[Tensor]) -> NestedTensor:\n",
        "    max_size = []\n",
        "    for i in range(tensor_list[0].dim()):\n",
        "        max_size_i = torch.max(\n",
        "            torch.stack([img.shape[i] for img in tensor_list]).to(torch.float32)\n",
        "        ).to(torch.int64)\n",
        "        max_size.append(max_size_i)\n",
        "    max_size = tuple(max_size)\n",
        "\n",
        "    # work around for\n",
        "    # pad_img[: img.shape[0], : img.shape[1], : img.shape[2]].copy_(img)\n",
        "    # m[: img.shape[1], :img.shape[2]] = False\n",
        "    # which is not yet supported in onnx\n",
        "    padded_imgs = []\n",
        "    padded_masks = []\n",
        "    for img in tensor_list:\n",
        "        padding = [(s1 - s2) for s1, s2 in zip(max_size, tuple(img.shape))]\n",
        "        padded_img = torch.nn.functional.pad(img, (0, padding[2], 0, padding[1], 0, padding[0]))\n",
        "        padded_imgs.append(padded_img)\n",
        "\n",
        "        m = torch.zeros_like(img[0], dtype=torch.int, device=img.device)\n",
        "        padded_mask = torch.nn.functional.pad(m, (0, padding[2], 0, padding[1]), \"constant\", 1)\n",
        "        padded_masks.append(padded_mask.to(torch.bool))\n",
        "\n",
        "    tensor = torch.stack(padded_imgs)\n",
        "    mask = torch.stack(padded_masks)\n",
        "\n",
        "    return NestedTensor(tensor, mask=mask)\n",
        "\n",
        "\n",
        "def is_dist_avail_and_initialized():\n",
        "    if not dist.is_available():\n",
        "        return False\n",
        "    if not dist.is_initialized():\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def get_world_size() -> int:\n",
        "    if not dist.is_available():\n",
        "        return 1\n",
        "    if not dist.is_initialized():\n",
        "        return 1\n",
        "    return dist.get_world_size()\n",
        "\n",
        "\n",
        "def dice_loss(inputs, targets, num_masks):\n",
        "    \"\"\"\n",
        "    Compute the DICE loss, similar to generalized IOU for masks\n",
        "    Args:\n",
        "        inputs: A float tensor of arbitrary shape.\n",
        "                The predictions for each example.\n",
        "        targets: A float tensor with the same shape as inputs. Stores the binary\n",
        "                 classification label for each element in inputs\n",
        "                (0 for the negative class and 1 for the positive class).\n",
        "    \"\"\"\n",
        "    inputs = inputs.sigmoid()\n",
        "    inputs = inputs.flatten(1)\n",
        "    numerator = 2 * (inputs * targets).sum(-1)\n",
        "    denominator = inputs.sum(-1) + targets.sum(-1)\n",
        "    loss = 1 - (numerator + 1) / (denominator + 1)\n",
        "    return loss.sum() / num_masks\n",
        "\n",
        "\n",
        "def sigmoid_focal_loss(inputs, targets, num_masks, alpha: float = 0.25, gamma: float = 2):\n",
        "    \"\"\"\n",
        "    Loss used in RetinaNet for dense detection: https://arxiv.org/abs/1708.02002.\n",
        "    Args:\n",
        "        inputs: A float tensor of arbitrary shape.\n",
        "                The predictions for each example.\n",
        "        targets: A float tensor with the same shape as inputs. Stores the binary\n",
        "                 classification label for each element in inputs\n",
        "                (0 for the negative class and 1 for the positive class).\n",
        "        alpha: (optional) Weighting factor in range (0,1) to balance\n",
        "                positive vs negative examples. Default = -1 (no weighting).\n",
        "        gamma: Exponent of the modulating factor (1 - p_t) to\n",
        "               balance easy vs hard examples.\n",
        "    Returns:\n",
        "        Loss tensor\n",
        "    \"\"\"\n",
        "    prob = inputs.sigmoid()\n",
        "    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
        "    p_t = prob * targets + (1 - prob) * (1 - targets)\n",
        "    loss = ce_loss * ((1 - p_t) ** gamma)\n",
        "\n",
        "    if alpha >= 0:\n",
        "        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
        "        loss = alpha_t * loss\n",
        "\n",
        "    return loss.mean(1).sum() / num_masks\n",
        "\n",
        "\n",
        "class SetCriterion(nn.Module):\n",
        "    \"\"\"This class computes the loss for DETR.\n",
        "    The process happens in two steps:\n",
        "        1) we compute hungarian assignment between ground truth boxes and the outputs of the model\n",
        "        2) we supervise each pair of matched ground-truth / prediction (supervise class and box)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, weight_dict, losses, eos_coef=0.001):\n",
        "        \"\"\"Create the criterion.\n",
        "        Parameters:\n",
        "            num_classes: number of object categories, omitting the special no-object category\n",
        "            matcher: module able to compute a matching between targets and proposals\n",
        "            weight_dict: dict containing as key the names of the losses and as values their relative weight.\n",
        "            eos_coef: relative classification weight applied to the no-object category\n",
        "            losses: list of all the losses to be applied. See get_loss for list of available losses.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.weight_dict = weight_dict\n",
        "        self.eos_coef = eos_coef\n",
        "        self.losses = losses\n",
        "        empty_weight = torch.ones(self.num_classes)\n",
        "        empty_weight[0] = self.eos_coef\n",
        "        self.register_buffer(\"empty_weight\", empty_weight)\n",
        "\n",
        "    def loss_labels(self, outputs, targets, indices, num_masks):\n",
        "        \"\"\"Classification loss (NLL)\n",
        "        targets dicts must contain the key \"labels\" containing a tensor of dim [nb_target_boxes]\n",
        "        \"\"\"\n",
        "        assert \"pred_logits\" in outputs\n",
        "        src_logits = outputs[\"pred_logits\"]\n",
        "\n",
        "        idx = self._get_src_permutation_idx(indices)\n",
        "        target_classes_o = torch.cat([t[\"labels\"][J] for t, (_, J) in zip(targets, indices)])\n",
        "        target_classes = torch.zeros(\n",
        "            src_logits.shape[:2], dtype=torch.int64, device=src_logits.device\n",
        "        )\n",
        "        target_classes[idx] = target_classes_o.long()\n",
        "\n",
        "        loss_ce = F.cross_entropy(src_logits.transpose(1, 2), target_classes, self.empty_weight)\n",
        "        losses = {\"loss_ce\": loss_ce}\n",
        "        return losses\n",
        "\n",
        "    def loss_masks(self, outputs, targets, indices, num_masks):\n",
        "        \"\"\"Compute the losses related to the masks: the focal loss and the dice loss.\n",
        "        targets dicts must contain the key \"masks\" containing a tensor of dim [nb_target_boxes, h, w]\n",
        "        \"\"\"\n",
        "        assert \"pred_masks\" in outputs\n",
        "\n",
        "        src_idx = self._get_src_permutation_idx(indices)\n",
        "        tgt_idx = self._get_tgt_permutation_idx(indices)\n",
        "        src_masks = outputs[\"pred_masks\"]\n",
        "        if src_masks.dim() != 4:\n",
        "            return {\"no_loss\": 0}\n",
        "        src_masks = src_masks[src_idx]\n",
        "        masks = [t[\"masks\"] for t in targets]\n",
        "        # TODO use valid to mask invalid areas due to padding in loss\n",
        "        target_masks, valid = nested_tensor_from_tensor_list(masks).decompose()\n",
        "        target_masks = target_masks.to(src_masks)\n",
        "        target_masks = target_masks[tgt_idx]\n",
        "\n",
        "        # upsample predictions to the target size\n",
        "        src_masks = F.interpolate(\n",
        "            src_masks[:, None], size=target_masks.shape[-2:], mode=\"bilinear\", align_corners=False\n",
        "        )\n",
        "        src_masks = src_masks[:, 0].flatten(1)\n",
        "\n",
        "        target_masks = target_masks.flatten(1)\n",
        "        target_masks = target_masks.view(src_masks.shape)\n",
        "        losses = {\n",
        "            \"loss_mask\": sigmoid_focal_loss(src_masks, target_masks, num_masks),\n",
        "            \"loss_dice\": dice_loss(src_masks, target_masks, num_masks),\n",
        "        }\n",
        "        return losses\n",
        "\n",
        "    def _get_src_permutation_idx(self, indices):\n",
        "        # permute predictions following indices\n",
        "        batch_idx = torch.cat([torch.full_like(src, i) for i, (src, _) in enumerate(indices)])\n",
        "        src_idx = torch.cat([src for (src, _) in indices])\n",
        "        return batch_idx.long(), src_idx.long()\n",
        "\n",
        "    def _get_tgt_permutation_idx(self, indices):\n",
        "        # permute targets following indices\n",
        "        batch_idx = torch.cat([torch.full_like(tgt, i) for i, (_, tgt) in enumerate(indices)])\n",
        "        tgt_idx = torch.cat([tgt for (_, tgt) in indices])\n",
        "        return batch_idx, tgt_idx\n",
        "\n",
        "    def get_loss(self, loss, outputs, targets, indices, num_masks):\n",
        "        loss_map = {\"labels\": self.loss_labels, \"masks\": self.loss_masks}\n",
        "        assert loss in loss_map, f\"do you really want to compute {loss} loss?\"\n",
        "        return loss_map[loss](outputs, targets, indices, num_masks)\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        \"\"\"This performs the loss computation.\n",
        "        Parameters:\n",
        "             outputs: dict of tensors, see the output specification of the model for the format\n",
        "             targets: list of dicts, such that len(targets) == batch_size.\n",
        "                      The expected keys in each dict depends on the losses applied, see each loss' doc\n",
        "        \"\"\"\n",
        "        # outputs_without_aux = {k: v for k, v in outputs.items() if k != \"aux_outputs\"}\n",
        "\n",
        "        # Retrieve the matching between the outputs of the last layer and the targets\n",
        "\n",
        "        labels = [x['labels'] for x in targets]\n",
        "        indices_new = []\n",
        "        for label in labels:\n",
        "            t = torch.arange(len(label))\n",
        "            indices_new.append([label, t])\n",
        "        indices = indices_new\n",
        "        # Compute the average number of target boxes accross all nodes, for normalization purposes\n",
        "        num_masks = sum(len(t[\"labels\"]) for t in targets)\n",
        "        num_masks = torch.as_tensor(\n",
        "            [num_masks], dtype=torch.float, device=next(iter(outputs.values())).device\n",
        "        )\n",
        "        if is_dist_avail_and_initialized():\n",
        "            torch.distributed.all_reduce(num_masks)\n",
        "        num_masks = torch.clamp(num_masks / get_world_size(), min=1).item()\n",
        "\n",
        "        # Compute all the requested losses\n",
        "        losses = {}\n",
        "        for loss in self.losses:\n",
        "            losses.update(self.get_loss(loss, outputs, targets, indices, num_masks))\n",
        "\n",
        "        # In case of auxiliary losses, we repeat this process with the output of each intermediate layer.\n",
        "        if \"aux_outputs\" in outputs:\n",
        "            for i, aux_outputs in enumerate(outputs[\"aux_outputs\"]):\n",
        "                # use the indices as the last stage\n",
        "                for loss in self.losses:\n",
        "                    l_dict = self.get_loss(loss, aux_outputs, targets, indices, num_masks)\n",
        "                    l_dict = {k + f\"_{i}\": v for k, v in l_dict.items()}\n",
        "                    losses.update(l_dict)\n",
        "\n",
        "        return losses\n",
        "    \n",
        "\n",
        "class ATMLoss(nn.Module):\n",
        "    \"\"\"ATMLoss.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_classes,\n",
        "                 dec_layers,\n",
        "                 mask_weight=20.0,\n",
        "                 dice_weight=1.0,\n",
        "                 cls_weight=1.0,\n",
        "                 loss_weight=1.0):\n",
        "        super(ATMLoss, self).__init__()\n",
        "        weight_dict = {\"loss_ce\": cls_weight, \"loss_mask\": mask_weight, \"loss_dice\": dice_weight}\n",
        "        aux_weight_dict = {}\n",
        "        for i in range(dec_layers - 1):\n",
        "            aux_weight_dict.update({k + f\"_{i}\": v for k, v in weight_dict.items()})\n",
        "        weight_dict.update(aux_weight_dict)\n",
        "        \n",
        "        self.criterion = SetCriterion(\n",
        "                num_classes,\n",
        "                weight_dict=weight_dict,\n",
        "                losses=[\"labels\", \"masks\"],\n",
        "            )\n",
        "        self.loss_weight = loss_weight\n",
        "\n",
        "    def forward(self,\n",
        "                outputs,\n",
        "                label,\n",
        "                ignore_index,\n",
        "                ):\n",
        "        \"\"\"Forward function.\"\"\"\n",
        "        self.ignore_index = ignore_index\n",
        "        targets = self.prepare_targets(label)\n",
        "        losses = self.criterion(outputs, targets)\n",
        "        loss = 0\n",
        "\n",
        "        for k in list(losses.keys()):\n",
        "            if k in self.criterion.weight_dict:\n",
        "                # losses[k] = losses[k] * self.criterion.weight_dict[k] * self.loss_weight\n",
        "                loss += losses[k] * self.criterion.weight_dict[k] * self.loss_weight\n",
        "            else:\n",
        "                # remove this loss if not specified in `weight_dict`\n",
        "                losses.pop(k)\n",
        "\n",
        "        return loss, losses\n",
        "\n",
        "    def prepare_targets(self, targets):\n",
        "        new_targets = []\n",
        "        for targets_per_image in targets:\n",
        "            # gt_cls\n",
        "            gt_cls = targets_per_image.unique()\n",
        "            gt_cls = gt_cls[gt_cls != self.ignore_index]\n",
        "            masks = []\n",
        "            for cls in gt_cls:\n",
        "                masks.append(targets_per_image == cls)\n",
        "            if len(gt_cls) == 0:\n",
        "                masks.append(targets_per_image == self.ignore_index)\n",
        "\n",
        "            masks = torch.stack(masks, dim=0)\n",
        "            new_targets.append(\n",
        "                {\n",
        "                    \"labels\": gt_cls,\n",
        "                    \"masks\": masks,\n",
        "                }\n",
        "            )\n",
        "        return new_targets"
      ],
      "metadata": {
        "id": "1JcrF9w6PsoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Dataloader method\n",
        "def load_data(root, annotation_file, batch_size=2):\n",
        "    preprocess = transforms.Compose([\n",
        "            ImglistToTensor(),  # list of PIL images to (FRAMES x CHANNELS x HEIGHT x WIDTH) tensor\n",
        "            # transforms.Resize(299),  # image batch, resize smaller edge to 299\n",
        "            transforms.Resize((128,128)),\n",
        "            # transforms.CenterCrop(299),  # image batch, center crop to square 299x299\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "    dataset = VideoFrameDataset(\n",
        "        root_path=root,\n",
        "        annotationfile_path=annotation_file,\n",
        "        num_segments=1,\n",
        "        frames_per_segment=22,\n",
        "        imagefile_template='image_{:d}.png',\n",
        "        transform=preprocess,\n",
        "        mask=True,\n",
        "        test_mode=False\n",
        "    )\n",
        "\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "            dataset=dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=2, # arbitrarily chosen\n",
        "            pin_memory=True\n",
        "        )\n",
        "    return dataloader\n",
        "\n",
        "### Load the train and validation datasets\n",
        "batch_size = 4\n",
        "trainloader = load_data('Dataset_Student/train/data/', 'Dataset_Student/train/annotations.txt', batch_size)\n",
        "valloader = load_data('Dataset_Student/val/data/', 'Dataset_Student/val/annotations.txt', batch_size)"
      ],
      "metadata": {
        "id": "50SLH26hUP_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Jaccard method\n",
        "def compute_jaccard(ground_truth_mask, predicted_mask, device):\n",
        "  jaccard = torchmetrics.JaccardIndex(task=\"multiclass\", num_classes=49).to(device)\n",
        "  jaccard(torch.Tensor(ground_truth_mask), torch.Tensor(predicted_mask))"
      ],
      "metadata": {
        "id": "8cHNecAcjhIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "GbRcKY2dQJMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.utils as utils\n",
        "\n",
        "### Training loop\n",
        "def train_model(epoch, decoder, encoder, criterion, optimizer, scheduler, dataloader, validationloader, num_epochs, device):\n",
        "    while epoch < num_epochs:\n",
        "        decoder.train()\n",
        "        encoder.eval()\n",
        "\n",
        "        train_loss = 0\n",
        "\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            inputs, labels, target_masks = data \n",
        "            inputs, labels, target_masks = inputs.to(device), labels.to(device), target_masks.to(device)\n",
        "\n",
        "            inputs = inputs[:, :11] #Remove depending on preference\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            ### forward pass through encoder to get the embeddings\n",
        "            predicted_embeddings = encoder(inputs.transpose(1, 2)) # batch x frames*num_patches x embedding dim\n",
        "\n",
        "            # Reshape predicted embeddings to (b t) (h w) m\n",
        "            predicted_embeddings = rearrange(predicted_embeddings, 'b (t n) m -> b t n m', t=22) # nicer way of doing this surely\n",
        "            predicted_embeddings = rearrange(predicted_embeddings, 'b t n m -> (b t) n m')\n",
        "            #print(predicted_embeddings.shape)\n",
        "\n",
        "            target_masks = rearrange(target_masks, 'b t n m -> (b t) n m')\n",
        "\n",
        "            ### forward pass through decoder to get the masks\n",
        "            outputs = decoder(predicted_embeddings) # output shape = ?\n",
        "\n",
        "            # the target_mask tensor is of shape b f h w\n",
        "\n",
        "            ### compute the loss and step\n",
        "            loss, losses = criterion(outputs, target_masks, -1)\n",
        "            train_loss += loss.item()\n",
        "            loss.backward()\n",
        "\n",
        "            # Implementing the gradient clipping\n",
        "            utils.clip_grad_norm_(decoder.parameters(), 1.0)\n",
        "\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the scheduler learning rate\n",
        "            scheduler.step()\n",
        "\n",
        "            if i % 10 == 0: # and epoch < 5:\n",
        "                print(f\"Losses: {losses}\")\n",
        "                print(f\"Current loss: {loss.item()}\") # we can just take a sample, don't need to average it\n",
        "        \n",
        "        avg_epoch_loss = train_loss / len(dataloader)\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Epoch: {epoch + 1}, Learning Rate: {current_lr:.6f}, Avg train loss: {avg_epoch_loss:.4f}\") #, Avg val loss: {avg_val_loss:.4f}, Jaccard: {jaccard_score:.4f}\n",
        "\n",
        "        # Used this approach (while and epoch increase) so that we can get back to training the loaded model from checkpoint\n",
        "        epoch += 1\n",
        "\n",
        "        # Checkpoint\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': decoder.module.state_dict() if torch.cuda.device_count() > 1 else decoder.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict()\n",
        "            }, \"checkpoint_decoder_1.pkl\")\n",
        "\n",
        "    return {\n",
        "        \"epochs\": epoch,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"model\": decoder\n",
        "            }\n",
        "\n",
        "# run full evaluation at this point?\n",
        "#print(f'Decoder training finshed at epoch {results[\"epoch\"]}, trainig loss: {results[\"train_loss\"]}')\n"
      ],
      "metadata": {
        "id": "RHW1vNPaceXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Initialize Decoder\n",
        "decoder = ATMHead(img_size=128, H=160, W=240, in_channels=768, use_stages=1)\n",
        "decoder.to(device)\n",
        "\n",
        "### Epochs, Optimizer, Criterion and Scheduler\n",
        "criterion = ATMLoss(49, 1) ## 48 classes + 1 background which will be added in the loss\n",
        "criterion.to(device)\n",
        "\n",
        "initial_lr = 0.00001\n",
        "final_lr = 0.00000001\n",
        "optimizer = torch.optim.AdamW(decoder.parameters(), lr=initial_lr, weight_decay=0.05)\n",
        "\n",
        "num_epochs = 10\n",
        "total_steps = num_epochs * len(trainloader)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=final_lr)\n",
        "\n",
        "epoch = 0\n",
        "encoder.mode = \"test\"\n",
        "results = train_model(epoch, decoder, encoder, criterion, optimizer, scheduler, trainloader, valloader, num_epochs, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef_zZY3C468P",
        "outputId": "2bccd3e0-0bf8-423c-b6a3-02ddf160e2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses: {'loss_ce': tensor(4.2055, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8367, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 7.2639007568359375\n",
            "Losses: {'loss_ce': tensor(3.9161, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8354, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 6.851487159729004\n",
            "Losses: {'loss_ce': tensor(3.6573, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.1035, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8689, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 6.596006870269775\n",
            "Losses: {'loss_ce': tensor(3.5504, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8588, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 6.267131805419922\n",
            "Losses: {'loss_ce': tensor(3.3343, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8675, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 5.945165634155273\n",
            "Losses: {'loss_ce': tensor(3.3584, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0782, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8364, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 5.759361267089844\n",
            "Losses: {'loss_ce': tensor(2.9828, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0683, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8119, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 5.159989833831787\n",
            "Losses: {'loss_ce': tensor(2.8266, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0681, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8536, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 5.042050838470459\n",
            "Losses: {'loss_ce': tensor(2.5399, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0574, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8539, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 4.5408148765563965\n",
            "Losses: {'loss_ce': tensor(2.5263, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0516, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8359, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 4.394100666046143\n",
            "Losses: {'loss_ce': tensor(2.0838, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0489, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8572, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 3.918853282928467\n",
            "Losses: {'loss_ce': tensor(2.0198, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0405, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8362, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 3.6654019355773926\n",
            "Losses: {'loss_ce': tensor(1.8754, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0310, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8216, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 3.31653094291687\n",
            "Losses: {'loss_ce': tensor(1.5995, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0307, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8237, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 3.037778615951538\n",
            "Losses: {'loss_ce': tensor(1.6457, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0261, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8387, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 3.0054991245269775\n",
            "Losses: {'loss_ce': tensor(1.2426, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0260, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8380, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 2.6014516353607178\n",
            "Losses: {'loss_ce': tensor(1.0027, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0219, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8321, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 2.272266387939453\n",
            "Losses: {'loss_ce': tensor(0.9109, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0173, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8212, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 2.0774903297424316\n",
            "Losses: {'loss_ce': tensor(0.8952, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8445, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 2.0662474632263184\n",
            "Losses: {'loss_ce': tensor(0.6126, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8106, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.7123444080352783\n",
            "Losses: {'loss_ce': tensor(0.5810, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0131, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8168, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.66054105758667\n",
            "Losses: {'loss_ce': tensor(0.4563, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0111, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8147, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.4933202266693115\n",
            "Losses: {'loss_ce': tensor(0.3977, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0109, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8226, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.438863754272461\n",
            "Losses: {'loss_ce': tensor(0.3814, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0118, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8226, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.4396837949752808\n",
            "Losses: {'loss_ce': tensor(0.2697, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0123, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8120, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.3269991874694824\n",
            "Epoch: 1, Learning Rate: 0.000010, Avg train loss: 3.5795\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses: {'loss_ce': tensor(0.2069, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0116, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8246, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.2632930278778076\n",
            "Losses: {'loss_ce': tensor(0.1889, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0115, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8406, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.2591526508331299\n",
            "Losses: {'loss_ce': tensor(0.1733, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0102, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8265, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.2047860622406006\n",
            "Losses: {'loss_ce': tensor(0.1626, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0098, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8054, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1645734310150146\n",
            "Losses: {'loss_ce': tensor(0.1281, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0103, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8218, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1554266214370728\n",
            "Losses: {'loss_ce': tensor(0.1123, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0111, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8412, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1764854192733765\n",
            "Losses: {'loss_ce': tensor(0.1016, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0110, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8480, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1705741882324219\n",
            "Losses: {'loss_ce': tensor(0.1087, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0119, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8285, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1741987466812134\n",
            "Losses: {'loss_ce': tensor(0.1198, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0108, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.7937, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1294939517974854\n",
            "Losses: {'loss_ce': tensor(0.1024, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0105, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8136, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.126698613166809\n",
            "Losses: {'loss_ce': tensor(0.1046, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0111, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8022, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1281989812850952\n",
            "Losses: {'loss_ce': tensor(0.1001, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0102, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8122, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.115422248840332\n",
            "Losses: {'loss_ce': tensor(0.0950, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0116, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8106, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1385412216186523\n",
            "Losses: {'loss_ce': tensor(0.0888, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0109, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8195, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.125583291053772\n",
            "Losses: {'loss_ce': tensor(0.0963, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0108, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8047, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1166958808898926\n",
            "Losses: {'loss_ce': tensor(0.0828, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0101, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8319, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1167411804199219\n",
            "Losses: {'loss_ce': tensor(0.0987, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0112, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.7949, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.117524266242981\n",
            "Losses: {'loss_ce': tensor(0.0788, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0115, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8298, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1396507024765015\n",
            "Losses: {'loss_ce': tensor(0.0724, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0110, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8443, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1358529329299927\n",
            "Losses: {'loss_ce': tensor(0.0900, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0108, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.7946, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1005092859268188\n",
            "Losses: {'loss_ce': tensor(0.0790, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0103, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8191, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1031774282455444\n",
            "Losses: {'loss_ce': tensor(0.0779, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0107, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8206, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.112616777420044\n",
            "Losses: {'loss_ce': tensor(0.0728, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0096, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8377, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.102882742881775\n",
            "Losses: {'loss_ce': tensor(0.0740, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0106, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8241, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1095041036605835\n",
            "Losses: {'loss_ce': tensor(0.0683, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0114, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8428, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1398800611495972\n",
            "Epoch: 2, Learning Rate: 0.000009, Avg train loss: 1.1464\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses: {'loss_ce': tensor(0.0846, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0115, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8056, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1202596426010132\n",
            "Losses: {'loss_ce': tensor(0.0651, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0093, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8446, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0958218574523926\n",
            "Losses: {'loss_ce': tensor(0.0668, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0098, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8409, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1034672260284424\n",
            "Losses: {'loss_ce': tensor(0.0734, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0097, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8273, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0944454669952393\n",
            "Losses: {'loss_ce': tensor(0.0712, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0107, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8228, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1085965633392334\n",
            "Losses: {'loss_ce': tensor(0.0693, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0119, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8252, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1330128908157349\n",
            "Losses: {'loss_ce': tensor(0.0700, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0109, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8283, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1158040761947632\n",
            "Losses: {'loss_ce': tensor(0.0666, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0113, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8294, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1216423511505127\n",
            "Losses: {'loss_ce': tensor(0.0653, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0115, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8412, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1361111402511597\n",
            "Losses: {'loss_ce': tensor(0.0701, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0102, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8244, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0985047817230225\n",
            "Losses: {'loss_ce': tensor(0.0696, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0105, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8238, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1027060747146606\n",
            "Losses: {'loss_ce': tensor(0.0697, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0091, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8259, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0772607326507568\n",
            "Losses: {'loss_ce': tensor(0.0705, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0103, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8223, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0997719764709473\n",
            "Losses: {'loss_ce': tensor(0.0629, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0111, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8386, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1244754791259766\n",
            "Losses: {'loss_ce': tensor(0.0637, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0096, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8365, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0919373035430908\n",
            "Losses: {'loss_ce': tensor(0.0607, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0109, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8408, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1196409463882446\n",
            "Losses: {'loss_ce': tensor(0.0684, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0118, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8276, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.13132905960083\n",
            "Losses: {'loss_ce': tensor(0.0693, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0116, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8213, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1226561069488525\n",
            "Losses: {'loss_ce': tensor(0.0681, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0088, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8232, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0668308734893799\n",
            "Losses: {'loss_ce': tensor(0.0681, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0093, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8282, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.082726001739502\n",
            "Losses: {'loss_ce': tensor(0.0658, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0107, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8306, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1097608804702759\n",
            "Losses: {'loss_ce': tensor(0.0753, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0112, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.7995, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0978896617889404\n",
            "Losses: {'loss_ce': tensor(0.0627, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0095, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8368, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0891597270965576\n",
            "Losses: {'loss_ce': tensor(0.0554, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0106, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8514, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1193633079528809\n",
            "Losses: {'loss_ce': tensor(0.0736, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0100, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8077, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.080820083618164\n",
            "Epoch: 3, Learning Rate: 0.000008, Avg train loss: 1.1068\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses: {'loss_ce': tensor(0.0628, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0105, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8333, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1053917407989502\n",
            "Losses: {'loss_ce': tensor(0.0576, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0104, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8433, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.109499454498291\n",
            "Losses: {'loss_ce': tensor(0.0722, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0089, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8119, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.06207275390625\n",
            "Losses: {'loss_ce': tensor(0.0592, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0087, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8436, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0760762691497803\n",
            "Losses: {'loss_ce': tensor(0.0634, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0096, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8326, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0873169898986816\n",
            "Losses: {'loss_ce': tensor(0.0609, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0103, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8351, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1010817289352417\n",
            "Losses: {'loss_ce': tensor(0.0648, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0101, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8243, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0909967422485352\n",
            "Losses: {'loss_ce': tensor(0.0605, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0103, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8364, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1031303405761719\n",
            "Losses: {'loss_ce': tensor(0.0625, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0106, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8347, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1095843315124512\n",
            "Losses: {'loss_ce': tensor(0.0623, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0121, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8299, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1333460807800293\n",
            "Losses: {'loss_ce': tensor(0.0608, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0112, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8368, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1217960119247437\n",
            "Losses: {'loss_ce': tensor(0.0633, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0104, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8274, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.098523736000061\n",
            "Losses: {'loss_ce': tensor(0.0629, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0118, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8285, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1273983716964722\n",
            "Losses: {'loss_ce': tensor(0.0643, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0121, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8241, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.129644751548767\n",
            "Losses: {'loss_ce': tensor(0.0525, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0099, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8553, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1067126989364624\n",
            "Losses: {'loss_ce': tensor(0.0766, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0111, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.7990, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.09696626663208\n",
            "Losses: {'loss_ce': tensor(0.0739, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0088, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8032, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0526409149169922\n",
            "Losses: {'loss_ce': tensor(0.0641, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0103, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8271, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.097114086151123\n",
            "Losses: {'loss_ce': tensor(0.0703, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0121, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8034, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1163250207901\n",
            "Losses: {'loss_ce': tensor(0.0636, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0119, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8295, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.130370020866394\n",
            "Losses: {'loss_ce': tensor(0.0515, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0111, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8518, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.125704050064087\n",
            "Losses: {'loss_ce': tensor(0.0612, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0096, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8323, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0849179029464722\n",
            "Losses: {'loss_ce': tensor(0.0599, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0100, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8329, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0927462577819824\n",
            "Losses: {'loss_ce': tensor(0.0652, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0097, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8203, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0803501605987549\n",
            "Losses: {'loss_ce': tensor(0.0597, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0101, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8330, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0943416357040405\n",
            "Epoch: 4, Learning Rate: 0.000007, Avg train loss: 1.1004\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses: {'loss_ce': tensor(0.0700, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0097, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8128, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0767364501953125\n",
            "Losses: {'loss_ce': tensor(0.0644, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0106, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8215, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0968356132507324\n",
            "Losses: {'loss_ce': tensor(0.0567, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0107, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8425, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1131612062454224\n",
            "Losses: {'loss_ce': tensor(0.0664, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0112, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8155, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1061948537826538\n",
            "Losses: {'loss_ce': tensor(0.0607, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0105, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8284, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0997869968414307\n",
            "Losses: {'loss_ce': tensor(0.0626, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0110, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8246, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.107994794845581\n",
            "Losses: {'loss_ce': tensor(0.0763, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0100, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.7873, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0632973909378052\n",
            "Losses: {'loss_ce': tensor(0.0783, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0098, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.7904, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0646332502365112\n",
            "Losses: {'loss_ce': tensor(0.0565, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0104, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8390, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1029930114746094\n",
            "Losses: {'loss_ce': tensor(0.0600, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0089, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8330, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0701637268066406\n",
            "Losses: {'loss_ce': tensor(0.0810, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0108, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.7765, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0735864639282227\n",
            "Losses: {'loss_ce': tensor(0.0651, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0109, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8198, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1026313304901123\n",
            "Losses: {'loss_ce': tensor(0.0605, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0099, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8294, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0877184867858887\n",
            "Losses: {'loss_ce': tensor(0.0548, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0093, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8451, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0850282907485962\n",
            "Losses: {'loss_ce': tensor(0.0663, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0114, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8173, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1125608682632446\n",
            "Losses: {'loss_ce': tensor(0.0631, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0104, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8235, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0952177047729492\n",
            "Losses: {'loss_ce': tensor(0.0564, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0108, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8390, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1114728450775146\n",
            "Losses: {'loss_ce': tensor(0.0781, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0103, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.7835, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0682578086853027\n",
            "Losses: {'loss_ce': tensor(0.0671, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0099, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8132, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.077346920967102\n",
            "Losses: {'loss_ce': tensor(0.0590, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0096, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8352, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0861947536468506\n",
            "Losses: {'loss_ce': tensor(0.0560, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0107, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8413, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1120615005493164\n",
            "Losses: {'loss_ce': tensor(0.0688, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0106, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8076, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0884299278259277\n",
            "Losses: {'loss_ce': tensor(0.0533, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0110, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8495, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1224180459976196\n",
            "Losses: {'loss_ce': tensor(0.0687, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0109, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8058, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.092400312423706\n",
            "Losses: {'loss_ce': tensor(0.0691, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0104, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8062, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0823919773101807\n",
            "Epoch: 5, Learning Rate: 0.000005, Avg train loss: 1.0974\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses: {'loss_ce': tensor(0.0628, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0108, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8177, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0966492891311646\n",
            "Losses: {'loss_ce': tensor(0.0544, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0104, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8449, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1077771186828613\n",
            "Losses: {'loss_ce': tensor(0.0683, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0103, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8094, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0846610069274902\n",
            "Losses: {'loss_ce': tensor(0.0620, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0105, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8260, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0985116958618164\n",
            "Losses: {'loss_ce': tensor(0.0531, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0102, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8487, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.105488896369934\n",
            "Losses: {'loss_ce': tensor(0.0700, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0109, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8026, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.090298056602478\n",
            "Losses: {'loss_ce': tensor(0.0641, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0098, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8182, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.078971266746521\n",
            "Losses: {'loss_ce': tensor(0.0556, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0091, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8429, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0803512334823608\n",
            "Losses: {'loss_ce': tensor(0.0622, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0097, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8207, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0774238109588623\n",
            "Losses: {'loss_ce': tensor(0.0647, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0117, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8210, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1200306415557861\n",
            "Losses: {'loss_ce': tensor(0.0598, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0115, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8286, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1175777912139893\n",
            "Losses: {'loss_ce': tensor(0.0597, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0096, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8322, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0835397243499756\n",
            "Losses: {'loss_ce': tensor(0.0666, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0099, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8126, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.077941656112671\n",
            "Losses: {'loss_ce': tensor(0.0739, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0088, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.7995, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.049436330795288\n",
            "Losses: {'loss_ce': tensor(0.0489, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0103, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8591, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1148536205291748\n",
            "Losses: {'loss_ce': tensor(0.0559, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0100, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8388, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.094433069229126\n",
            "Losses: {'loss_ce': tensor(0.0587, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0103, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8288, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0942890644073486\n",
            "Losses: {'loss_ce': tensor(0.0583, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0104, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8310, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0964677333831787\n",
            "Losses: {'loss_ce': tensor(0.0857, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0107, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.7652, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0657535791397095\n",
            "Losses: {'loss_ce': tensor(0.0688, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0107, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8031, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0851407051086426\n",
            "Losses: {'loss_ce': tensor(0.0509, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0109, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8526, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1210302114486694\n",
            "Losses: {'loss_ce': tensor(0.0637, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0111, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8194, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1043708324432373\n",
            "Losses: {'loss_ce': tensor(0.0624, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0111, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8199, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.104028582572937\n",
            "Losses: {'loss_ce': tensor(0.0581, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0105, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8327, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1013131141662598\n",
            "Losses: {'loss_ce': tensor(0.0615, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0102, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8237, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0893890857696533\n",
            "Epoch: 6, Learning Rate: 0.000003, Avg train loss: 1.0956\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses: {'loss_ce': tensor(0.0595, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0109, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8302, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1085443496704102\n",
            "Losses: {'loss_ce': tensor(0.0542, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0108, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8456, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1159751415252686\n",
            "Losses: {'loss_ce': tensor(0.0636, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0111, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8182, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1044306755065918\n",
            "Losses: {'loss_ce': tensor(0.0591, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0102, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8304, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0940531492233276\n",
            "Losses: {'loss_ce': tensor(0.0682, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0103, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8057, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0788899660110474\n",
            "Losses: {'loss_ce': tensor(0.0562, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0101, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8383, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0958458185195923\n",
            "Losses: {'loss_ce': tensor(0.0634, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0092, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8205, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.067021131515503\n",
            "Losses: {'loss_ce': tensor(0.0593, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0096, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8262, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0783545970916748\n",
            "Losses: {'loss_ce': tensor(0.0553, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0104, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8397, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1026160717010498\n",
            "Losses: {'loss_ce': tensor(0.0682, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0099, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8073, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.074060082435608\n",
            "Losses: {'loss_ce': tensor(0.0570, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0091, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8371, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0766379833221436\n",
            "Losses: {'loss_ce': tensor(0.0599, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0105, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8253, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0956273078918457\n",
            "Losses: {'loss_ce': tensor(0.0615, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0109, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8212, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.100244402885437\n",
            "Losses: {'loss_ce': tensor(0.0595, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0108, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8232, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0988343954086304\n",
            "Losses: {'loss_ce': tensor(0.0636, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0112, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8176, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1050121784210205\n",
            "Losses: {'loss_ce': tensor(0.0604, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0101, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8308, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0931713581085205\n",
            "Losses: {'loss_ce': tensor(0.0578, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0117, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8350, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1270235776901245\n",
            "Losses: {'loss_ce': tensor(0.0595, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0116, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8269, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1181225776672363\n",
            "Losses: {'loss_ce': tensor(0.0726, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0100, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.7970, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.068666934967041\n",
            "Losses: {'loss_ce': tensor(0.0696, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0112, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.7998, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0942611694335938\n",
            "Losses: {'loss_ce': tensor(0.0581, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0102, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8330, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0943360328674316\n",
            "Losses: {'loss_ce': tensor(0.0539, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0106, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8448, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1102919578552246\n",
            "Losses: {'loss_ce': tensor(0.0631, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0105, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8198, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0919859409332275\n",
            "Losses: {'loss_ce': tensor(0.0569, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0095, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8333, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0811407566070557\n",
            "Losses: {'loss_ce': tensor(0.0568, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0121, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8362, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1348975896835327\n",
            "Epoch: 7, Learning Rate: 0.000002, Avg train loss: 1.0947\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses: {'loss_ce': tensor(0.0750, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0112, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.7862, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0855634212493896\n",
            "Losses: {'loss_ce': tensor(0.0574, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0114, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8347, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1205283403396606\n",
            "Losses: {'loss_ce': tensor(0.0673, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0103, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8102, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0826910734176636\n",
            "Losses: {'loss_ce': tensor(0.0608, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0088, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8241, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0605379343032837\n",
            "Losses: {'loss_ce': tensor(0.0623, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0114, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8191, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1095223426818848\n",
            "Losses: {'loss_ce': tensor(0.0618, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0103, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8221, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0899850130081177\n",
            "Losses: {'loss_ce': tensor(0.0529, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0113, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8438, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1232860088348389\n",
            "Losses: {'loss_ce': tensor(0.0599, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0104, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8276, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.095578670501709\n",
            "Losses: {'loss_ce': tensor(0.0627, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0096, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8191, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0729639530181885\n",
            "Losses: {'loss_ce': tensor(0.0590, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0092, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8253, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0675685405731201\n",
            "Losses: {'loss_ce': tensor(0.0619, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0109, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8209, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1003204584121704\n",
            "Losses: {'loss_ce': tensor(0.0578, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0102, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8358, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0971763134002686\n",
            "Losses: {'loss_ce': tensor(0.0639, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0097, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8180, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.07633376121521\n",
            "Losses: {'loss_ce': tensor(0.0661, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0109, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8102, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0938704013824463\n",
            "Losses: {'loss_ce': tensor(0.0621, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0095, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8198, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0728747844696045\n",
            "Losses: {'loss_ce': tensor(0.0702, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0128, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8007, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1277869939804077\n",
            "Losses: {'loss_ce': tensor(0.0491, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0100, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8562, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1044687032699585\n",
            "Losses: {'loss_ce': tensor(0.0630, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0096, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8187, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0738295316696167\n",
            "Losses: {'loss_ce': tensor(0.0573, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0096, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8331, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0816211700439453\n",
            "Losses: {'loss_ce': tensor(0.0657, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0125, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8107, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.125942587852478\n",
            "Losses: {'loss_ce': tensor(0.0502, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0106, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8537, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1155006885528564\n",
            "Losses: {'loss_ce': tensor(0.0725, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0088, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.7934, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0422407388687134\n",
            "Losses: {'loss_ce': tensor(0.0706, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0095, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.7987, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.059096336364746\n",
            "Losses: {'loss_ce': tensor(0.0603, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0100, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8257, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0867218971252441\n",
            "Losses: {'loss_ce': tensor(0.0623, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0100, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8212, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.083296537399292\n",
            "Epoch: 8, Learning Rate: 0.000001, Avg train loss: 1.0941\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses: {'loss_ce': tensor(0.0619, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0090, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8190, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0609163045883179\n",
            "Losses: {'loss_ce': tensor(0.0525, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0100, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8463, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0980701446533203\n",
            "Losses: {'loss_ce': tensor(0.0601, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0106, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8275, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0985679626464844\n",
            "Losses: {'loss_ce': tensor(0.0542, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0123, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8406, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1411304473876953\n",
            "Losses: {'loss_ce': tensor(0.0540, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0114, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8420, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1241260766983032\n",
            "Losses: {'loss_ce': tensor(0.0640, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0096, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8117, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0673563480377197\n",
            "Losses: {'loss_ce': tensor(0.0622, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0111, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8224, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1068103313446045\n",
            "Losses: {'loss_ce': tensor(0.0596, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0099, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8304, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0870225429534912\n",
            "Losses: {'loss_ce': tensor(0.0731, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0112, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.7923, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0888851881027222\n",
            "Losses: {'loss_ce': tensor(0.0558, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0113, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8341, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1163594722747803\n",
            "Losses: {'loss_ce': tensor(0.0523, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0107, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8457, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1121906042099\n",
            "Losses: {'loss_ce': tensor(0.0544, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0094, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8379, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.079365849494934\n",
            "Losses: {'loss_ce': tensor(0.0585, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0089, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8293, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.066162347793579\n",
            "Losses: {'loss_ce': tensor(0.0693, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0131, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.7982, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1291427612304688\n",
            "Losses: {'loss_ce': tensor(0.0610, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0090, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8245, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.066311001777649\n",
            "Losses: {'loss_ce': tensor(0.0583, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0106, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8300, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0993331670761108\n",
            "Losses: {'loss_ce': tensor(0.0606, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0099, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8275, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0862915515899658\n",
            "Losses: {'loss_ce': tensor(0.0638, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0099, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8152, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.076249361038208\n",
            "Losses: {'loss_ce': tensor(0.0591, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0121, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8258, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1267194747924805\n",
            "Losses: {'loss_ce': tensor(0.0571, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0095, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8329, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.079629898071289\n",
            "Losses: {'loss_ce': tensor(0.0618, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0108, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8180, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0960865020751953\n",
            "Losses: {'loss_ce': tensor(0.0594, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0122, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8224, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1264609098434448\n",
            "Losses: {'loss_ce': tensor(0.0598, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0122, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8247, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1281901597976685\n",
            "Losses: {'loss_ce': tensor(0.0638, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0107, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8174, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0956387519836426\n",
            "Losses: {'loss_ce': tensor(0.0676, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0110, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8034, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0916597843170166\n",
            "Epoch: 9, Learning Rate: 0.000000, Avg train loss: 1.0938\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses: {'loss_ce': tensor(0.0589, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0106, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8296, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1012928485870361\n",
            "Losses: {'loss_ce': tensor(0.0550, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0104, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8406, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1041566133499146\n",
            "Losses: {'loss_ce': tensor(0.0624, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0099, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8188, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.078826665878296\n",
            "Losses: {'loss_ce': tensor(0.0535, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0110, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8437, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.116767168045044\n",
            "Losses: {'loss_ce': tensor(0.0564, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0112, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8363, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1157395839691162\n",
            "Losses: {'loss_ce': tensor(0.0610, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0096, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8211, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0733091831207275\n",
            "Losses: {'loss_ce': tensor(0.0596, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0103, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8258, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0912410020828247\n",
            "Losses: {'loss_ce': tensor(0.0584, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0100, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8306, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0884153842926025\n",
            "Losses: {'loss_ce': tensor(0.0616, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0117, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8202, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1149300336837769\n",
            "Losses: {'loss_ce': tensor(0.0538, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0111, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8414, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.1164897680282593\n",
            "Losses: {'loss_ce': tensor(0.0617, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0098, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8231, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0808446407318115\n",
            "Losses: {'loss_ce': tensor(0.0573, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0099, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8329, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0873595476150513\n",
            "Losses: {'loss_ce': tensor(0.0643, device='cuda:0', grad_fn=<NllLoss2DBackward0>), 'loss_mask': tensor(0.0099, device='cuda:0', grad_fn=<DivBackward0>), 'loss_dice': tensor(0.8162, device='cuda:0', grad_fn=<DivBackward0>)}\n",
            "Current loss: 1.0794918537139893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Evaluate\n",
        "def predict_masks_for_validation(encoder, decoder, valloader):\n",
        "    val_results = []\n",
        "    val_masks = []\n",
        "\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    for i, data in enumerate(valloader, 0):\n",
        "        inputs, labels, masks = data\n",
        "        inputs, labels, masks = inputs.to(device), labels.to(device), masks.to(device)\n",
        "\n",
        "        inputs = inputs[:, :11]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass through encoder to get the embeddings\n",
        "        predicted_embeddings = encoder(inputs.transpose(1, 2))\n",
        "\n",
        "        # Reshape predicted embeddings to (b t) (h w) m\n",
        "        predicted_embeddings = rearrange(predicted_embeddings, 'b (t n) m -> b t n m', t=22)\n",
        "        predicted_embeddings = rearrange(predicted_embeddings, 'b t n m -> (b t) n m')\n",
        "\n",
        "        # forward pass through decoder to get the masks\n",
        "        outputs = decoder(predicted_embeddings)\n",
        "\n",
        "        # use argmax to go from logits to classes\n",
        "        prediction = torch.argmax(outputs, 1)\n",
        "\n",
        "        val_results.append(prediction.cpu())  # Move tensor to CPU and append\n",
        "        val_masks.append(masks.cpu())  # Move tensor to CPU and append\n",
        "\n",
        "    results_tensor = torch.cat(val_results, dim=0)  # Concatenate tensors\n",
        "    mask_tensor = torch.cat(val_masks, dim=0)  # Concatenate tensors\n",
        "    print(results_tensor.shape)\n",
        "    print(mask_tensor.shape)\n",
        "    #jaccard = compute_jaccard(mask_tensor, results_tensor, device)\n",
        "    return results_tensor, mask_tensor\n",
        "\n",
        "\n",
        "\n",
        "### Evaluate\n",
        "def predict_final_masks_for_validation(encoder, decoder, valloader):\n",
        "    val_results = []\n",
        "    val_masks = []\n",
        "\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    for i, data in enumerate(valloader, 0):\n",
        "        inputs, labels, masks = data\n",
        "        inputs, labels, masks = inputs.to(device), labels.to(device), masks.to(device)\n",
        "\n",
        "        inputs = inputs[:, :11]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass through encoder to get the embeddings\n",
        "        predicted_embeddings = encoder(inputs.transpose(1, 2))\n",
        "\n",
        "        # Reshape predicted embeddings to (b t) (h w) m\n",
        "        predicted_embeddings = rearrange(predicted_embeddings, 'b (t n) m -> b t n m', t=22) # nicer way of doing this surely\n",
        "        predicted_embeddings = rearrange(predicted_embeddings, 'b t n m -> (b t) n m')\n",
        "\n",
        "        # forward pass through decoder to get the masks\n",
        "        outputs = decoder(predicted_embeddings)[-1:]\n",
        "\n",
        "        # use argmax to go from logits to classes\n",
        "        prediction = torch.argmax(outputs, 1)\n",
        "\n",
        "\n",
        "        val_results.append(prediction) # this only works when batch_size = 1\n",
        "        val_masks.append(masks)\n",
        "\n",
        "    results_tensor = torch.stack(val_results)\n",
        "    mask_tensor = torch.stack(val_masks)\n",
        "    print(results_tensor.shape)\n",
        "    print(mask_tensor.shape)\n",
        "    #jaccard = compute_jaccard(mask_tensor, results_tensor, device)\n",
        "    return results_tensor, mask_tensor\n"
      ],
      "metadata": {
        "id": "nLbttx7vci2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Evaluate first model\n",
        "#Load the validation datasets\n",
        "batch_size = 1\n",
        "valloader = load_data('Dataset_Student/val/data/', 'Dataset_Student/val/annotations.txt', batch_size)\n",
        "#compute results\n",
        "results, jaccard = predict_masks_for_validation(encoder, decoder, valloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOCC77SQ3X5j",
        "outputId": "181b5c2b-854c-4ebb-f421-7f3a13122b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([22000, 160, 240])\n",
            "torch.Size([1000, 22, 160, 240])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(results)\n",
        "torch.unique(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "tQHQyGad8IYT",
        "outputId": "f33762f9-2833-4dcb-aed8-2b87a042a497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b862a410a834>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Finetuning training loop\n",
        "def train_finetuning_model(epoch, decoder, encoder, criterion, optimizer_decoder, optimizer_encoder, scheduler_decoder, scheduler_encoder, dataloader, validationloader, num_epochs, device):\n",
        "    while epoch < num_epochs:\n",
        "        decoder.train()\n",
        "        encoder.train()  # Set encoder to train mode\n",
        "\n",
        "        train_loss = 0\n",
        "\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            inputs, labels, target_masks = data \n",
        "            inputs, labels, target_masks = inputs.to(device), labels.to(device), target_masks.to(device)\n",
        "\n",
        "            inputs = inputs[:, :11] # Remove depending on preference\n",
        "\n",
        "            optimizer_decoder.zero_grad()\n",
        "            optimizer_encoder.zero_grad()  # Add optimizer for encoder\n",
        "\n",
        "            ### forward pass through encoder to get the embeddings\n",
        "            predicted_embeddings = encoder(inputs.transpose(1, 2)) # batch x frames*num_patches x embedding dim\n",
        "\n",
        "            # Reshape predicted embeddings to (b t) (h w) m\n",
        "            predicted_embeddings = rearrange(predicted_embeddings, 'b (t n) m -> b t n m', t=22)\n",
        "            predicted_embeddings = rearrange(predicted_embeddings, 'b t n m -> (b t) n m')\n",
        "\n",
        "            target_masks = rearrange(target_masks, 'b t n m -> (b t) n m')\n",
        "\n",
        "            ### forward pass through decoder to get the masks\n",
        "            outputs = decoder(predicted_embeddings)\n",
        "\n",
        "            ### compute the loss and step\n",
        "            loss = criterion(outputs, target_masks, -1)\n",
        "            train_loss += loss.item()\n",
        "            loss.backward()\n",
        "\n",
        "            # Implementing the gradient clipping\n",
        "            utils.clip_grad_norm_(decoder.parameters(), 1.0)\n",
        "\n",
        "            optimizer_decoder.step()\n",
        "            optimizer_encoder.step()  # Add step for encoder optimizer\n",
        "\n",
        "            # Update the scheduler learning rate\n",
        "            scheduler_decoder.step()\n",
        "            scheduler_encoder.step()  # Add step for encoder scheduler\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Current loss: {loss.item()}\")\n",
        "\n",
        "        avg_epoch_loss = train_loss / len(dataloader)\n",
        "\n",
        "        current_lr_decoder = optimizer_decoder.param_groups[0]['lr']\n",
        "        current_lr_encoder = optimizer_encoder.param_groups[0]['lr']\n",
        "        print(f\"Epoch: {epoch + 1}, Decoder Learning Rate: {current_lr_decoder:.6f}, Encoder Learning Rate: {current_lr_encoder:.6f}, Avg train loss: {avg_epoch_loss:.4f}\")\n",
        "\n",
        "        epoch += 1\n",
        "\n",
        "        # Checkpoint\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': decoder.module.state_dict() if torch.cuda.device_count() > 1 else decoder.state_dict(),\n",
        "            'optimizer_state_dict': optimizer_decoder.state_dict(),\n",
        "            'scheduler_state_dict': scheduler_decoder.state_dict()\n",
        "            }, \"checkpoint_decoder_1.pkl\")\n",
        "\n",
        "    return {\n",
        "        \"epochs\": epoch,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"model\": decoder\n",
        "            }\n"
      ],
      "metadata": {
        "id": "UYYoU5Jl_p1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Training with finetuning the projector\n",
        "### Initialize JEPA\n",
        "print(\"Remember to reinitialize the JEPA first, and make sure you run all the classes in order.\")\n",
        "\n",
        "### Initialize Decoder\n",
        "decoder = ATMHead(img_size=128, H=160, W=240, in_channels=768, use_stages=1)\n",
        "decoder.to(device)\n",
        "\n",
        "### Epochs, Optimizer, Criterion and Scheduler\n",
        "criterion = ATMLoss(49, 1) ## 48 classes + 1 background which will be added in the loss\n",
        "criterion.to(device)\n",
        "\n",
        "learning_rate_decoder_initial = 1e-5\n",
        "learning_rate_decoder_final = 1e-7\n",
        "learning_rate_predictor_initial = 1e-8\n",
        "learning_rate_predictor_final = 1e-10\n",
        "optimizer_decoder = torch.optim.AdamW(decoder.parameters(), lr=learning_rate_decoder_initial, weight_decay=0.05)\n",
        "optimizer_encoder = torch.optim.Adam(encoder.predictor.parameters(), lr=learning_rate_predictor_initial, weight_decay=0.05)\n",
        "\n",
        "num_epochs = 10\n",
        "total_steps = num_epochs * len(trainloader)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=final_lr)\n",
        "\n",
        "epoch = 0\n",
        "encoder.mode = \"test\"\n",
        "results = train_finetuning_model(epoch, decoder, encoder, criterion, optimizer, scheduler, trainloader, valloader, num_epochs, device)"
      ],
      "metadata": {
        "id": "PBjsG_EUcH1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Evaluate"
      ],
      "metadata": {
        "id": "3lDkReQlcl9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Training without the predictor, trying to get the model to predict future mask from 11 frames input"
      ],
      "metadata": {
        "id": "N12NEMtScQW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Evaluate"
      ],
      "metadata": {
        "id": "htnV_i3FcnVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Training using the VPTR decoder (which includes predictor)"
      ],
      "metadata": {
        "id": "7X0hLce6ce6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Download and unzip hidden data set for leaderboard\n",
        "!gdown https://drive.google.com/uc?id=1j6WOMJ_gpTl2--ddt9htMAW8ObPH-T0h\n",
        "!unzip hidden.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7gpClNIPOIR",
        "outputId": "a32c744c-6aa8-4189-81a1-599147e35fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  inflating: hidden/video_15052/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15052/._image_5.png  \n",
            "  inflating: hidden/video_15052/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15052/._image_7.png  \n",
            "  inflating: hidden/video_15052/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15052/._image_6.png  \n",
            "  inflating: hidden/video_15294/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15294/._image_10.png  \n",
            "  inflating: hidden/video_15294/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15294/._image_8.png  \n",
            "  inflating: hidden/video_15294/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15294/._image_9.png  \n",
            "  inflating: hidden/video_15294/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15294/._image_2.png  \n",
            "  inflating: hidden/video_15294/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15294/._image_3.png  \n",
            "  inflating: hidden/video_15294/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15294/._image_1.png  \n",
            "  inflating: hidden/video_15294/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15294/._image_0.png  \n",
            "  inflating: hidden/video_15294/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15294/._image_4.png  \n",
            "  inflating: hidden/video_15294/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15294/._image_5.png  \n",
            "  inflating: hidden/video_15294/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15294/._image_7.png  \n",
            "  inflating: hidden/video_15294/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15294/._image_6.png  \n",
            "  inflating: hidden/video_16411/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16411/._image_10.png  \n",
            "  inflating: hidden/video_16411/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16411/._image_8.png  \n",
            "  inflating: hidden/video_16411/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16411/._image_9.png  \n",
            "  inflating: hidden/video_16411/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16411/._image_2.png  \n",
            "  inflating: hidden/video_16411/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16411/._image_3.png  \n",
            "  inflating: hidden/video_16411/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16411/._image_1.png  \n",
            "  inflating: hidden/video_16411/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16411/._image_0.png  \n",
            "  inflating: hidden/video_16411/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16411/._image_4.png  \n",
            "  inflating: hidden/video_16411/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16411/._image_5.png  \n",
            "  inflating: hidden/video_16411/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16411/._image_7.png  \n",
            "  inflating: hidden/video_16411/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16411/._image_6.png  \n",
            "  inflating: hidden/video_16623/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16623/._image_10.png  \n",
            "  inflating: hidden/video_16623/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16623/._image_8.png  \n",
            "  inflating: hidden/video_16623/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16623/._image_9.png  \n",
            "  inflating: hidden/video_16623/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16623/._image_2.png  \n",
            "  inflating: hidden/video_16623/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16623/._image_3.png  \n",
            "  inflating: hidden/video_16623/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16623/._image_1.png  \n",
            "  inflating: hidden/video_16623/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16623/._image_0.png  \n",
            "  inflating: hidden/video_16623/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16623/._image_4.png  \n",
            "  inflating: hidden/video_16623/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16623/._image_5.png  \n",
            "  inflating: hidden/video_16623/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16623/._image_7.png  \n",
            "  inflating: hidden/video_16623/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16623/._image_6.png  \n",
            "  inflating: hidden/video_16247/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16247/._image_10.png  \n",
            "  inflating: hidden/video_16247/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16247/._image_8.png  \n",
            "  inflating: hidden/video_16247/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16247/._image_9.png  \n",
            "  inflating: hidden/video_16247/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16247/._image_2.png  \n",
            "  inflating: hidden/video_16247/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16247/._image_3.png  \n",
            "  inflating: hidden/video_16247/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16247/._image_1.png  \n",
            "  inflating: hidden/video_16247/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16247/._image_0.png  \n",
            "  inflating: hidden/video_16247/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16247/._image_4.png  \n",
            "  inflating: hidden/video_16247/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16247/._image_5.png  \n",
            "  inflating: hidden/video_16247/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16247/._image_7.png  \n",
            "  inflating: hidden/video_16247/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16247/._image_6.png  \n",
            "  inflating: hidden/video_16849/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16849/._image_10.png  \n",
            "  inflating: hidden/video_16849/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16849/._image_8.png  \n",
            "  inflating: hidden/video_16849/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16849/._image_9.png  \n",
            "  inflating: hidden/video_16849/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16849/._image_2.png  \n",
            "  inflating: hidden/video_16849/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16849/._image_3.png  \n",
            "  inflating: hidden/video_16849/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16849/._image_1.png  \n",
            "  inflating: hidden/video_16849/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16849/._image_0.png  \n",
            "  inflating: hidden/video_16849/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16849/._image_4.png  \n",
            "  inflating: hidden/video_16849/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16849/._image_5.png  \n",
            "  inflating: hidden/video_16849/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16849/._image_7.png  \n",
            "  inflating: hidden/video_16849/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16849/._image_6.png  \n",
            "  inflating: hidden/video_16075/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16075/._image_10.png  \n",
            "  inflating: hidden/video_16075/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16075/._image_8.png  \n",
            "  inflating: hidden/video_16075/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16075/._image_9.png  \n",
            "  inflating: hidden/video_16075/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16075/._image_2.png  \n",
            "  inflating: hidden/video_16075/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16075/._image_3.png  \n",
            "  inflating: hidden/video_16075/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16075/._image_1.png  \n",
            "  inflating: hidden/video_16075/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16075/._image_0.png  \n",
            "  inflating: hidden/video_16075/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16075/._image_4.png  \n",
            "  inflating: hidden/video_16075/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16075/._image_5.png  \n",
            "  inflating: hidden/video_16075/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16075/._image_7.png  \n",
            "  inflating: hidden/video_16075/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16075/._image_6.png  \n",
            "  inflating: hidden/video_15851/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15851/._image_10.png  \n",
            "  inflating: hidden/video_15851/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15851/._image_8.png  \n",
            "  inflating: hidden/video_15851/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15851/._image_9.png  \n",
            "  inflating: hidden/video_15851/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15851/._image_2.png  \n",
            "  inflating: hidden/video_15851/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15851/._image_3.png  \n",
            "  inflating: hidden/video_15851/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15851/._image_1.png  \n",
            "  inflating: hidden/video_15851/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15851/._image_0.png  \n",
            "  inflating: hidden/video_15851/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15851/._image_4.png  \n",
            "  inflating: hidden/video_15851/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15851/._image_5.png  \n",
            "  inflating: hidden/video_15851/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15851/._image_7.png  \n",
            "  inflating: hidden/video_15851/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15851/._image_6.png  \n",
            "  inflating: hidden/video_16882/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16882/._image_10.png  \n",
            "  inflating: hidden/video_16882/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16882/._image_8.png  \n",
            "  inflating: hidden/video_16882/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16882/._image_9.png  \n",
            "  inflating: hidden/video_16882/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16882/._image_2.png  \n",
            "  inflating: hidden/video_16882/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16882/._image_3.png  \n",
            "  inflating: hidden/video_16882/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16882/._image_1.png  \n",
            "  inflating: hidden/video_16882/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16882/._image_0.png  \n",
            "  inflating: hidden/video_16882/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16882/._image_4.png  \n",
            "  inflating: hidden/video_16882/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16882/._image_5.png  \n",
            "  inflating: hidden/video_16882/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16882/._image_7.png  \n",
            "  inflating: hidden/video_16882/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16882/._image_6.png  \n",
            "  inflating: hidden/video_15409/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15409/._image_10.png  \n",
            "  inflating: hidden/video_15409/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15409/._image_8.png  \n",
            "  inflating: hidden/video_15409/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15409/._image_9.png  \n",
            "  inflating: hidden/video_15409/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15409/._image_2.png  \n",
            "  inflating: hidden/video_15409/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15409/._image_3.png  \n",
            "  inflating: hidden/video_15409/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15409/._image_1.png  \n",
            "  inflating: hidden/video_15409/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15409/._image_0.png  \n",
            "  inflating: hidden/video_15409/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15409/._image_4.png  \n",
            "  inflating: hidden/video_15409/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15409/._image_5.png  \n",
            "  inflating: hidden/video_15409/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15409/._image_7.png  \n",
            "  inflating: hidden/video_15409/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15409/._image_6.png  \n",
            "  inflating: hidden/video_16876/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16876/._image_10.png  \n",
            "  inflating: hidden/video_16876/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16876/._image_8.png  \n",
            "  inflating: hidden/video_16876/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16876/._image_9.png  \n",
            "  inflating: hidden/video_16876/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16876/._image_2.png  \n",
            "  inflating: hidden/video_16876/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16876/._image_3.png  \n",
            "  inflating: hidden/video_16876/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16876/._image_1.png  \n",
            "  inflating: hidden/video_16876/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16876/._image_0.png  \n",
            "  inflating: hidden/video_16876/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16876/._image_4.png  \n",
            "  inflating: hidden/video_16876/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16876/._image_5.png  \n",
            "  inflating: hidden/video_16876/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16876/._image_7.png  \n",
            "  inflating: hidden/video_16876/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16876/._image_6.png  \n",
            "  inflating: hidden/video_16278/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16278/._image_10.png  \n",
            "  inflating: hidden/video_16278/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16278/._image_8.png  \n",
            "  inflating: hidden/video_16278/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16278/._image_9.png  \n",
            "  inflating: hidden/video_16278/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16278/._image_2.png  \n",
            "  inflating: hidden/video_16278/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16278/._image_3.png  \n",
            "  inflating: hidden/video_16278/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16278/._image_1.png  \n",
            "  inflating: hidden/video_16278/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16278/._image_0.png  \n",
            "  inflating: hidden/video_16278/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16278/._image_4.png  \n",
            "  inflating: hidden/video_16278/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16278/._image_5.png  \n",
            "  inflating: hidden/video_16278/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16278/._image_7.png  \n",
            "  inflating: hidden/video_16278/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16278/._image_6.png  \n",
            "  inflating: hidden/video_15099/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15099/._image_10.png  \n",
            "  inflating: hidden/video_15099/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15099/._image_8.png  \n",
            "  inflating: hidden/video_15099/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15099/._image_9.png  \n",
            "  inflating: hidden/video_15099/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15099/._image_2.png  \n",
            "  inflating: hidden/video_15099/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15099/._image_3.png  \n",
            "  inflating: hidden/video_15099/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15099/._image_1.png  \n",
            "  inflating: hidden/video_15099/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15099/._image_0.png  \n",
            "  inflating: hidden/video_15099/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15099/._image_4.png  \n",
            "  inflating: hidden/video_15099/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15099/._image_5.png  \n",
            "  inflating: hidden/video_15099/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15099/._image_7.png  \n",
            "  inflating: hidden/video_15099/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15099/._image_6.png  \n",
            "  inflating: hidden/video_15256/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15256/._image_10.png  \n",
            "  inflating: hidden/video_15256/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15256/._image_8.png  \n",
            "  inflating: hidden/video_15256/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15256/._image_9.png  \n",
            "  inflating: hidden/video_15256/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15256/._image_2.png  \n",
            "  inflating: hidden/video_15256/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15256/._image_3.png  \n",
            "  inflating: hidden/video_15256/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15256/._image_1.png  \n",
            "  inflating: hidden/video_15256/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15256/._image_0.png  \n",
            "  inflating: hidden/video_15256/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15256/._image_4.png  \n",
            "  inflating: hidden/video_15256/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15256/._image_5.png  \n",
            "  inflating: hidden/video_15256/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15256/._image_7.png  \n",
            "  inflating: hidden/video_15256/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15256/._image_6.png  \n",
            "  inflating: hidden/video_15064/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15064/._image_10.png  \n",
            "  inflating: hidden/video_15064/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15064/._image_8.png  \n",
            "  inflating: hidden/video_15064/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15064/._image_9.png  \n",
            "  inflating: hidden/video_15064/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15064/._image_2.png  \n",
            "  inflating: hidden/video_15064/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15064/._image_3.png  \n",
            "  inflating: hidden/video_15064/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15064/._image_1.png  \n",
            "  inflating: hidden/video_15064/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15064/._image_0.png  \n",
            "  inflating: hidden/video_15064/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15064/._image_4.png  \n",
            "  inflating: hidden/video_15064/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15064/._image_5.png  \n",
            "  inflating: hidden/video_15064/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15064/._image_7.png  \n",
            "  inflating: hidden/video_15064/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15064/._image_6.png  \n",
            "  inflating: hidden/video_15858/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15858/._image_10.png  \n",
            "  inflating: hidden/video_15858/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15858/._image_8.png  \n",
            "  inflating: hidden/video_15858/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15858/._image_9.png  \n",
            "  inflating: hidden/video_15858/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15858/._image_2.png  \n",
            "  inflating: hidden/video_15858/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15858/._image_3.png  \n",
            "  inflating: hidden/video_15858/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15858/._image_1.png  \n",
            "  inflating: hidden/video_15858/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15858/._image_0.png  \n",
            "  inflating: hidden/video_15858/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15858/._image_4.png  \n",
            "  inflating: hidden/video_15858/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15858/._image_5.png  \n",
            "  inflating: hidden/video_15858/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15858/._image_7.png  \n",
            "  inflating: hidden/video_15858/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15858/._image_6.png  \n",
            "  inflating: hidden/video_15400/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15400/._image_10.png  \n",
            "  inflating: hidden/video_15400/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15400/._image_8.png  \n",
            "  inflating: hidden/video_15400/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15400/._image_9.png  \n",
            "  inflating: hidden/video_15400/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15400/._image_2.png  \n",
            "  inflating: hidden/video_15400/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15400/._image_3.png  \n",
            "  inflating: hidden/video_15400/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15400/._image_1.png  \n",
            "  inflating: hidden/video_15400/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15400/._image_0.png  \n",
            "  inflating: hidden/video_15400/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15400/._image_4.png  \n",
            "  inflating: hidden/video_15400/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15400/._image_5.png  \n",
            "  inflating: hidden/video_15400/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15400/._image_7.png  \n",
            "  inflating: hidden/video_15400/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15400/._image_6.png  \n",
            "  inflating: hidden/video_16285/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16285/._image_10.png  \n",
            "  inflating: hidden/video_16285/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16285/._image_8.png  \n",
            "  inflating: hidden/video_16285/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16285/._image_9.png  \n",
            "  inflating: hidden/video_16285/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16285/._image_2.png  \n",
            "  inflating: hidden/video_16285/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16285/._image_3.png  \n",
            "  inflating: hidden/video_16285/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16285/._image_1.png  \n",
            "  inflating: hidden/video_16285/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16285/._image_0.png  \n",
            "  inflating: hidden/video_16285/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16285/._image_4.png  \n",
            "  inflating: hidden/video_16285/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16285/._image_5.png  \n",
            "  inflating: hidden/video_16285/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16285/._image_7.png  \n",
            "  inflating: hidden/video_16285/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16285/._image_6.png  \n",
            "  inflating: hidden/video_15632/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15632/._image_10.png  \n",
            "  inflating: hidden/video_15632/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15632/._image_8.png  \n",
            "  inflating: hidden/video_15632/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15632/._image_9.png  \n",
            "  inflating: hidden/video_15632/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15632/._image_2.png  \n",
            "  inflating: hidden/video_15632/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15632/._image_3.png  \n",
            "  inflating: hidden/video_15632/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15632/._image_1.png  \n",
            "  inflating: hidden/video_15632/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15632/._image_0.png  \n",
            "  inflating: hidden/video_15632/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15632/._image_4.png  \n",
            "  inflating: hidden/video_15632/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15632/._image_5.png  \n",
            "  inflating: hidden/video_15632/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15632/._image_7.png  \n",
            "  inflating: hidden/video_15632/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15632/._image_6.png  \n",
            "  inflating: hidden/video_16271/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16271/._image_10.png  \n",
            "  inflating: hidden/video_16271/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16271/._image_8.png  \n",
            "  inflating: hidden/video_16271/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16271/._image_9.png  \n",
            "  inflating: hidden/video_16271/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16271/._image_2.png  \n",
            "  inflating: hidden/video_16271/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16271/._image_3.png  \n",
            "  inflating: hidden/video_16271/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16271/._image_1.png  \n",
            "  inflating: hidden/video_16271/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16271/._image_0.png  \n",
            "  inflating: hidden/video_16271/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16271/._image_4.png  \n",
            "  inflating: hidden/video_16271/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16271/._image_5.png  \n",
            "  inflating: hidden/video_16271/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16271/._image_7.png  \n",
            "  inflating: hidden/video_16271/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16271/._image_6.png  \n",
            "  inflating: hidden/video_16043/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16043/._image_10.png  \n",
            "  inflating: hidden/video_16043/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16043/._image_8.png  \n",
            "  inflating: hidden/video_16043/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16043/._image_9.png  \n",
            "  inflating: hidden/video_16043/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16043/._image_2.png  \n",
            "  inflating: hidden/video_16043/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16043/._image_3.png  \n",
            "  inflating: hidden/video_16043/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16043/._image_1.png  \n",
            "  inflating: hidden/video_16043/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16043/._image_0.png  \n",
            "  inflating: hidden/video_16043/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16043/._image_4.png  \n",
            "  inflating: hidden/video_16043/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16043/._image_5.png  \n",
            "  inflating: hidden/video_16043/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16043/._image_7.png  \n",
            "  inflating: hidden/video_16043/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16043/._image_6.png  \n",
            "  inflating: hidden/video_16427/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16427/._image_10.png  \n",
            "  inflating: hidden/video_16427/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16427/._image_8.png  \n",
            "  inflating: hidden/video_16427/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16427/._image_9.png  \n",
            "  inflating: hidden/video_16427/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16427/._image_2.png  \n",
            "  inflating: hidden/video_16427/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16427/._image_3.png  \n",
            "  inflating: hidden/video_16427/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16427/._image_1.png  \n",
            "  inflating: hidden/video_16427/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16427/._image_0.png  \n",
            "  inflating: hidden/video_16427/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16427/._image_4.png  \n",
            "  inflating: hidden/video_16427/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16427/._image_5.png  \n",
            "  inflating: hidden/video_16427/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16427/._image_7.png  \n",
            "  inflating: hidden/video_16427/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16427/._image_6.png  \n",
            "  inflating: hidden/video_15090/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15090/._image_10.png  \n",
            "  inflating: hidden/video_15090/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15090/._image_8.png  \n",
            "  inflating: hidden/video_15090/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15090/._image_9.png  \n",
            "  inflating: hidden/video_15090/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15090/._image_2.png  \n",
            "  inflating: hidden/video_15090/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15090/._image_3.png  \n",
            "  inflating: hidden/video_15090/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15090/._image_1.png  \n",
            "  inflating: hidden/video_15090/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15090/._image_0.png  \n",
            "  inflating: hidden/video_15090/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15090/._image_4.png  \n",
            "  inflating: hidden/video_15090/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15090/._image_5.png  \n",
            "  inflating: hidden/video_15090/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15090/._image_7.png  \n",
            "  inflating: hidden/video_15090/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15090/._image_6.png  \n",
            "  inflating: hidden/video_16615/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16615/._image_10.png  \n",
            "  inflating: hidden/video_16615/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16615/._image_8.png  \n",
            "  inflating: hidden/video_16615/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16615/._image_9.png  \n",
            "  inflating: hidden/video_16615/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16615/._image_2.png  \n",
            "  inflating: hidden/video_16615/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16615/._image_3.png  \n",
            "  inflating: hidden/video_16615/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16615/._image_1.png  \n",
            "  inflating: hidden/video_16615/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16615/._image_0.png  \n",
            "  inflating: hidden/video_16615/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16615/._image_4.png  \n",
            "  inflating: hidden/video_16615/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16615/._image_5.png  \n",
            "  inflating: hidden/video_16615/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16615/._image_7.png  \n",
            "  inflating: hidden/video_16615/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16615/._image_6.png  \n",
            "  inflating: hidden/video_16088/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16088/._image_10.png  \n",
            "  inflating: hidden/video_16088/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16088/._image_8.png  \n",
            "  inflating: hidden/video_16088/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16088/._image_9.png  \n",
            "  inflating: hidden/video_16088/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16088/._image_2.png  \n",
            "  inflating: hidden/video_16088/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16088/._image_3.png  \n",
            "  inflating: hidden/video_16088/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16088/._image_1.png  \n",
            "  inflating: hidden/video_16088/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16088/._image_0.png  \n",
            "  inflating: hidden/video_16088/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16088/._image_4.png  \n",
            "  inflating: hidden/video_16088/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16088/._image_5.png  \n",
            "  inflating: hidden/video_16088/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16088/._image_7.png  \n",
            "  inflating: hidden/video_16088/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16088/._image_6.png  \n",
            "  inflating: hidden/video_15867/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15867/._image_10.png  \n",
            "  inflating: hidden/video_15867/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15867/._image_8.png  \n",
            "  inflating: hidden/video_15867/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15867/._image_9.png  \n",
            "  inflating: hidden/video_15867/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15867/._image_2.png  \n",
            "  inflating: hidden/video_15867/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15867/._image_3.png  \n",
            "  inflating: hidden/video_15867/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15867/._image_1.png  \n",
            "  inflating: hidden/video_15867/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15867/._image_0.png  \n",
            "  inflating: hidden/video_15867/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15867/._image_4.png  \n",
            "  inflating: hidden/video_15867/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15867/._image_5.png  \n",
            "  inflating: hidden/video_15867/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15867/._image_7.png  \n",
            "  inflating: hidden/video_15867/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15867/._image_6.png  \n",
            "  inflating: hidden/video_15269/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15269/._image_10.png  \n",
            "  inflating: hidden/video_15269/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15269/._image_8.png  \n",
            "  inflating: hidden/video_15269/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15269/._image_9.png  \n",
            "  inflating: hidden/video_15269/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15269/._image_2.png  \n",
            "  inflating: hidden/video_15269/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15269/._image_3.png  \n",
            "  inflating: hidden/video_15269/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15269/._image_1.png  \n",
            "  inflating: hidden/video_15269/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15269/._image_0.png  \n",
            "  inflating: hidden/video_15269/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15269/._image_4.png  \n",
            "  inflating: hidden/video_15269/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15269/._image_5.png  \n",
            "  inflating: hidden/video_15269/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15269/._image_7.png  \n",
            "  inflating: hidden/video_15269/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15269/._image_6.png  \n",
            "  inflating: hidden/video_15893/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15893/._image_10.png  \n",
            "  inflating: hidden/video_15893/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15893/._image_8.png  \n",
            "  inflating: hidden/video_15893/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15893/._image_9.png  \n",
            "  inflating: hidden/video_15893/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15893/._image_2.png  \n",
            "  inflating: hidden/video_15893/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15893/._image_3.png  \n",
            "  inflating: hidden/video_15893/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15893/._image_1.png  \n",
            "  inflating: hidden/video_15893/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15893/._image_0.png  \n",
            "  inflating: hidden/video_15893/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15893/._image_4.png  \n",
            "  inflating: hidden/video_15893/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15893/._image_5.png  \n",
            "  inflating: hidden/video_15893/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15893/._image_7.png  \n",
            "  inflating: hidden/video_15893/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15893/._image_6.png  \n",
            "  inflating: hidden/video_16418/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16418/._image_10.png  \n",
            "  inflating: hidden/video_16418/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16418/._image_8.png  \n",
            "  inflating: hidden/video_16418/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16418/._image_9.png  \n",
            "  inflating: hidden/video_16418/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16418/._image_2.png  \n",
            "  inflating: hidden/video_16418/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16418/._image_3.png  \n",
            "  inflating: hidden/video_16418/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16418/._image_1.png  \n",
            "  inflating: hidden/video_16418/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16418/._image_0.png  \n",
            "  inflating: hidden/video_16418/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16418/._image_4.png  \n",
            "  inflating: hidden/video_16418/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16418/._image_5.png  \n",
            "  inflating: hidden/video_16418/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16418/._image_7.png  \n",
            "  inflating: hidden/video_16418/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16418/._image_6.png  \n",
            "  inflating: hidden/video_16840/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16840/._image_10.png  \n",
            "  inflating: hidden/video_16840/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16840/._image_8.png  \n",
            "  inflating: hidden/video_16840/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16840/._image_9.png  \n",
            "  inflating: hidden/video_16840/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16840/._image_2.png  \n",
            "  inflating: hidden/video_16840/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16840/._image_3.png  \n",
            "  inflating: hidden/video_16840/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16840/._image_1.png  \n",
            "  inflating: hidden/video_16840/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16840/._image_0.png  \n",
            "  inflating: hidden/video_16840/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16840/._image_4.png  \n",
            "  inflating: hidden/video_16840/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16840/._image_5.png  \n",
            "  inflating: hidden/video_16840/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16840/._image_7.png  \n",
            "  inflating: hidden/video_16840/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16840/._image_6.png  \n",
            "  inflating: hidden/video_15097/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15097/._image_10.png  \n",
            "  inflating: hidden/video_15097/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15097/._image_8.png  \n",
            "  inflating: hidden/video_15097/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15097/._image_9.png  \n",
            "  inflating: hidden/video_15097/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15097/._image_2.png  \n",
            "  inflating: hidden/video_15097/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15097/._image_3.png  \n",
            "  inflating: hidden/video_15097/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15097/._image_1.png  \n",
            "  inflating: hidden/video_15097/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15097/._image_0.png  \n",
            "  inflating: hidden/video_15097/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15097/._image_4.png  \n",
            "  inflating: hidden/video_15097/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15097/._image_5.png  \n",
            "  inflating: hidden/video_15097/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15097/._image_7.png  \n",
            "  inflating: hidden/video_15097/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15097/._image_6.png  \n",
            "  inflating: hidden/video_16612/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16612/._image_10.png  \n",
            "  inflating: hidden/video_16612/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16612/._image_8.png  \n",
            "  inflating: hidden/video_16612/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16612/._image_9.png  \n",
            "  inflating: hidden/video_16612/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16612/._image_2.png  \n",
            "  inflating: hidden/video_16612/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16612/._image_3.png  \n",
            "  inflating: hidden/video_16612/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16612/._image_1.png  \n",
            "  inflating: hidden/video_16612/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16612/._image_0.png  \n",
            "  inflating: hidden/video_16612/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16612/._image_4.png  \n",
            "  inflating: hidden/video_16612/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16612/._image_5.png  \n",
            "  inflating: hidden/video_16612/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16612/._image_7.png  \n",
            "  inflating: hidden/video_16612/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16612/._image_6.png  \n",
            "  inflating: hidden/video_16420/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16420/._image_10.png  \n",
            "  inflating: hidden/video_16420/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16420/._image_8.png  \n",
            "  inflating: hidden/video_16420/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16420/._image_9.png  \n",
            "  inflating: hidden/video_16420/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16420/._image_2.png  \n",
            "  inflating: hidden/video_16420/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16420/._image_3.png  \n",
            "  inflating: hidden/video_16420/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16420/._image_1.png  \n",
            "  inflating: hidden/video_16420/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16420/._image_0.png  \n",
            "  inflating: hidden/video_16420/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16420/._image_4.png  \n",
            "  inflating: hidden/video_16420/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16420/._image_5.png  \n",
            "  inflating: hidden/video_16420/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16420/._image_7.png  \n",
            "  inflating: hidden/video_16420/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16420/._image_6.png  \n",
            "  inflating: hidden/video_16878/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16878/._image_10.png  \n",
            "  inflating: hidden/video_16878/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16878/._image_8.png  \n",
            "  inflating: hidden/video_16878/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16878/._image_9.png  \n",
            "  inflating: hidden/video_16878/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16878/._image_2.png  \n",
            "  inflating: hidden/video_16878/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16878/._image_3.png  \n",
            "  inflating: hidden/video_16878/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16878/._image_1.png  \n",
            "  inflating: hidden/video_16878/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16878/._image_0.png  \n",
            "  inflating: hidden/video_16878/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16878/._image_4.png  \n",
            "  inflating: hidden/video_16878/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16878/._image_5.png  \n",
            "  inflating: hidden/video_16878/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16878/._image_7.png  \n",
            "  inflating: hidden/video_16878/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16878/._image_6.png  \n",
            "  inflating: hidden/video_16044/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16044/._image_10.png  \n",
            "  inflating: hidden/video_16044/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16044/._image_8.png  \n",
            "  inflating: hidden/video_16044/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16044/._image_9.png  \n",
            "  inflating: hidden/video_16044/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16044/._image_2.png  \n",
            "  inflating: hidden/video_16044/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16044/._image_3.png  \n",
            "  inflating: hidden/video_16044/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16044/._image_1.png  \n",
            "  inflating: hidden/video_16044/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16044/._image_0.png  \n",
            "  inflating: hidden/video_16044/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16044/._image_4.png  \n",
            "  inflating: hidden/video_16044/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16044/._image_5.png  \n",
            "  inflating: hidden/video_16044/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16044/._image_7.png  \n",
            "  inflating: hidden/video_16044/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16044/._image_6.png  \n",
            "  inflating: hidden/video_16276/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16276/._image_10.png  \n",
            "  inflating: hidden/video_16276/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16276/._image_8.png  \n",
            "  inflating: hidden/video_16276/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16276/._image_9.png  \n",
            "  inflating: hidden/video_16276/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16276/._image_2.png  \n",
            "  inflating: hidden/video_16276/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16276/._image_3.png  \n",
            "  inflating: hidden/video_16276/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16276/._image_1.png  \n",
            "  inflating: hidden/video_16276/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16276/._image_0.png  \n",
            "  inflating: hidden/video_16276/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16276/._image_4.png  \n",
            "  inflating: hidden/video_16276/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16276/._image_5.png  \n",
            "  inflating: hidden/video_16276/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16276/._image_7.png  \n",
            "  inflating: hidden/video_16276/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16276/._image_6.png  \n",
            "  inflating: hidden/video_15635/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15635/._image_10.png  \n",
            "  inflating: hidden/video_15635/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15635/._image_8.png  \n",
            "  inflating: hidden/video_15635/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15635/._image_9.png  \n",
            "  inflating: hidden/video_15635/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15635/._image_2.png  \n",
            "  inflating: hidden/video_15635/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15635/._image_3.png  \n",
            "  inflating: hidden/video_15635/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15635/._image_1.png  \n",
            "  inflating: hidden/video_15635/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15635/._image_0.png  \n",
            "  inflating: hidden/video_15635/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15635/._image_4.png  \n",
            "  inflating: hidden/video_15635/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15635/._image_5.png  \n",
            "  inflating: hidden/video_15635/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15635/._image_7.png  \n",
            "  inflating: hidden/video_15635/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15635/._image_6.png  \n",
            "  inflating: hidden/video_15407/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15407/._image_10.png  \n",
            "  inflating: hidden/video_15407/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15407/._image_8.png  \n",
            "  inflating: hidden/video_15407/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15407/._image_9.png  \n",
            "  inflating: hidden/video_15407/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15407/._image_2.png  \n",
            "  inflating: hidden/video_15407/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15407/._image_3.png  \n",
            "  inflating: hidden/video_15407/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15407/._image_1.png  \n",
            "  inflating: hidden/video_15407/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15407/._image_0.png  \n",
            "  inflating: hidden/video_15407/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15407/._image_4.png  \n",
            "  inflating: hidden/video_15407/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15407/._image_5.png  \n",
            "  inflating: hidden/video_15407/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15407/._image_7.png  \n",
            "  inflating: hidden/video_15407/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15407/._image_6.png  \n",
            "  inflating: hidden/video_16282/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16282/._image_10.png  \n",
            "  inflating: hidden/video_16282/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16282/._image_8.png  \n",
            "  inflating: hidden/video_16282/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16282/._image_9.png  \n",
            "  inflating: hidden/video_16282/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16282/._image_2.png  \n",
            "  inflating: hidden/video_16282/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16282/._image_3.png  \n",
            "  inflating: hidden/video_16282/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16282/._image_1.png  \n",
            "  inflating: hidden/video_16282/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16282/._image_0.png  \n",
            "  inflating: hidden/video_16282/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16282/._image_4.png  \n",
            "  inflating: hidden/video_16282/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16282/._image_5.png  \n",
            "  inflating: hidden/video_16282/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16282/._image_7.png  \n",
            "  inflating: hidden/video_16282/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16282/._image_6.png  \n",
            "  inflating: hidden/video_15063/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15063/._image_10.png  \n",
            "  inflating: hidden/video_15063/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15063/._image_8.png  \n",
            "  inflating: hidden/video_15063/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15063/._image_9.png  \n",
            "  inflating: hidden/video_15063/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15063/._image_2.png  \n",
            "  inflating: hidden/video_15063/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15063/._image_3.png  \n",
            "  inflating: hidden/video_15063/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15063/._image_1.png  \n",
            "  inflating: hidden/video_15063/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15063/._image_0.png  \n",
            "  inflating: hidden/video_15063/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15063/._image_4.png  \n",
            "  inflating: hidden/video_15063/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15063/._image_5.png  \n",
            "  inflating: hidden/video_15063/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15063/._image_7.png  \n",
            "  inflating: hidden/video_15063/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15063/._image_6.png  \n",
            "  inflating: hidden/video_15251/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15251/._image_10.png  \n",
            "  inflating: hidden/video_15251/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15251/._image_8.png  \n",
            "  inflating: hidden/video_15251/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15251/._image_9.png  \n",
            "  inflating: hidden/video_15251/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15251/._image_2.png  \n",
            "  inflating: hidden/video_15251/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15251/._image_3.png  \n",
            "  inflating: hidden/video_15251/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15251/._image_1.png  \n",
            "  inflating: hidden/video_15251/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15251/._image_0.png  \n",
            "  inflating: hidden/video_15251/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15251/._image_4.png  \n",
            "  inflating: hidden/video_15251/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15251/._image_5.png  \n",
            "  inflating: hidden/video_15251/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15251/._image_7.png  \n",
            "  inflating: hidden/video_15251/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15251/._image_6.png  \n",
            "  inflating: hidden/video_16249/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16249/._image_10.png  \n",
            "  inflating: hidden/video_16249/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16249/._image_8.png  \n",
            "  inflating: hidden/video_16249/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16249/._image_9.png  \n",
            "  inflating: hidden/video_16249/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16249/._image_2.png  \n",
            "  inflating: hidden/video_16249/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16249/._image_3.png  \n",
            "  inflating: hidden/video_16249/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16249/._image_1.png  \n",
            "  inflating: hidden/video_16249/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16249/._image_0.png  \n",
            "  inflating: hidden/video_16249/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16249/._image_4.png  \n",
            "  inflating: hidden/video_16249/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16249/._image_5.png  \n",
            "  inflating: hidden/video_16249/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16249/._image_7.png  \n",
            "  inflating: hidden/video_16249/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16249/._image_6.png  \n",
            "  inflating: hidden/video_16847/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16847/._image_10.png  \n",
            "  inflating: hidden/video_16847/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16847/._image_8.png  \n",
            "  inflating: hidden/video_16847/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16847/._image_9.png  \n",
            "  inflating: hidden/video_16847/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16847/._image_2.png  \n",
            "  inflating: hidden/video_16847/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16847/._image_3.png  \n",
            "  inflating: hidden/video_16847/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16847/._image_1.png  \n",
            "  inflating: hidden/video_16847/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16847/._image_0.png  \n",
            "  inflating: hidden/video_16847/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16847/._image_4.png  \n",
            "  inflating: hidden/video_16847/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16847/._image_5.png  \n",
            "  inflating: hidden/video_16847/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16847/._image_7.png  \n",
            "  inflating: hidden/video_16847/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16847/._image_6.png  \n",
            "  inflating: hidden/video_15894/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15894/._image_10.png  \n",
            "  inflating: hidden/video_15894/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15894/._image_8.png  \n",
            "  inflating: hidden/video_15894/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15894/._image_9.png  \n",
            "  inflating: hidden/video_15894/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15894/._image_2.png  \n",
            "  inflating: hidden/video_15894/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15894/._image_3.png  \n",
            "  inflating: hidden/video_15894/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15894/._image_1.png  \n",
            "  inflating: hidden/video_15894/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15894/._image_0.png  \n",
            "  inflating: hidden/video_15894/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15894/._image_4.png  \n",
            "  inflating: hidden/video_15894/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15894/._image_5.png  \n",
            "  inflating: hidden/video_15894/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15894/._image_7.png  \n",
            "  inflating: hidden/video_15894/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15894/._image_6.png  \n",
            "  inflating: hidden/video_15860/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15860/._image_10.png  \n",
            "  inflating: hidden/video_15860/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15860/._image_8.png  \n",
            "  inflating: hidden/video_15860/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15860/._image_9.png  \n",
            "  inflating: hidden/video_15860/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15860/._image_2.png  \n",
            "  inflating: hidden/video_15860/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15860/._image_3.png  \n",
            "  inflating: hidden/video_15860/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15860/._image_1.png  \n",
            "  inflating: hidden/video_15860/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15860/._image_0.png  \n",
            "  inflating: hidden/video_15860/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15860/._image_4.png  \n",
            "  inflating: hidden/video_15860/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15860/._image_5.png  \n",
            "  inflating: hidden/video_15860/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15860/._image_7.png  \n",
            "  inflating: hidden/video_15860/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15860/._image_6.png  \n",
            "  inflating: hidden/video_15438/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15438/._image_10.png  \n",
            "  inflating: hidden/video_15438/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15438/._image_8.png  \n",
            "  inflating: hidden/video_15438/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15438/._image_9.png  \n",
            "  inflating: hidden/video_15438/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15438/._image_2.png  \n",
            "  inflating: hidden/video_15438/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15438/._image_3.png  \n",
            "  inflating: hidden/video_15438/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15438/._image_1.png  \n",
            "  inflating: hidden/video_15438/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15438/._image_0.png  \n",
            "  inflating: hidden/video_15438/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15438/._image_4.png  \n",
            "  inflating: hidden/video_15438/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15438/._image_5.png  \n",
            "  inflating: hidden/video_15438/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15438/._image_7.png  \n",
            "  inflating: hidden/video_15438/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15438/._image_6.png  \n",
            "  inflating: hidden/video_16813/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16813/._image_10.png  \n",
            "  inflating: hidden/video_16813/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16813/._image_8.png  \n",
            "  inflating: hidden/video_16813/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16813/._image_9.png  \n",
            "  inflating: hidden/video_16813/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16813/._image_2.png  \n",
            "  inflating: hidden/video_16813/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16813/._image_3.png  \n",
            "  inflating: hidden/video_16813/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16813/._image_1.png  \n",
            "  inflating: hidden/video_16813/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16813/._image_0.png  \n",
            "  inflating: hidden/video_16813/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16813/._image_4.png  \n",
            "  inflating: hidden/video_16813/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16813/._image_5.png  \n",
            "  inflating: hidden/video_16813/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16813/._image_7.png  \n",
            "  inflating: hidden/video_16813/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16813/._image_6.png  \n",
            "  inflating: hidden/video_15498/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15498/._image_10.png  \n",
            "  inflating: hidden/video_15498/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15498/._image_8.png  \n",
            "  inflating: hidden/video_15498/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15498/._image_9.png  \n",
            "  inflating: hidden/video_15498/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15498/._image_2.png  \n",
            "  inflating: hidden/video_15498/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15498/._image_3.png  \n",
            "  inflating: hidden/video_15498/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15498/._image_1.png  \n",
            "  inflating: hidden/video_15498/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15498/._image_0.png  \n",
            "  inflating: hidden/video_15498/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15498/._image_4.png  \n",
            "  inflating: hidden/video_15498/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15498/._image_5.png  \n",
            "  inflating: hidden/video_15498/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15498/._image_7.png  \n",
            "  inflating: hidden/video_15498/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15498/._image_6.png  \n",
            "  inflating: hidden/video_16679/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16679/._image_10.png  \n",
            "  inflating: hidden/video_16679/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16679/._image_8.png  \n",
            "  inflating: hidden/video_16679/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16679/._image_9.png  \n",
            "  inflating: hidden/video_16679/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16679/._image_2.png  \n",
            "  inflating: hidden/video_16679/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16679/._image_3.png  \n",
            "  inflating: hidden/video_16679/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16679/._image_1.png  \n",
            "  inflating: hidden/video_16679/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16679/._image_0.png  \n",
            "  inflating: hidden/video_16679/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16679/._image_4.png  \n",
            "  inflating: hidden/video_16679/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16679/._image_5.png  \n",
            "  inflating: hidden/video_16679/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16679/._image_7.png  \n",
            "  inflating: hidden/video_16679/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16679/._image_6.png  \n",
            "  inflating: hidden/video_15834/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15834/._image_10.png  \n",
            "  inflating: hidden/video_15834/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15834/._image_8.png  \n",
            "  inflating: hidden/video_15834/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15834/._image_9.png  \n",
            "  inflating: hidden/video_15834/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15834/._image_2.png  \n",
            "  inflating: hidden/video_15834/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15834/._image_3.png  \n",
            "  inflating: hidden/video_15834/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15834/._image_1.png  \n",
            "  inflating: hidden/video_15834/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15834/._image_0.png  \n",
            "  inflating: hidden/video_15834/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15834/._image_4.png  \n",
            "  inflating: hidden/video_15834/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15834/._image_5.png  \n",
            "  inflating: hidden/video_15834/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15834/._image_7.png  \n",
            "  inflating: hidden/video_15834/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15834/._image_6.png  \n",
            "  inflating: hidden/video_15008/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15008/._image_10.png  \n",
            "  inflating: hidden/video_15008/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15008/._image_8.png  \n",
            "  inflating: hidden/video_15008/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15008/._image_9.png  \n",
            "  inflating: hidden/video_15008/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15008/._image_2.png  \n",
            "  inflating: hidden/video_15008/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15008/._image_3.png  \n",
            "  inflating: hidden/video_15008/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15008/._image_1.png  \n",
            "  inflating: hidden/video_15008/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15008/._image_0.png  \n",
            "  inflating: hidden/video_15008/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15008/._image_4.png  \n",
            "  inflating: hidden/video_15008/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15008/._image_5.png  \n",
            "  inflating: hidden/video_15008/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15008/._image_7.png  \n",
            "  inflating: hidden/video_15008/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15008/._image_6.png  \n",
            "  inflating: hidden/video_16474/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16474/._image_10.png  \n",
            "  inflating: hidden/video_16474/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16474/._image_8.png  \n",
            "  inflating: hidden/video_16474/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16474/._image_9.png  \n",
            "  inflating: hidden/video_16474/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16474/._image_2.png  \n",
            "  inflating: hidden/video_16474/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16474/._image_3.png  \n",
            "  inflating: hidden/video_16474/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16474/._image_1.png  \n",
            "  inflating: hidden/video_16474/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16474/._image_0.png  \n",
            "  inflating: hidden/video_16474/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16474/._image_4.png  \n",
            "  inflating: hidden/video_16474/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16474/._image_5.png  \n",
            "  inflating: hidden/video_16474/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16474/._image_7.png  \n",
            "  inflating: hidden/video_16474/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16474/._image_6.png  \n",
            "  inflating: hidden/video_16646/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16646/._image_10.png  \n",
            "  inflating: hidden/video_16646/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16646/._image_8.png  \n",
            "  inflating: hidden/video_16646/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16646/._image_9.png  \n",
            "  inflating: hidden/video_16646/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16646/._image_2.png  \n",
            "  inflating: hidden/video_16646/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16646/._image_3.png  \n",
            "  inflating: hidden/video_16646/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16646/._image_1.png  \n",
            "  inflating: hidden/video_16646/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16646/._image_0.png  \n",
            "  inflating: hidden/video_16646/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16646/._image_4.png  \n",
            "  inflating: hidden/video_16646/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16646/._image_5.png  \n",
            "  inflating: hidden/video_16646/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16646/._image_7.png  \n",
            "  inflating: hidden/video_16646/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16646/._image_6.png  \n",
            "  inflating: hidden/video_16222/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16222/._image_10.png  \n",
            "  inflating: hidden/video_16222/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16222/._image_8.png  \n",
            "  inflating: hidden/video_16222/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16222/._image_9.png  \n",
            "  inflating: hidden/video_16222/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16222/._image_2.png  \n",
            "  inflating: hidden/video_16222/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16222/._image_3.png  \n",
            "  inflating: hidden/video_16222/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16222/._image_1.png  \n",
            "  inflating: hidden/video_16222/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16222/._image_0.png  \n",
            "  inflating: hidden/video_16222/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16222/._image_4.png  \n",
            "  inflating: hidden/video_16222/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16222/._image_5.png  \n",
            "  inflating: hidden/video_16222/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16222/._image_7.png  \n",
            "  inflating: hidden/video_16222/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16222/._image_6.png  \n",
            "  inflating: hidden/video_15695/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15695/._image_10.png  \n",
            "  inflating: hidden/video_15695/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15695/._image_8.png  \n",
            "  inflating: hidden/video_15695/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15695/._image_9.png  \n",
            "  inflating: hidden/video_15695/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15695/._image_2.png  \n",
            "  inflating: hidden/video_15695/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15695/._image_3.png  \n",
            "  inflating: hidden/video_15695/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15695/._image_1.png  \n",
            "  inflating: hidden/video_15695/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15695/._image_0.png  \n",
            "  inflating: hidden/video_15695/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15695/._image_4.png  \n",
            "  inflating: hidden/video_15695/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15695/._image_5.png  \n",
            "  inflating: hidden/video_15695/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15695/._image_7.png  \n",
            "  inflating: hidden/video_15695/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15695/._image_6.png  \n",
            "  inflating: hidden/video_16010/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16010/._image_10.png  \n",
            "  inflating: hidden/video_16010/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16010/._image_8.png  \n",
            "  inflating: hidden/video_16010/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16010/._image_9.png  \n",
            "  inflating: hidden/video_16010/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16010/._image_2.png  \n",
            "  inflating: hidden/video_16010/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16010/._image_3.png  \n",
            "  inflating: hidden/video_16010/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16010/._image_1.png  \n",
            "  inflating: hidden/video_16010/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16010/._image_0.png  \n",
            "  inflating: hidden/video_16010/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16010/._image_4.png  \n",
            "  inflating: hidden/video_16010/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16010/._image_5.png  \n",
            "  inflating: hidden/video_16010/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16010/._image_7.png  \n",
            "  inflating: hidden/video_16010/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16010/._image_6.png  \n",
            "  inflating: hidden/video_15453/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15453/._image_10.png  \n",
            "  inflating: hidden/video_15453/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15453/._image_8.png  \n",
            "  inflating: hidden/video_15453/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15453/._image_9.png  \n",
            "  inflating: hidden/video_15453/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15453/._image_2.png  \n",
            "  inflating: hidden/video_15453/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15453/._image_3.png  \n",
            "  inflating: hidden/video_15453/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15453/._image_1.png  \n",
            "  inflating: hidden/video_15453/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15453/._image_0.png  \n",
            "  inflating: hidden/video_15453/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15453/._image_4.png  \n",
            "  inflating: hidden/video_15453/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15453/._image_5.png  \n",
            "  inflating: hidden/video_15453/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15453/._image_7.png  \n",
            "  inflating: hidden/video_15453/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15453/._image_6.png  \n",
            "  inflating: hidden/video_15661/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15661/._image_10.png  \n",
            "  inflating: hidden/video_15661/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15661/._image_8.png  \n",
            "  inflating: hidden/video_15661/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15661/._image_9.png  \n",
            "  inflating: hidden/video_15661/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15661/._image_2.png  \n",
            "  inflating: hidden/video_15661/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15661/._image_3.png  \n",
            "  inflating: hidden/video_15661/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15661/._image_1.png  \n",
            "  inflating: hidden/video_15661/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15661/._image_0.png  \n",
            "  inflating: hidden/video_15661/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15661/._image_4.png  \n",
            "  inflating: hidden/video_15661/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15661/._image_5.png  \n",
            "  inflating: hidden/video_15661/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15661/._image_7.png  \n",
            "  inflating: hidden/video_15661/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15661/._image_6.png  \n",
            "  inflating: hidden/video_15205/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15205/._image_10.png  \n",
            "  inflating: hidden/video_15205/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15205/._image_8.png  \n",
            "  inflating: hidden/video_15205/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15205/._image_9.png  \n",
            "  inflating: hidden/video_15205/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15205/._image_2.png  \n",
            "  inflating: hidden/video_15205/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15205/._image_3.png  \n",
            "  inflating: hidden/video_15205/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15205/._image_1.png  \n",
            "  inflating: hidden/video_15205/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15205/._image_0.png  \n",
            "  inflating: hidden/video_15205/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15205/._image_4.png  \n",
            "  inflating: hidden/video_15205/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15205/._image_5.png  \n",
            "  inflating: hidden/video_15205/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15205/._image_7.png  \n",
            "  inflating: hidden/video_15205/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15205/._image_6.png  \n",
            "  inflating: hidden/video_16480/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16480/._image_10.png  \n",
            "  inflating: hidden/video_16480/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16480/._image_8.png  \n",
            "  inflating: hidden/video_16480/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16480/._image_9.png  \n",
            "  inflating: hidden/video_16480/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16480/._image_2.png  \n",
            "  inflating: hidden/video_16480/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16480/._image_3.png  \n",
            "  inflating: hidden/video_16480/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16480/._image_1.png  \n",
            "  inflating: hidden/video_16480/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16480/._image_0.png  \n",
            "  inflating: hidden/video_16480/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16480/._image_4.png  \n",
            "  inflating: hidden/video_16480/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16480/._image_5.png  \n",
            "  inflating: hidden/video_16480/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16480/._image_7.png  \n",
            "  inflating: hidden/video_16480/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16480/._image_6.png  \n",
            "  inflating: hidden/video_15037/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15037/._image_10.png  \n",
            "  inflating: hidden/video_15037/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15037/._image_8.png  \n",
            "  inflating: hidden/video_15037/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15037/._image_9.png  \n",
            "  inflating: hidden/video_15037/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15037/._image_2.png  \n",
            "  inflating: hidden/video_15037/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15037/._image_3.png  \n",
            "  inflating: hidden/video_15037/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15037/._image_1.png  \n",
            "  inflating: hidden/video_15037/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15037/._image_0.png  \n",
            "  inflating: hidden/video_15037/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15037/._image_4.png  \n",
            "  inflating: hidden/video_15037/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15037/._image_5.png  \n",
            "  inflating: hidden/video_15037/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15037/._image_7.png  \n",
            "  inflating: hidden/video_15037/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15037/._image_6.png  \n",
            "  inflating: hidden/video_15659/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15659/._image_10.png  \n",
            "  inflating: hidden/video_15659/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15659/._image_8.png  \n",
            "  inflating: hidden/video_15659/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15659/._image_9.png  \n",
            "  inflating: hidden/video_15659/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15659/._image_2.png  \n",
            "  inflating: hidden/video_15659/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15659/._image_3.png  \n",
            "  inflating: hidden/video_15659/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15659/._image_1.png  \n",
            "  inflating: hidden/video_15659/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15659/._image_0.png  \n",
            "  inflating: hidden/video_15659/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15659/._image_4.png  \n",
            "  inflating: hidden/video_15659/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15659/._image_5.png  \n",
            "  inflating: hidden/video_15659/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15659/._image_7.png  \n",
            "  inflating: hidden/video_15659/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15659/._image_6.png  \n",
            "  inflating: hidden/video_15833/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15833/._image_10.png  \n",
            "  inflating: hidden/video_15833/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15833/._image_8.png  \n",
            "  inflating: hidden/video_15833/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15833/._image_9.png  \n",
            "  inflating: hidden/video_15833/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15833/._image_2.png  \n",
            "  inflating: hidden/video_15833/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15833/._image_3.png  \n",
            "  inflating: hidden/video_15833/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15833/._image_1.png  \n",
            "  inflating: hidden/video_15833/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15833/._image_0.png  \n",
            "  inflating: hidden/video_15833/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15833/._image_4.png  \n",
            "  inflating: hidden/video_15833/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15833/._image_5.png  \n",
            "  inflating: hidden/video_15833/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15833/._image_7.png  \n",
            "  inflating: hidden/video_15833/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15833/._image_6.png  \n",
            "  inflating: hidden/video_16028/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16028/._image_10.png  \n",
            "  inflating: hidden/video_16028/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16028/._image_8.png  \n",
            "  inflating: hidden/video_16028/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16028/._image_9.png  \n",
            "  inflating: hidden/video_16028/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16028/._image_2.png  \n",
            "  inflating: hidden/video_16028/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16028/._image_3.png  \n",
            "  inflating: hidden/video_16028/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16028/._image_1.png  \n",
            "  inflating: hidden/video_16028/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16028/._image_0.png  \n",
            "  inflating: hidden/video_16028/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16028/._image_4.png  \n",
            "  inflating: hidden/video_16028/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16028/._image_5.png  \n",
            "  inflating: hidden/video_16028/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16028/._image_7.png  \n",
            "  inflating: hidden/video_16028/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16028/._image_6.png  \n",
            "  inflating: hidden/video_16814/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16814/._image_10.png  \n",
            "  inflating: hidden/video_16814/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16814/._image_8.png  \n",
            "  inflating: hidden/video_16814/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16814/._image_9.png  \n",
            "  inflating: hidden/video_16814/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16814/._image_2.png  \n",
            "  inflating: hidden/video_16814/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16814/._image_3.png  \n",
            "  inflating: hidden/video_16814/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16814/._image_1.png  \n",
            "  inflating: hidden/video_16814/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16814/._image_0.png  \n",
            "  inflating: hidden/video_16814/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16814/._image_4.png  \n",
            "  inflating: hidden/video_16814/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16814/._image_5.png  \n",
            "  inflating: hidden/video_16814/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16814/._image_7.png  \n",
            "  inflating: hidden/video_16814/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16814/._image_6.png  \n",
            "  inflating: hidden/video_15030/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15030/._image_10.png  \n",
            "  inflating: hidden/video_15030/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15030/._image_8.png  \n",
            "  inflating: hidden/video_15030/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15030/._image_9.png  \n",
            "  inflating: hidden/video_15030/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15030/._image_2.png  \n",
            "  inflating: hidden/video_15030/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15030/._image_3.png  \n",
            "  inflating: hidden/video_15030/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15030/._image_1.png  \n",
            "  inflating: hidden/video_15030/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15030/._image_0.png  \n",
            "  inflating: hidden/video_15030/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15030/._image_4.png  \n",
            "  inflating: hidden/video_15030/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15030/._image_5.png  \n",
            "  inflating: hidden/video_15030/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15030/._image_7.png  \n",
            "  inflating: hidden/video_15030/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15030/._image_6.png  \n",
            "  inflating: hidden/video_15202/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15202/._image_10.png  \n",
            "  inflating: hidden/video_15202/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15202/._image_8.png  \n",
            "  inflating: hidden/video_15202/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15202/._image_9.png  \n",
            "  inflating: hidden/video_15202/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15202/._image_2.png  \n",
            "  inflating: hidden/video_15202/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15202/._image_3.png  \n",
            "  inflating: hidden/video_15202/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15202/._image_1.png  \n",
            "  inflating: hidden/video_15202/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15202/._image_0.png  \n",
            "  inflating: hidden/video_15202/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15202/._image_4.png  \n",
            "  inflating: hidden/video_15202/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15202/._image_5.png  \n",
            "  inflating: hidden/video_15202/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15202/._image_7.png  \n",
            "  inflating: hidden/video_15202/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15202/._image_6.png  \n",
            "  inflating: hidden/video_16487/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16487/._image_10.png  \n",
            "  inflating: hidden/video_16487/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16487/._image_8.png  \n",
            "  inflating: hidden/video_16487/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16487/._image_9.png  \n",
            "  inflating: hidden/video_16487/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16487/._image_2.png  \n",
            "  inflating: hidden/video_16487/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16487/._image_3.png  \n",
            "  inflating: hidden/video_16487/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16487/._image_1.png  \n",
            "  inflating: hidden/video_16487/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16487/._image_0.png  \n",
            "  inflating: hidden/video_16487/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16487/._image_4.png  \n",
            "  inflating: hidden/video_16487/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16487/._image_5.png  \n",
            "  inflating: hidden/video_16487/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16487/._image_7.png  \n",
            "  inflating: hidden/video_16487/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16487/._image_6.png  \n",
            "  inflating: hidden/video_15666/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15666/._image_10.png  \n",
            "  inflating: hidden/video_15666/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15666/._image_8.png  \n",
            "  inflating: hidden/video_15666/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15666/._image_9.png  \n",
            "  inflating: hidden/video_15666/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15666/._image_2.png  \n",
            "  inflating: hidden/video_15666/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15666/._image_3.png  \n",
            "  inflating: hidden/video_15666/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15666/._image_1.png  \n",
            "  inflating: hidden/video_15666/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15666/._image_0.png  \n",
            "  inflating: hidden/video_15666/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15666/._image_4.png  \n",
            "  inflating: hidden/video_15666/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15666/._image_5.png  \n",
            "  inflating: hidden/video_15666/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15666/._image_7.png  \n",
            "  inflating: hidden/video_15666/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15666/._image_6.png  \n",
            "  inflating: hidden/video_15454/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15454/._image_10.png  \n",
            "  inflating: hidden/video_15454/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15454/._image_8.png  \n",
            "  inflating: hidden/video_15454/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15454/._image_9.png  \n",
            "  inflating: hidden/video_15454/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15454/._image_2.png  \n",
            "  inflating: hidden/video_15454/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15454/._image_3.png  \n",
            "  inflating: hidden/video_15454/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15454/._image_1.png  \n",
            "  inflating: hidden/video_15454/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15454/._image_0.png  \n",
            "  inflating: hidden/video_15454/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15454/._image_4.png  \n",
            "  inflating: hidden/video_15454/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15454/._image_5.png  \n",
            "  inflating: hidden/video_15454/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15454/._image_7.png  \n",
            "  inflating: hidden/video_15454/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15454/._image_6.png  \n",
            "  inflating: hidden/video_15692/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15692/._image_10.png  \n",
            "  inflating: hidden/video_15692/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15692/._image_8.png  \n",
            "  inflating: hidden/video_15692/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15692/._image_9.png  \n",
            "  inflating: hidden/video_15692/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15692/._image_2.png  \n",
            "  inflating: hidden/video_15692/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15692/._image_3.png  \n",
            "  inflating: hidden/video_15692/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15692/._image_1.png  \n",
            "  inflating: hidden/video_15692/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15692/._image_0.png  \n",
            "  inflating: hidden/video_15692/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15692/._image_4.png  \n",
            "  inflating: hidden/video_15692/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15692/._image_5.png  \n",
            "  inflating: hidden/video_15692/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15692/._image_7.png  \n",
            "  inflating: hidden/video_15692/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15692/._image_6.png  \n",
            "  inflating: hidden/video_16017/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16017/._image_10.png  \n",
            "  inflating: hidden/video_16017/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16017/._image_8.png  \n",
            "  inflating: hidden/video_16017/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16017/._image_9.png  \n",
            "  inflating: hidden/video_16017/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16017/._image_2.png  \n",
            "  inflating: hidden/video_16017/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16017/._image_3.png  \n",
            "  inflating: hidden/video_16017/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16017/._image_1.png  \n",
            "  inflating: hidden/video_16017/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16017/._image_0.png  \n",
            "  inflating: hidden/video_16017/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16017/._image_4.png  \n",
            "  inflating: hidden/video_16017/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16017/._image_5.png  \n",
            "  inflating: hidden/video_16017/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16017/._image_7.png  \n",
            "  inflating: hidden/video_16017/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16017/._image_6.png  \n",
            "  inflating: hidden/video_16225/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16225/._image_10.png  \n",
            "  inflating: hidden/video_16225/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16225/._image_8.png  \n",
            "  inflating: hidden/video_16225/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16225/._image_9.png  \n",
            "  inflating: hidden/video_16225/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16225/._image_2.png  \n",
            "  inflating: hidden/video_16225/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16225/._image_3.png  \n",
            "  inflating: hidden/video_16225/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16225/._image_1.png  \n",
            "  inflating: hidden/video_16225/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16225/._image_0.png  \n",
            "  inflating: hidden/video_16225/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16225/._image_4.png  \n",
            "  inflating: hidden/video_16225/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16225/._image_5.png  \n",
            "  inflating: hidden/video_16225/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16225/._image_7.png  \n",
            "  inflating: hidden/video_16225/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16225/._image_6.png  \n",
            "  inflating: hidden/video_16641/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16641/._image_10.png  \n",
            "  inflating: hidden/video_16641/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16641/._image_8.png  \n",
            "  inflating: hidden/video_16641/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16641/._image_9.png  \n",
            "  inflating: hidden/video_16641/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16641/._image_2.png  \n",
            "  inflating: hidden/video_16641/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16641/._image_3.png  \n",
            "  inflating: hidden/video_16641/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16641/._image_1.png  \n",
            "  inflating: hidden/video_16641/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16641/._image_0.png  \n",
            "  inflating: hidden/video_16641/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16641/._image_4.png  \n",
            "  inflating: hidden/video_16641/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16641/._image_5.png  \n",
            "  inflating: hidden/video_16641/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16641/._image_7.png  \n",
            "  inflating: hidden/video_16641/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16641/._image_6.png  \n",
            "  inflating: hidden/video_16473/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16473/._image_10.png  \n",
            "  inflating: hidden/video_16473/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16473/._image_8.png  \n",
            "  inflating: hidden/video_16473/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16473/._image_9.png  \n",
            "  inflating: hidden/video_16473/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16473/._image_2.png  \n",
            "  inflating: hidden/video_16473/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16473/._image_3.png  \n",
            "  inflating: hidden/video_16473/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16473/._image_1.png  \n",
            "  inflating: hidden/video_16473/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16473/._image_0.png  \n",
            "  inflating: hidden/video_16473/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16473/._image_4.png  \n",
            "  inflating: hidden/video_16473/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16473/._image_5.png  \n",
            "  inflating: hidden/video_16473/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16473/._image_7.png  \n",
            "  inflating: hidden/video_16473/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16473/._image_6.png  \n",
            "  inflating: hidden/video_15805/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15805/._image_10.png  \n",
            "  inflating: hidden/video_15805/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15805/._image_8.png  \n",
            "  inflating: hidden/video_15805/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15805/._image_9.png  \n",
            "  inflating: hidden/video_15805/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15805/._image_2.png  \n",
            "  inflating: hidden/video_15805/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15805/._image_3.png  \n",
            "  inflating: hidden/video_15805/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15805/._image_1.png  \n",
            "  inflating: hidden/video_15805/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15805/._image_0.png  \n",
            "  inflating: hidden/video_15805/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15805/._image_4.png  \n",
            "  inflating: hidden/video_15805/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15805/._image_5.png  \n",
            "  inflating: hidden/video_15805/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15805/._image_7.png  \n",
            "  inflating: hidden/video_15805/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15805/._image_6.png  \n",
            "  inflating: hidden/video_15039/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15039/._image_10.png  \n",
            "  inflating: hidden/video_15039/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15039/._image_8.png  \n",
            "  inflating: hidden/video_15039/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15039/._image_9.png  \n",
            "  inflating: hidden/video_15039/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15039/._image_2.png  \n",
            "  inflating: hidden/video_15039/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15039/._image_3.png  \n",
            "  inflating: hidden/video_15039/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15039/._image_1.png  \n",
            "  inflating: hidden/video_15039/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15039/._image_0.png  \n",
            "  inflating: hidden/video_15039/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15039/._image_4.png  \n",
            "  inflating: hidden/video_15039/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15039/._image_5.png  \n",
            "  inflating: hidden/video_15039/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15039/._image_7.png  \n",
            "  inflating: hidden/video_15039/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15039/._image_6.png  \n",
            "  inflating: hidden/video_16822/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16822/._image_10.png  \n",
            "  inflating: hidden/video_16822/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16822/._image_8.png  \n",
            "  inflating: hidden/video_16822/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16822/._image_9.png  \n",
            "  inflating: hidden/video_16822/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16822/._image_2.png  \n",
            "  inflating: hidden/video_16822/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16822/._image_3.png  \n",
            "  inflating: hidden/video_16822/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16822/._image_1.png  \n",
            "  inflating: hidden/video_16822/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16822/._image_0.png  \n",
            "  inflating: hidden/video_16822/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16822/._image_4.png  \n",
            "  inflating: hidden/video_16822/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16822/._image_5.png  \n",
            "  inflating: hidden/video_16822/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16822/._image_7.png  \n",
            "  inflating: hidden/video_16822/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16822/._image_6.png  \n",
            "  inflating: hidden/video_16648/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16648/._image_10.png  \n",
            "  inflating: hidden/video_16648/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16648/._image_8.png  \n",
            "  inflating: hidden/video_16648/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16648/._image_9.png  \n",
            "  inflating: hidden/video_16648/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16648/._image_2.png  \n",
            "  inflating: hidden/video_16648/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16648/._image_3.png  \n",
            "  inflating: hidden/video_16648/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16648/._image_1.png  \n",
            "  inflating: hidden/video_16648/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16648/._image_0.png  \n",
            "  inflating: hidden/video_16648/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16648/._image_4.png  \n",
            "  inflating: hidden/video_16648/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16648/._image_5.png  \n",
            "  inflating: hidden/video_16648/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16648/._image_7.png  \n",
            "  inflating: hidden/video_16648/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16648/._image_6.png  \n",
            "  inflating: hidden/video_15650/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15650/._image_10.png  \n",
            "  inflating: hidden/video_15650/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15650/._image_8.png  \n",
            "  inflating: hidden/video_15650/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15650/._image_9.png  \n",
            "  inflating: hidden/video_15650/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15650/._image_2.png  \n",
            "  inflating: hidden/video_15650/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15650/._image_3.png  \n",
            "  inflating: hidden/video_15650/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15650/._image_1.png  \n",
            "  inflating: hidden/video_15650/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15650/._image_0.png  \n",
            "  inflating: hidden/video_15650/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15650/._image_4.png  \n",
            "  inflating: hidden/video_15650/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15650/._image_5.png  \n",
            "  inflating: hidden/video_15650/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15650/._image_7.png  \n",
            "  inflating: hidden/video_15650/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15650/._image_6.png  \n",
            "  inflating: hidden/video_15462/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15462/._image_10.png  \n",
            "  inflating: hidden/video_15462/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15462/._image_8.png  \n",
            "  inflating: hidden/video_15462/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15462/._image_9.png  \n",
            "  inflating: hidden/video_15462/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15462/._image_2.png  \n",
            "  inflating: hidden/video_15462/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15462/._image_3.png  \n",
            "  inflating: hidden/video_15462/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15462/._image_1.png  \n",
            "  inflating: hidden/video_15462/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15462/._image_0.png  \n",
            "  inflating: hidden/video_15462/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15462/._image_4.png  \n",
            "  inflating: hidden/video_15462/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15462/._image_5.png  \n",
            "  inflating: hidden/video_15462/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15462/._image_7.png  \n",
            "  inflating: hidden/video_15462/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15462/._image_6.png  \n",
            "  inflating: hidden/video_15006/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15006/._image_10.png  \n",
            "  inflating: hidden/video_15006/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15006/._image_8.png  \n",
            "  inflating: hidden/video_15006/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15006/._image_9.png  \n",
            "  inflating: hidden/video_15006/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15006/._image_2.png  \n",
            "  inflating: hidden/video_15006/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15006/._image_3.png  \n",
            "  inflating: hidden/video_15006/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15006/._image_1.png  \n",
            "  inflating: hidden/video_15006/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15006/._image_0.png  \n",
            "  inflating: hidden/video_15006/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15006/._image_4.png  \n",
            "  inflating: hidden/video_15006/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15006/._image_5.png  \n",
            "  inflating: hidden/video_15006/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15006/._image_7.png  \n",
            "  inflating: hidden/video_15006/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15006/._image_6.png  \n",
            "  inflating: hidden/video_16683/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16683/._image_10.png  \n",
            "  inflating: hidden/video_16683/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16683/._image_8.png  \n",
            "  inflating: hidden/video_16683/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16683/._image_9.png  \n",
            "  inflating: hidden/video_16683/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16683/._image_2.png  \n",
            "  inflating: hidden/video_16683/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16683/._image_3.png  \n",
            "  inflating: hidden/video_16683/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16683/._image_1.png  \n",
            "  inflating: hidden/video_16683/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16683/._image_0.png  \n",
            "  inflating: hidden/video_16683/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16683/._image_4.png  \n",
            "  inflating: hidden/video_16683/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16683/._image_5.png  \n",
            "  inflating: hidden/video_16683/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16683/._image_7.png  \n",
            "  inflating: hidden/video_16683/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16683/._image_6.png  \n",
            "  inflating: hidden/video_15234/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15234/._image_10.png  \n",
            "  inflating: hidden/video_15234/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15234/._image_8.png  \n",
            "  inflating: hidden/video_15234/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15234/._image_9.png  \n",
            "  inflating: hidden/video_15234/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15234/._image_2.png  \n",
            "  inflating: hidden/video_15234/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15234/._image_3.png  \n",
            "  inflating: hidden/video_15234/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15234/._image_1.png  \n",
            "  inflating: hidden/video_15234/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15234/._image_0.png  \n",
            "  inflating: hidden/video_15234/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15234/._image_4.png  \n",
            "  inflating: hidden/video_15234/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15234/._image_5.png  \n",
            "  inflating: hidden/video_15234/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15234/._image_7.png  \n",
            "  inflating: hidden/video_15234/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15234/._image_6.png  \n",
            "  inflating: hidden/video_16677/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16677/._image_10.png  \n",
            "  inflating: hidden/video_16677/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16677/._image_8.png  \n",
            "  inflating: hidden/video_16677/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16677/._image_9.png  \n",
            "  inflating: hidden/video_16677/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16677/._image_2.png  \n",
            "  inflating: hidden/video_16677/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16677/._image_3.png  \n",
            "  inflating: hidden/video_16677/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16677/._image_1.png  \n",
            "  inflating: hidden/video_16677/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16677/._image_0.png  \n",
            "  inflating: hidden/video_16677/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16677/._image_4.png  \n",
            "  inflating: hidden/video_16677/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16677/._image_5.png  \n",
            "  inflating: hidden/video_16677/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16677/._image_7.png  \n",
            "  inflating: hidden/video_16677/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16677/._image_6.png  \n",
            "  inflating: hidden/video_16445/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16445/._image_10.png  \n",
            "  inflating: hidden/video_16445/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16445/._image_8.png  \n",
            "  inflating: hidden/video_16445/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16445/._image_9.png  \n",
            "  inflating: hidden/video_16445/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16445/._image_2.png  \n",
            "  inflating: hidden/video_16445/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16445/._image_3.png  \n",
            "  inflating: hidden/video_16445/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16445/._image_1.png  \n",
            "  inflating: hidden/video_16445/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16445/._image_0.png  \n",
            "  inflating: hidden/video_16445/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16445/._image_4.png  \n",
            "  inflating: hidden/video_16445/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16445/._image_5.png  \n",
            "  inflating: hidden/video_16445/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16445/._image_7.png  \n",
            "  inflating: hidden/video_16445/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16445/._image_6.png  \n",
            "  inflating: hidden/video_16021/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16021/._image_10.png  \n",
            "  inflating: hidden/video_16021/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16021/._image_8.png  \n",
            "  inflating: hidden/video_16021/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16021/._image_9.png  \n",
            "  inflating: hidden/video_16021/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16021/._image_2.png  \n",
            "  inflating: hidden/video_16021/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16021/._image_3.png  \n",
            "  inflating: hidden/video_16021/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16021/._image_1.png  \n",
            "  inflating: hidden/video_16021/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16021/._image_0.png  \n",
            "  inflating: hidden/video_16021/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16021/._image_4.png  \n",
            "  inflating: hidden/video_16021/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16021/._image_5.png  \n",
            "  inflating: hidden/video_16021/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16021/._image_7.png  \n",
            "  inflating: hidden/video_16021/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16021/._image_6.png  \n",
            "  inflating: hidden/video_15496/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15496/._image_10.png  \n",
            "  inflating: hidden/video_15496/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15496/._image_8.png  \n",
            "  inflating: hidden/video_15496/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15496/._image_9.png  \n",
            "  inflating: hidden/video_15496/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15496/._image_2.png  \n",
            "  inflating: hidden/video_15496/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15496/._image_3.png  \n",
            "  inflating: hidden/video_15496/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15496/._image_1.png  \n",
            "  inflating: hidden/video_15496/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15496/._image_0.png  \n",
            "  inflating: hidden/video_15496/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15496/._image_4.png  \n",
            "  inflating: hidden/video_15496/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15496/._image_5.png  \n",
            "  inflating: hidden/video_15496/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15496/._image_7.png  \n",
            "  inflating: hidden/video_15496/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15496/._image_6.png  \n",
            "  inflating: hidden/video_16213/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16213/._image_10.png  \n",
            "  inflating: hidden/video_16213/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16213/._image_8.png  \n",
            "  inflating: hidden/video_16213/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16213/._image_9.png  \n",
            "  inflating: hidden/video_16213/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16213/._image_2.png  \n",
            "  inflating: hidden/video_16213/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16213/._image_3.png  \n",
            "  inflating: hidden/video_16213/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16213/._image_1.png  \n",
            "  inflating: hidden/video_16213/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16213/._image_0.png  \n",
            "  inflating: hidden/video_16213/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16213/._image_4.png  \n",
            "  inflating: hidden/video_16213/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16213/._image_5.png  \n",
            "  inflating: hidden/video_16213/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16213/._image_7.png  \n",
            "  inflating: hidden/video_16213/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16213/._image_6.png  \n",
            "  inflating: hidden/video_16019/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16019/._image_10.png  \n",
            "  inflating: hidden/video_16019/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16019/._image_8.png  \n",
            "  inflating: hidden/video_16019/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16019/._image_9.png  \n",
            "  inflating: hidden/video_16019/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16019/._image_2.png  \n",
            "  inflating: hidden/video_16019/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16019/._image_3.png  \n",
            "  inflating: hidden/video_16019/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16019/._image_1.png  \n",
            "  inflating: hidden/video_16019/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16019/._image_0.png  \n",
            "  inflating: hidden/video_16019/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16019/._image_4.png  \n",
            "  inflating: hidden/video_16019/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16019/._image_5.png  \n",
            "  inflating: hidden/video_16019/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16019/._image_7.png  \n",
            "  inflating: hidden/video_16019/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16019/._image_6.png  \n",
            "  inflating: hidden/video_16825/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16825/._image_10.png  \n",
            "  inflating: hidden/video_16825/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16825/._image_8.png  \n",
            "  inflating: hidden/video_16825/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16825/._image_9.png  \n",
            "  inflating: hidden/video_16825/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16825/._image_2.png  \n",
            "  inflating: hidden/video_16825/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16825/._image_3.png  \n",
            "  inflating: hidden/video_16825/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16825/._image_1.png  \n",
            "  inflating: hidden/video_16825/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16825/._image_0.png  \n",
            "  inflating: hidden/video_16825/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16825/._image_4.png  \n",
            "  inflating: hidden/video_16825/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16825/._image_5.png  \n",
            "  inflating: hidden/video_16825/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16825/._image_7.png  \n",
            "  inflating: hidden/video_16825/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16825/._image_6.png  \n",
            "  inflating: hidden/video_15668/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15668/._image_10.png  \n",
            "  inflating: hidden/video_15668/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15668/._image_8.png  \n",
            "  inflating: hidden/video_15668/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15668/._image_9.png  \n",
            "  inflating: hidden/video_15668/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15668/._image_2.png  \n",
            "  inflating: hidden/video_15668/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15668/._image_3.png  \n",
            "  inflating: hidden/video_15668/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15668/._image_1.png  \n",
            "  inflating: hidden/video_15668/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15668/._image_0.png  \n",
            "  inflating: hidden/video_15668/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15668/._image_4.png  \n",
            "  inflating: hidden/video_15668/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15668/._image_5.png  \n",
            "  inflating: hidden/video_15668/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15668/._image_7.png  \n",
            "  inflating: hidden/video_15668/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15668/._image_6.png  \n",
            "  inflating: hidden/video_15802/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15802/._image_10.png  \n",
            "  inflating: hidden/video_15802/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15802/._image_8.png  \n",
            "  inflating: hidden/video_15802/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15802/._image_9.png  \n",
            "  inflating: hidden/video_15802/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15802/._image_2.png  \n",
            "  inflating: hidden/video_15802/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15802/._image_3.png  \n",
            "  inflating: hidden/video_15802/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15802/._image_1.png  \n",
            "  inflating: hidden/video_15802/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15802/._image_0.png  \n",
            "  inflating: hidden/video_15802/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15802/._image_4.png  \n",
            "  inflating: hidden/video_15802/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15802/._image_5.png  \n",
            "  inflating: hidden/video_15802/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15802/._image_7.png  \n",
            "  inflating: hidden/video_15802/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15802/._image_6.png  \n",
            "  inflating: hidden/video_16489/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16489/._image_10.png  \n",
            "  inflating: hidden/video_16489/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16489/._image_8.png  \n",
            "  inflating: hidden/video_16489/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16489/._image_9.png  \n",
            "  inflating: hidden/video_16489/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16489/._image_2.png  \n",
            "  inflating: hidden/video_16489/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16489/._image_3.png  \n",
            "  inflating: hidden/video_16489/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16489/._image_1.png  \n",
            "  inflating: hidden/video_16489/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16489/._image_0.png  \n",
            "  inflating: hidden/video_16489/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16489/._image_4.png  \n",
            "  inflating: hidden/video_16489/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16489/._image_5.png  \n",
            "  inflating: hidden/video_16489/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16489/._image_7.png  \n",
            "  inflating: hidden/video_16489/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16489/._image_6.png  \n",
            "  inflating: hidden/video_15491/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15491/._image_10.png  \n",
            "  inflating: hidden/video_15491/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15491/._image_8.png  \n",
            "  inflating: hidden/video_15491/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15491/._image_9.png  \n",
            "  inflating: hidden/video_15491/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15491/._image_2.png  \n",
            "  inflating: hidden/video_15491/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15491/._image_3.png  \n",
            "  inflating: hidden/video_15491/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15491/._image_1.png  \n",
            "  inflating: hidden/video_15491/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15491/._image_0.png  \n",
            "  inflating: hidden/video_15491/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15491/._image_4.png  \n",
            "  inflating: hidden/video_15491/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15491/._image_5.png  \n",
            "  inflating: hidden/video_15491/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15491/._image_7.png  \n",
            "  inflating: hidden/video_15491/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15491/._image_6.png  \n",
            "  inflating: hidden/video_16214/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16214/._image_10.png  \n",
            "  inflating: hidden/video_16214/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16214/._image_8.png  \n",
            "  inflating: hidden/video_16214/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16214/._image_9.png  \n",
            "  inflating: hidden/video_16214/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16214/._image_2.png  \n",
            "  inflating: hidden/video_16214/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16214/._image_3.png  \n",
            "  inflating: hidden/video_16214/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16214/._image_1.png  \n",
            "  inflating: hidden/video_16214/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16214/._image_0.png  \n",
            "  inflating: hidden/video_16214/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16214/._image_4.png  \n",
            "  inflating: hidden/video_16214/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16214/._image_5.png  \n",
            "  inflating: hidden/video_16214/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16214/._image_7.png  \n",
            "  inflating: hidden/video_16214/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16214/._image_6.png  \n",
            "  inflating: hidden/video_16026/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16026/._image_10.png  \n",
            "  inflating: hidden/video_16026/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16026/._image_8.png  \n",
            "  inflating: hidden/video_16026/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16026/._image_9.png  \n",
            "  inflating: hidden/video_16026/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16026/._image_2.png  \n",
            "  inflating: hidden/video_16026/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16026/._image_3.png  \n",
            "  inflating: hidden/video_16026/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16026/._image_1.png  \n",
            "  inflating: hidden/video_16026/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16026/._image_0.png  \n",
            "  inflating: hidden/video_16026/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16026/._image_4.png  \n",
            "  inflating: hidden/video_16026/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16026/._image_5.png  \n",
            "  inflating: hidden/video_16026/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16026/._image_7.png  \n",
            "  inflating: hidden/video_16026/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16026/._image_6.png  \n",
            "  inflating: hidden/video_16442/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16442/._image_10.png  \n",
            "  inflating: hidden/video_16442/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16442/._image_8.png  \n",
            "  inflating: hidden/video_16442/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16442/._image_9.png  \n",
            "  inflating: hidden/video_16442/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16442/._image_2.png  \n",
            "  inflating: hidden/video_16442/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16442/._image_3.png  \n",
            "  inflating: hidden/video_16442/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16442/._image_1.png  \n",
            "  inflating: hidden/video_16442/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16442/._image_0.png  \n",
            "  inflating: hidden/video_16442/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16442/._image_4.png  \n",
            "  inflating: hidden/video_16442/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16442/._image_5.png  \n",
            "  inflating: hidden/video_16442/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16442/._image_7.png  \n",
            "  inflating: hidden/video_16442/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16442/._image_6.png  \n",
            "  inflating: hidden/video_16670/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16670/._image_10.png  \n",
            "  inflating: hidden/video_16670/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16670/._image_8.png  \n",
            "  inflating: hidden/video_16670/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16670/._image_9.png  \n",
            "  inflating: hidden/video_16670/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16670/._image_2.png  \n",
            "  inflating: hidden/video_16670/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16670/._image_3.png  \n",
            "  inflating: hidden/video_16670/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16670/._image_1.png  \n",
            "  inflating: hidden/video_16670/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16670/._image_0.png  \n",
            "  inflating: hidden/video_16670/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16670/._image_4.png  \n",
            "  inflating: hidden/video_16670/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16670/._image_5.png  \n",
            "  inflating: hidden/video_16670/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16670/._image_7.png  \n",
            "  inflating: hidden/video_16670/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16670/._image_6.png  \n",
            "  inflating: hidden/video_15233/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15233/._image_10.png  \n",
            "  inflating: hidden/video_15233/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15233/._image_8.png  \n",
            "  inflating: hidden/video_15233/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15233/._image_9.png  \n",
            "  inflating: hidden/video_15233/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15233/._image_2.png  \n",
            "  inflating: hidden/video_15233/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15233/._image_3.png  \n",
            "  inflating: hidden/video_15233/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15233/._image_1.png  \n",
            "  inflating: hidden/video_15233/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15233/._image_0.png  \n",
            "  inflating: hidden/video_15233/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15233/._image_4.png  \n",
            "  inflating: hidden/video_15233/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15233/._image_5.png  \n",
            "  inflating: hidden/video_15233/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15233/._image_7.png  \n",
            "  inflating: hidden/video_15233/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15233/._image_6.png  \n",
            "  inflating: hidden/video_15001/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15001/._image_10.png  \n",
            "  inflating: hidden/video_15001/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15001/._image_8.png  \n",
            "  inflating: hidden/video_15001/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15001/._image_9.png  \n",
            "  inflating: hidden/video_15001/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15001/._image_2.png  \n",
            "  inflating: hidden/video_15001/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15001/._image_3.png  \n",
            "  inflating: hidden/video_15001/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15001/._image_1.png  \n",
            "  inflating: hidden/video_15001/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15001/._image_0.png  \n",
            "  inflating: hidden/video_15001/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15001/._image_4.png  \n",
            "  inflating: hidden/video_15001/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15001/._image_5.png  \n",
            "  inflating: hidden/video_15001/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15001/._image_7.png  \n",
            "  inflating: hidden/video_15001/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15001/._image_6.png  \n",
            "  inflating: hidden/video_16684/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16684/._image_10.png  \n",
            "  inflating: hidden/video_16684/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16684/._image_8.png  \n",
            "  inflating: hidden/video_16684/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16684/._image_9.png  \n",
            "  inflating: hidden/video_16684/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16684/._image_2.png  \n",
            "  inflating: hidden/video_16684/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16684/._image_3.png  \n",
            "  inflating: hidden/video_16684/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16684/._image_1.png  \n",
            "  inflating: hidden/video_16684/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16684/._image_0.png  \n",
            "  inflating: hidden/video_16684/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16684/._image_4.png  \n",
            "  inflating: hidden/video_16684/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16684/._image_5.png  \n",
            "  inflating: hidden/video_16684/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16684/._image_7.png  \n",
            "  inflating: hidden/video_16684/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16684/._image_6.png  \n",
            "  inflating: hidden/video_15465/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15465/._image_10.png  \n",
            "  inflating: hidden/video_15465/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15465/._image_8.png  \n",
            "  inflating: hidden/video_15465/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15465/._image_9.png  \n",
            "  inflating: hidden/video_15465/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15465/._image_2.png  \n",
            "  inflating: hidden/video_15465/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15465/._image_3.png  \n",
            "  inflating: hidden/video_15465/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15465/._image_1.png  \n",
            "  inflating: hidden/video_15465/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15465/._image_0.png  \n",
            "  inflating: hidden/video_15465/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15465/._image_4.png  \n",
            "  inflating: hidden/video_15465/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15465/._image_5.png  \n",
            "  inflating: hidden/video_15465/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15465/._image_7.png  \n",
            "  inflating: hidden/video_15465/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15465/._image_6.png  \n",
            "  inflating: hidden/video_15657/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15657/._image_10.png  \n",
            "  inflating: hidden/video_15657/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15657/._image_8.png  \n",
            "  inflating: hidden/video_15657/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15657/._image_9.png  \n",
            "  inflating: hidden/video_15657/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15657/._image_2.png  \n",
            "  inflating: hidden/video_15657/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15657/._image_3.png  \n",
            "  inflating: hidden/video_15657/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15657/._image_1.png  \n",
            "  inflating: hidden/video_15657/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15657/._image_0.png  \n",
            "  inflating: hidden/video_15657/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15657/._image_4.png  \n",
            "  inflating: hidden/video_15657/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15657/._image_5.png  \n",
            "  inflating: hidden/video_15657/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15657/._image_7.png  \n",
            "  inflating: hidden/video_15657/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15657/._image_6.png  \n",
            "  inflating: hidden/video_15406/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15406/._image_10.png  \n",
            "  inflating: hidden/video_15406/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15406/._image_8.png  \n",
            "  inflating: hidden/video_15406/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15406/._image_9.png  \n",
            "  inflating: hidden/video_15406/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15406/._image_2.png  \n",
            "  inflating: hidden/video_15406/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15406/._image_3.png  \n",
            "  inflating: hidden/video_15406/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15406/._image_1.png  \n",
            "  inflating: hidden/video_15406/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15406/._image_0.png  \n",
            "  inflating: hidden/video_15406/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15406/._image_4.png  \n",
            "  inflating: hidden/video_15406/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15406/._image_5.png  \n",
            "  inflating: hidden/video_15406/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15406/._image_7.png  \n",
            "  inflating: hidden/video_15406/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15406/._image_6.png  \n",
            "  inflating: hidden/video_16283/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16283/._image_10.png  \n",
            "  inflating: hidden/video_16283/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16283/._image_8.png  \n",
            "  inflating: hidden/video_16283/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16283/._image_9.png  \n",
            "  inflating: hidden/video_16283/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16283/._image_2.png  \n",
            "  inflating: hidden/video_16283/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16283/._image_3.png  \n",
            "  inflating: hidden/video_16283/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16283/._image_1.png  \n",
            "  inflating: hidden/video_16283/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16283/._image_0.png  \n",
            "  inflating: hidden/video_16283/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16283/._image_4.png  \n",
            "  inflating: hidden/video_16283/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16283/._image_5.png  \n",
            "  inflating: hidden/video_16283/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16283/._image_7.png  \n",
            "  inflating: hidden/video_16283/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16283/._image_6.png  \n",
            "  inflating: hidden/video_15634/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15634/._image_10.png  \n",
            "  inflating: hidden/video_15634/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15634/._image_8.png  \n",
            "  inflating: hidden/video_15634/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15634/._image_9.png  \n",
            "  inflating: hidden/video_15634/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15634/._image_2.png  \n",
            "  inflating: hidden/video_15634/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15634/._image_3.png  \n",
            "  inflating: hidden/video_15634/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15634/._image_1.png  \n",
            "  inflating: hidden/video_15634/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15634/._image_0.png  \n",
            "  inflating: hidden/video_15634/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15634/._image_4.png  \n",
            "  inflating: hidden/video_15634/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15634/._image_5.png  \n",
            "  inflating: hidden/video_15634/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15634/._image_7.png  \n",
            "  inflating: hidden/video_15634/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15634/._image_6.png  \n",
            "  inflating: hidden/video_15250/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15250/._image_10.png  \n",
            "  inflating: hidden/video_15250/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15250/._image_8.png  \n",
            "  inflating: hidden/video_15250/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15250/._image_9.png  \n",
            "  inflating: hidden/video_15250/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15250/._image_2.png  \n",
            "  inflating: hidden/video_15250/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15250/._image_3.png  \n",
            "  inflating: hidden/video_15250/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15250/._image_1.png  \n",
            "  inflating: hidden/video_15250/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15250/._image_0.png  \n",
            "  inflating: hidden/video_15250/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15250/._image_4.png  \n",
            "  inflating: hidden/video_15250/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15250/._image_5.png  \n",
            "  inflating: hidden/video_15250/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15250/._image_7.png  \n",
            "  inflating: hidden/video_15250/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15250/._image_6.png  \n",
            "  inflating: hidden/video_15062/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15062/._image_10.png  \n",
            "  inflating: hidden/video_15062/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15062/._image_8.png  \n",
            "  inflating: hidden/video_15062/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15062/._image_9.png  \n",
            "  inflating: hidden/video_15062/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15062/._image_2.png  \n",
            "  inflating: hidden/video_15062/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15062/._image_3.png  \n",
            "  inflating: hidden/video_15062/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15062/._image_1.png  \n",
            "  inflating: hidden/video_15062/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15062/._image_0.png  \n",
            "  inflating: hidden/video_15062/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15062/._image_4.png  \n",
            "  inflating: hidden/video_15062/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15062/._image_5.png  \n",
            "  inflating: hidden/video_15062/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15062/._image_7.png  \n",
            "  inflating: hidden/video_15062/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15062/._image_6.png  \n",
            "  inflating: hidden/video_16421/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16421/._image_10.png  \n",
            "  inflating: hidden/video_16421/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16421/._image_8.png  \n",
            "  inflating: hidden/video_16421/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16421/._image_9.png  \n",
            "  inflating: hidden/video_16421/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16421/._image_2.png  \n",
            "  inflating: hidden/video_16421/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16421/._image_3.png  \n",
            "  inflating: hidden/video_16421/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16421/._image_1.png  \n",
            "  inflating: hidden/video_16421/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16421/._image_0.png  \n",
            "  inflating: hidden/video_16421/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16421/._image_4.png  \n",
            "  inflating: hidden/video_16421/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16421/._image_5.png  \n",
            "  inflating: hidden/video_16421/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16421/._image_7.png  \n",
            "  inflating: hidden/video_16421/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16421/._image_6.png  \n",
            "  inflating: hidden/video_15096/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15096/._image_10.png  \n",
            "  inflating: hidden/video_15096/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15096/._image_8.png  \n",
            "  inflating: hidden/video_15096/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15096/._image_9.png  \n",
            "  inflating: hidden/video_15096/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15096/._image_2.png  \n",
            "  inflating: hidden/video_15096/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15096/._image_3.png  \n",
            "  inflating: hidden/video_15096/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15096/._image_1.png  \n",
            "  inflating: hidden/video_15096/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15096/._image_0.png  \n",
            "  inflating: hidden/video_15096/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15096/._image_4.png  \n",
            "  inflating: hidden/video_15096/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15096/._image_5.png  \n",
            "  inflating: hidden/video_15096/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15096/._image_7.png  \n",
            "  inflating: hidden/video_15096/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15096/._image_6.png  \n",
            "  inflating: hidden/video_16613/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16613/._image_10.png  \n",
            "  inflating: hidden/video_16613/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16613/._image_8.png  \n",
            "  inflating: hidden/video_16613/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16613/._image_9.png  \n",
            "  inflating: hidden/video_16613/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16613/._image_2.png  \n",
            "  inflating: hidden/video_16613/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16613/._image_3.png  \n",
            "  inflating: hidden/video_16613/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16613/._image_1.png  \n",
            "  inflating: hidden/video_16613/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16613/._image_0.png  \n",
            "  inflating: hidden/video_16613/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16613/._image_4.png  \n",
            "  inflating: hidden/video_16613/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16613/._image_5.png  \n",
            "  inflating: hidden/video_16613/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16613/._image_7.png  \n",
            "  inflating: hidden/video_16613/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16613/._image_6.png  \n",
            "  inflating: hidden/video_16277/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16277/._image_10.png  \n",
            "  inflating: hidden/video_16277/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16277/._image_8.png  \n",
            "  inflating: hidden/video_16277/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16277/._image_9.png  \n",
            "  inflating: hidden/video_16277/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16277/._image_2.png  \n",
            "  inflating: hidden/video_16277/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16277/._image_3.png  \n",
            "  inflating: hidden/video_16277/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16277/._image_1.png  \n",
            "  inflating: hidden/video_16277/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16277/._image_0.png  \n",
            "  inflating: hidden/video_16277/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16277/._image_4.png  \n",
            "  inflating: hidden/video_16277/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16277/._image_5.png  \n",
            "  inflating: hidden/video_16277/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16277/._image_7.png  \n",
            "  inflating: hidden/video_16277/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16277/._image_6.png  \n",
            "  inflating: hidden/video_16045/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16045/._image_10.png  \n",
            "  inflating: hidden/video_16045/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16045/._image_8.png  \n",
            "  inflating: hidden/video_16045/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16045/._image_9.png  \n",
            "  inflating: hidden/video_16045/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16045/._image_2.png  \n",
            "  inflating: hidden/video_16045/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16045/._image_3.png  \n",
            "  inflating: hidden/video_16045/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16045/._image_1.png  \n",
            "  inflating: hidden/video_16045/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16045/._image_0.png  \n",
            "  inflating: hidden/video_16045/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16045/._image_4.png  \n",
            "  inflating: hidden/video_16045/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16045/._image_5.png  \n",
            "  inflating: hidden/video_16045/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16045/._image_7.png  \n",
            "  inflating: hidden/video_16045/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16045/._image_6.png  \n",
            "  inflating: hidden/video_16879/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16879/._image_10.png  \n",
            "  inflating: hidden/video_16879/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16879/._image_8.png  \n",
            "  inflating: hidden/video_16879/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16879/._image_9.png  \n",
            "  inflating: hidden/video_16879/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16879/._image_2.png  \n",
            "  inflating: hidden/video_16879/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16879/._image_3.png  \n",
            "  inflating: hidden/video_16879/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16879/._image_1.png  \n",
            "  inflating: hidden/video_16879/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16879/._image_0.png  \n",
            "  inflating: hidden/video_16879/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16879/._image_4.png  \n",
            "  inflating: hidden/video_16879/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16879/._image_5.png  \n",
            "  inflating: hidden/video_16879/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16879/._image_7.png  \n",
            "  inflating: hidden/video_16879/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16879/._image_6.png  \n",
            "  inflating: hidden/video_15861/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15861/._image_10.png  \n",
            "  inflating: hidden/video_15861/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15861/._image_8.png  \n",
            "  inflating: hidden/video_15861/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15861/._image_9.png  \n",
            "  inflating: hidden/video_15861/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15861/._image_2.png  \n",
            "  inflating: hidden/video_15861/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15861/._image_3.png  \n",
            "  inflating: hidden/video_15861/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15861/._image_1.png  \n",
            "  inflating: hidden/video_15861/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15861/._image_0.png  \n",
            "  inflating: hidden/video_15861/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15861/._image_4.png  \n",
            "  inflating: hidden/video_15861/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15861/._image_5.png  \n",
            "  inflating: hidden/video_15861/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15861/._image_7.png  \n",
            "  inflating: hidden/video_15861/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15861/._image_6.png  \n",
            "  inflating: hidden/video_15439/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15439/._image_10.png  \n",
            "  inflating: hidden/video_15439/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15439/._image_8.png  \n",
            "  inflating: hidden/video_15439/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15439/._image_9.png  \n",
            "  inflating: hidden/video_15439/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15439/._image_2.png  \n",
            "  inflating: hidden/video_15439/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15439/._image_3.png  \n",
            "  inflating: hidden/video_15439/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15439/._image_1.png  \n",
            "  inflating: hidden/video_15439/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15439/._image_0.png  \n",
            "  inflating: hidden/video_15439/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15439/._image_4.png  \n",
            "  inflating: hidden/video_15439/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15439/._image_5.png  \n",
            "  inflating: hidden/video_15439/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15439/._image_7.png  \n",
            "  inflating: hidden/video_15439/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15439/._image_6.png  \n",
            "  inflating: hidden/video_16846/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16846/._image_10.png  \n",
            "  inflating: hidden/video_16846/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16846/._image_8.png  \n",
            "  inflating: hidden/video_16846/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16846/._image_9.png  \n",
            "  inflating: hidden/video_16846/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16846/._image_2.png  \n",
            "  inflating: hidden/video_16846/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16846/._image_3.png  \n",
            "  inflating: hidden/video_16846/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16846/._image_1.png  \n",
            "  inflating: hidden/video_16846/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16846/._image_0.png  \n",
            "  inflating: hidden/video_16846/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16846/._image_4.png  \n",
            "  inflating: hidden/video_16846/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16846/._image_5.png  \n",
            "  inflating: hidden/video_16846/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16846/._image_7.png  \n",
            "  inflating: hidden/video_16846/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16846/._image_6.png  \n",
            "  inflating: hidden/video_16248/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16248/._image_10.png  \n",
            "  inflating: hidden/video_16248/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16248/._image_8.png  \n",
            "  inflating: hidden/video_16248/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16248/._image_9.png  \n",
            "  inflating: hidden/video_16248/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16248/._image_2.png  \n",
            "  inflating: hidden/video_16248/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16248/._image_3.png  \n",
            "  inflating: hidden/video_16248/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16248/._image_1.png  \n",
            "  inflating: hidden/video_16248/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16248/._image_0.png  \n",
            "  inflating: hidden/video_16248/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16248/._image_4.png  \n",
            "  inflating: hidden/video_16248/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16248/._image_5.png  \n",
            "  inflating: hidden/video_16248/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16248/._image_7.png  \n",
            "  inflating: hidden/video_16248/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16248/._image_6.png  \n",
            "  inflating: hidden/video_15895/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15895/._image_10.png  \n",
            "  inflating: hidden/video_15895/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15895/._image_8.png  \n",
            "  inflating: hidden/video_15895/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15895/._image_9.png  \n",
            "  inflating: hidden/video_15895/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15895/._image_2.png  \n",
            "  inflating: hidden/video_15895/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15895/._image_3.png  \n",
            "  inflating: hidden/video_15895/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15895/._image_1.png  \n",
            "  inflating: hidden/video_15895/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15895/._image_0.png  \n",
            "  inflating: hidden/video_15895/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15895/._image_4.png  \n",
            "  inflating: hidden/video_15895/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15895/._image_5.png  \n",
            "  inflating: hidden/video_15895/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15895/._image_7.png  \n",
            "  inflating: hidden/video_15895/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15895/._image_6.png  \n",
            "  inflating: hidden/video_16042/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16042/._image_10.png  \n",
            "  inflating: hidden/video_16042/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16042/._image_8.png  \n",
            "  inflating: hidden/video_16042/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16042/._image_9.png  \n",
            "  inflating: hidden/video_16042/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16042/._image_2.png  \n",
            "  inflating: hidden/video_16042/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16042/._image_3.png  \n",
            "  inflating: hidden/video_16042/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16042/._image_1.png  \n",
            "  inflating: hidden/video_16042/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16042/._image_0.png  \n",
            "  inflating: hidden/video_16042/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16042/._image_4.png  \n",
            "  inflating: hidden/video_16042/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16042/._image_5.png  \n",
            "  inflating: hidden/video_16042/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16042/._image_7.png  \n",
            "  inflating: hidden/video_16042/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16042/._image_6.png  \n",
            "  inflating: hidden/video_16270/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16270/._image_10.png  \n",
            "  inflating: hidden/video_16270/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16270/._image_8.png  \n",
            "  inflating: hidden/video_16270/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16270/._image_9.png  \n",
            "  inflating: hidden/video_16270/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16270/._image_2.png  \n",
            "  inflating: hidden/video_16270/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16270/._image_3.png  \n",
            "  inflating: hidden/video_16270/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16270/._image_1.png  \n",
            "  inflating: hidden/video_16270/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16270/._image_0.png  \n",
            "  inflating: hidden/video_16270/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16270/._image_4.png  \n",
            "  inflating: hidden/video_16270/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16270/._image_5.png  \n",
            "  inflating: hidden/video_16270/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16270/._image_7.png  \n",
            "  inflating: hidden/video_16270/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16270/._image_6.png  \n",
            "  inflating: hidden/video_15091/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15091/._image_10.png  \n",
            "  inflating: hidden/video_15091/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15091/._image_8.png  \n",
            "  inflating: hidden/video_15091/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15091/._image_9.png  \n",
            "  inflating: hidden/video_15091/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15091/._image_2.png  \n",
            "  inflating: hidden/video_15091/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15091/._image_3.png  \n",
            "  inflating: hidden/video_15091/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15091/._image_1.png  \n",
            "  inflating: hidden/video_15091/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15091/._image_0.png  \n",
            "  inflating: hidden/video_15091/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15091/._image_4.png  \n",
            "  inflating: hidden/video_15091/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15091/._image_5.png  \n",
            "  inflating: hidden/video_15091/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15091/._image_7.png  \n",
            "  inflating: hidden/video_15091/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15091/._image_6.png  \n",
            "  inflating: hidden/video_16614/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16614/._image_10.png  \n",
            "  inflating: hidden/video_16614/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16614/._image_8.png  \n",
            "  inflating: hidden/video_16614/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16614/._image_9.png  \n",
            "  inflating: hidden/video_16614/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16614/._image_2.png  \n",
            "  inflating: hidden/video_16614/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16614/._image_3.png  \n",
            "  inflating: hidden/video_16614/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16614/._image_1.png  \n",
            "  inflating: hidden/video_16614/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16614/._image_0.png  \n",
            "  inflating: hidden/video_16614/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16614/._image_4.png  \n",
            "  inflating: hidden/video_16614/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16614/._image_5.png  \n",
            "  inflating: hidden/video_16614/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16614/._image_7.png  \n",
            "  inflating: hidden/video_16614/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16614/._image_6.png  \n",
            "  inflating: hidden/video_16426/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16426/._image_10.png  \n",
            "  inflating: hidden/video_16426/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16426/._image_8.png  \n",
            "  inflating: hidden/video_16426/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16426/._image_9.png  \n",
            "  inflating: hidden/video_16426/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16426/._image_2.png  \n",
            "  inflating: hidden/video_16426/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16426/._image_3.png  \n",
            "  inflating: hidden/video_16426/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16426/._image_1.png  \n",
            "  inflating: hidden/video_16426/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16426/._image_0.png  \n",
            "  inflating: hidden/video_16426/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16426/._image_4.png  \n",
            "  inflating: hidden/video_16426/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16426/._image_5.png  \n",
            "  inflating: hidden/video_16426/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16426/._image_7.png  \n",
            "  inflating: hidden/video_16426/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16426/._image_6.png  \n",
            "  inflating: hidden/video_15859/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15859/._image_10.png  \n",
            "  inflating: hidden/video_15859/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15859/._image_8.png  \n",
            "  inflating: hidden/video_15859/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15859/._image_9.png  \n",
            "  inflating: hidden/video_15859/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15859/._image_2.png  \n",
            "  inflating: hidden/video_15859/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15859/._image_3.png  \n",
            "  inflating: hidden/video_15859/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15859/._image_1.png  \n",
            "  inflating: hidden/video_15859/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15859/._image_0.png  \n",
            "  inflating: hidden/video_15859/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15859/._image_4.png  \n",
            "  inflating: hidden/video_15859/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15859/._image_5.png  \n",
            "  inflating: hidden/video_15859/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15859/._image_7.png  \n",
            "  inflating: hidden/video_15859/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15859/._image_6.png  \n",
            "  inflating: hidden/video_15065/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15065/._image_10.png  \n",
            "  inflating: hidden/video_15065/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15065/._image_8.png  \n",
            "  inflating: hidden/video_15065/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15065/._image_9.png  \n",
            "  inflating: hidden/video_15065/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15065/._image_2.png  \n",
            "  inflating: hidden/video_15065/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15065/._image_3.png  \n",
            "  inflating: hidden/video_15065/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15065/._image_1.png  \n",
            "  inflating: hidden/video_15065/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15065/._image_0.png  \n",
            "  inflating: hidden/video_15065/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15065/._image_4.png  \n",
            "  inflating: hidden/video_15065/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15065/._image_5.png  \n",
            "  inflating: hidden/video_15065/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15065/._image_7.png  \n",
            "  inflating: hidden/video_15065/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15065/._image_6.png  \n",
            "  inflating: hidden/video_15257/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15257/._image_10.png  \n",
            "  inflating: hidden/video_15257/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15257/._image_8.png  \n",
            "  inflating: hidden/video_15257/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15257/._image_9.png  \n",
            "  inflating: hidden/video_15257/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15257/._image_2.png  \n",
            "  inflating: hidden/video_15257/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15257/._image_3.png  \n",
            "  inflating: hidden/video_15257/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15257/._image_1.png  \n",
            "  inflating: hidden/video_15257/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15257/._image_0.png  \n",
            "  inflating: hidden/video_15257/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15257/._image_4.png  \n",
            "  inflating: hidden/video_15257/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15257/._image_5.png  \n",
            "  inflating: hidden/video_15257/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15257/._image_7.png  \n",
            "  inflating: hidden/video_15257/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15257/._image_6.png  \n",
            "  inflating: hidden/video_15633/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15633/._image_10.png  \n",
            "  inflating: hidden/video_15633/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15633/._image_8.png  \n",
            "  inflating: hidden/video_15633/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15633/._image_9.png  \n",
            "  inflating: hidden/video_15633/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15633/._image_2.png  \n",
            "  inflating: hidden/video_15633/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15633/._image_3.png  \n",
            "  inflating: hidden/video_15633/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15633/._image_1.png  \n",
            "  inflating: hidden/video_15633/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15633/._image_0.png  \n",
            "  inflating: hidden/video_15633/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15633/._image_4.png  \n",
            "  inflating: hidden/video_15633/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15633/._image_5.png  \n",
            "  inflating: hidden/video_15633/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15633/._image_7.png  \n",
            "  inflating: hidden/video_15633/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15633/._image_6.png  \n",
            "  inflating: hidden/video_15401/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15401/._image_10.png  \n",
            "  inflating: hidden/video_15401/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15401/._image_8.png  \n",
            "  inflating: hidden/video_15401/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15401/._image_9.png  \n",
            "  inflating: hidden/video_15401/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15401/._image_2.png  \n",
            "  inflating: hidden/video_15401/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15401/._image_3.png  \n",
            "  inflating: hidden/video_15401/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15401/._image_1.png  \n",
            "  inflating: hidden/video_15401/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15401/._image_0.png  \n",
            "  inflating: hidden/video_15401/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15401/._image_4.png  \n",
            "  inflating: hidden/video_15401/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15401/._image_5.png  \n",
            "  inflating: hidden/video_15401/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15401/._image_7.png  \n",
            "  inflating: hidden/video_15401/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15401/._image_6.png  \n",
            "  inflating: hidden/video_16284/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16284/._image_10.png  \n",
            "  inflating: hidden/video_16284/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16284/._image_8.png  \n",
            "  inflating: hidden/video_16284/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16284/._image_9.png  \n",
            "  inflating: hidden/video_16284/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16284/._image_2.png  \n",
            "  inflating: hidden/video_16284/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16284/._image_3.png  \n",
            "  inflating: hidden/video_16284/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16284/._image_1.png  \n",
            "  inflating: hidden/video_16284/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16284/._image_0.png  \n",
            "  inflating: hidden/video_16284/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16284/._image_4.png  \n",
            "  inflating: hidden/video_16284/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16284/._image_5.png  \n",
            "  inflating: hidden/video_16284/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16284/._image_7.png  \n",
            "  inflating: hidden/video_16284/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16284/._image_6.png  \n",
            "  inflating: hidden/video_16419/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16419/._image_10.png  \n",
            "  inflating: hidden/video_16419/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16419/._image_8.png  \n",
            "  inflating: hidden/video_16419/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16419/._image_9.png  \n",
            "  inflating: hidden/video_16419/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16419/._image_2.png  \n",
            "  inflating: hidden/video_16419/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16419/._image_3.png  \n",
            "  inflating: hidden/video_16419/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16419/._image_1.png  \n",
            "  inflating: hidden/video_16419/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16419/._image_0.png  \n",
            "  inflating: hidden/video_16419/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16419/._image_4.png  \n",
            "  inflating: hidden/video_16419/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16419/._image_5.png  \n",
            "  inflating: hidden/video_16419/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16419/._image_7.png  \n",
            "  inflating: hidden/video_16419/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16419/._image_6.png  \n",
            "  inflating: hidden/video_15892/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15892/._image_10.png  \n",
            "  inflating: hidden/video_15892/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15892/._image_8.png  \n",
            "  inflating: hidden/video_15892/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15892/._image_9.png  \n",
            "  inflating: hidden/video_15892/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15892/._image_2.png  \n",
            "  inflating: hidden/video_15892/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15892/._image_3.png  \n",
            "  inflating: hidden/video_15892/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15892/._image_1.png  \n",
            "  inflating: hidden/video_15892/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15892/._image_0.png  \n",
            "  inflating: hidden/video_15892/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15892/._image_4.png  \n",
            "  inflating: hidden/video_15892/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15892/._image_5.png  \n",
            "  inflating: hidden/video_15892/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15892/._image_7.png  \n",
            "  inflating: hidden/video_15892/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15892/._image_6.png  \n",
            "  inflating: hidden/video_16841/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16841/._image_10.png  \n",
            "  inflating: hidden/video_16841/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16841/._image_8.png  \n",
            "  inflating: hidden/video_16841/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16841/._image_9.png  \n",
            "  inflating: hidden/video_16841/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16841/._image_2.png  \n",
            "  inflating: hidden/video_16841/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16841/._image_3.png  \n",
            "  inflating: hidden/video_16841/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16841/._image_1.png  \n",
            "  inflating: hidden/video_16841/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16841/._image_0.png  \n",
            "  inflating: hidden/video_16841/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16841/._image_4.png  \n",
            "  inflating: hidden/video_16841/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16841/._image_5.png  \n",
            "  inflating: hidden/video_16841/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16841/._image_7.png  \n",
            "  inflating: hidden/video_16841/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16841/._image_6.png  \n",
            "  inflating: hidden/video_16089/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16089/._image_10.png  \n",
            "  inflating: hidden/video_16089/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16089/._image_8.png  \n",
            "  inflating: hidden/video_16089/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16089/._image_9.png  \n",
            "  inflating: hidden/video_16089/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16089/._image_2.png  \n",
            "  inflating: hidden/video_16089/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16089/._image_3.png  \n",
            "  inflating: hidden/video_16089/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16089/._image_1.png  \n",
            "  inflating: hidden/video_16089/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16089/._image_0.png  \n",
            "  inflating: hidden/video_16089/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16089/._image_4.png  \n",
            "  inflating: hidden/video_16089/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16089/._image_5.png  \n",
            "  inflating: hidden/video_16089/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16089/._image_7.png  \n",
            "  inflating: hidden/video_16089/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16089/._image_6.png  \n",
            "  inflating: hidden/video_15268/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15268/._image_10.png  \n",
            "  inflating: hidden/video_15268/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15268/._image_8.png  \n",
            "  inflating: hidden/video_15268/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15268/._image_9.png  \n",
            "  inflating: hidden/video_15268/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15268/._image_2.png  \n",
            "  inflating: hidden/video_15268/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15268/._image_3.png  \n",
            "  inflating: hidden/video_15268/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15268/._image_1.png  \n",
            "  inflating: hidden/video_15268/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15268/._image_0.png  \n",
            "  inflating: hidden/video_15268/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15268/._image_4.png  \n",
            "  inflating: hidden/video_15268/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15268/._image_5.png  \n",
            "  inflating: hidden/video_15268/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15268/._image_7.png  \n",
            "  inflating: hidden/video_15268/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15268/._image_6.png  \n",
            "  inflating: hidden/video_15866/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15866/._image_10.png  \n",
            "  inflating: hidden/video_15866/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15866/._image_8.png  \n",
            "  inflating: hidden/video_15866/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15866/._image_9.png  \n",
            "  inflating: hidden/video_15866/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15866/._image_2.png  \n",
            "  inflating: hidden/video_15866/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15866/._image_3.png  \n",
            "  inflating: hidden/video_15866/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15866/._image_1.png  \n",
            "  inflating: hidden/video_15866/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15866/._image_0.png  \n",
            "  inflating: hidden/video_15866/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15866/._image_4.png  \n",
            "  inflating: hidden/video_15866/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15866/._image_5.png  \n",
            "  inflating: hidden/video_15866/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15866/._image_7.png  \n",
            "  inflating: hidden/video_15866/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15866/._image_6.png  \n",
            "  inflating: hidden/video_16622/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16622/._image_10.png  \n",
            "  inflating: hidden/video_16622/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16622/._image_8.png  \n",
            "  inflating: hidden/video_16622/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16622/._image_9.png  \n",
            "  inflating: hidden/video_16622/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16622/._image_2.png  \n",
            "  inflating: hidden/video_16622/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16622/._image_3.png  \n",
            "  inflating: hidden/video_16622/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16622/._image_1.png  \n",
            "  inflating: hidden/video_16622/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16622/._image_0.png  \n",
            "  inflating: hidden/video_16622/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16622/._image_4.png  \n",
            "  inflating: hidden/video_16622/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16622/._image_5.png  \n",
            "  inflating: hidden/video_16622/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16622/._image_7.png  \n",
            "  inflating: hidden/video_16622/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16622/._image_6.png  \n",
            "  inflating: hidden/video_15295/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15295/._image_10.png  \n",
            "  inflating: hidden/video_15295/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15295/._image_8.png  \n",
            "  inflating: hidden/video_15295/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15295/._image_9.png  \n",
            "  inflating: hidden/video_15295/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15295/._image_2.png  \n",
            "  inflating: hidden/video_15295/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15295/._image_3.png  \n",
            "  inflating: hidden/video_15295/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15295/._image_1.png  \n",
            "  inflating: hidden/video_15295/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15295/._image_0.png  \n",
            "  inflating: hidden/video_15295/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15295/._image_4.png  \n",
            "  inflating: hidden/video_15295/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15295/._image_5.png  \n",
            "  inflating: hidden/video_15295/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15295/._image_7.png  \n",
            "  inflating: hidden/video_15295/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15295/._image_6.png  \n",
            "  inflating: hidden/video_16410/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16410/._image_10.png  \n",
            "  inflating: hidden/video_16410/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16410/._image_8.png  \n",
            "  inflating: hidden/video_16410/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16410/._image_9.png  \n",
            "  inflating: hidden/video_16410/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16410/._image_2.png  \n",
            "  inflating: hidden/video_16410/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16410/._image_3.png  \n",
            "  inflating: hidden/video_16410/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16410/._image_1.png  \n",
            "  inflating: hidden/video_16410/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16410/._image_0.png  \n",
            "  inflating: hidden/video_16410/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16410/._image_4.png  \n",
            "  inflating: hidden/video_16410/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16410/._image_5.png  \n",
            "  inflating: hidden/video_16410/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16410/._image_7.png  \n",
            "  inflating: hidden/video_16410/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16410/._image_6.png  \n",
            "  inflating: hidden/video_16074/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16074/._image_10.png  \n",
            "  inflating: hidden/video_16074/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16074/._image_8.png  \n",
            "  inflating: hidden/video_16074/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16074/._image_9.png  \n",
            "  inflating: hidden/video_16074/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16074/._image_2.png  \n",
            "  inflating: hidden/video_16074/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16074/._image_3.png  \n",
            "  inflating: hidden/video_16074/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16074/._image_1.png  \n",
            "  inflating: hidden/video_16074/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16074/._image_0.png  \n",
            "  inflating: hidden/video_16074/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16074/._image_4.png  \n",
            "  inflating: hidden/video_16074/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16074/._image_5.png  \n",
            "  inflating: hidden/video_16074/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16074/._image_7.png  \n",
            "  inflating: hidden/video_16074/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16074/._image_6.png  \n",
            "  inflating: hidden/video_16848/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16848/._image_10.png  \n",
            "  inflating: hidden/video_16848/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16848/._image_8.png  \n",
            "  inflating: hidden/video_16848/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16848/._image_9.png  \n",
            "  inflating: hidden/video_16848/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16848/._image_2.png  \n",
            "  inflating: hidden/video_16848/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16848/._image_3.png  \n",
            "  inflating: hidden/video_16848/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16848/._image_1.png  \n",
            "  inflating: hidden/video_16848/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16848/._image_0.png  \n",
            "  inflating: hidden/video_16848/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16848/._image_4.png  \n",
            "  inflating: hidden/video_16848/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16848/._image_5.png  \n",
            "  inflating: hidden/video_16848/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16848/._image_7.png  \n",
            "  inflating: hidden/video_16848/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16848/._image_6.png  \n",
            "  inflating: hidden/video_16246/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16246/._image_10.png  \n",
            "  inflating: hidden/video_16246/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16246/._image_8.png  \n",
            "  inflating: hidden/video_16246/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16246/._image_9.png  \n",
            "  inflating: hidden/video_16246/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16246/._image_2.png  \n",
            "  inflating: hidden/video_16246/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16246/._image_3.png  \n",
            "  inflating: hidden/video_16246/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16246/._image_1.png  \n",
            "  inflating: hidden/video_16246/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16246/._image_0.png  \n",
            "  inflating: hidden/video_16246/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16246/._image_4.png  \n",
            "  inflating: hidden/video_16246/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16246/._image_5.png  \n",
            "  inflating: hidden/video_16246/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16246/._image_7.png  \n",
            "  inflating: hidden/video_16246/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16246/._image_6.png  \n",
            "  inflating: hidden/video_15605/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15605/._image_10.png  \n",
            "  inflating: hidden/video_15605/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15605/._image_8.png  \n",
            "  inflating: hidden/video_15605/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15605/._image_9.png  \n",
            "  inflating: hidden/video_15605/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15605/._image_2.png  \n",
            "  inflating: hidden/video_15605/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15605/._image_3.png  \n",
            "  inflating: hidden/video_15605/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15605/._image_1.png  \n",
            "  inflating: hidden/video_15605/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15605/._image_0.png  \n",
            "  inflating: hidden/video_15605/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15605/._image_4.png  \n",
            "  inflating: hidden/video_15605/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15605/._image_5.png  \n",
            "  inflating: hidden/video_15605/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15605/._image_7.png  \n",
            "  inflating: hidden/video_15605/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15605/._image_6.png  \n",
            "  inflating: hidden/video_16080/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16080/._image_10.png  \n",
            "  inflating: hidden/video_16080/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16080/._image_8.png  \n",
            "  inflating: hidden/video_16080/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16080/._image_9.png  \n",
            "  inflating: hidden/video_16080/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16080/._image_2.png  \n",
            "  inflating: hidden/video_16080/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16080/._image_3.png  \n",
            "  inflating: hidden/video_16080/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16080/._image_1.png  \n",
            "  inflating: hidden/video_16080/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16080/._image_0.png  \n",
            "  inflating: hidden/video_16080/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16080/._image_4.png  \n",
            "  inflating: hidden/video_16080/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16080/._image_5.png  \n",
            "  inflating: hidden/video_16080/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16080/._image_7.png  \n",
            "  inflating: hidden/video_16080/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16080/._image_6.png  \n",
            "  inflating: hidden/video_15437/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15437/._image_10.png  \n",
            "  inflating: hidden/video_15437/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15437/._image_8.png  \n",
            "  inflating: hidden/video_15437/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15437/._image_9.png  \n",
            "  inflating: hidden/video_15437/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15437/._image_2.png  \n",
            "  inflating: hidden/video_15437/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15437/._image_3.png  \n",
            "  inflating: hidden/video_15437/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15437/._image_1.png  \n",
            "  inflating: hidden/video_15437/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15437/._image_0.png  \n",
            "  inflating: hidden/video_15437/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15437/._image_4.png  \n",
            "  inflating: hidden/video_15437/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15437/._image_5.png  \n",
            "  inflating: hidden/video_15437/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15437/._image_7.png  \n",
            "  inflating: hidden/video_15437/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15437/._image_6.png  \n",
            "  inflating: hidden/video_15053/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15053/._image_10.png  \n",
            "  inflating: hidden/video_15053/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15053/._image_8.png  \n",
            "  inflating: hidden/video_15053/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15053/._image_9.png  \n",
            "  inflating: hidden/video_15053/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15053/._image_2.png  \n",
            "  inflating: hidden/video_15053/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15053/._image_3.png  \n",
            "  inflating: hidden/video_15053/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15053/._image_1.png  \n",
            "  inflating: hidden/video_15053/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15053/._image_0.png  \n",
            "  inflating: hidden/video_15053/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15053/._image_4.png  \n",
            "  inflating: hidden/video_15053/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15053/._image_5.png  \n",
            "  inflating: hidden/video_15053/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15053/._image_7.png  \n",
            "  inflating: hidden/video_15053/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15053/._image_6.png  \n",
            "  inflating: hidden/video_15261/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15261/._image_10.png  \n",
            "  inflating: hidden/video_15261/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15261/._image_8.png  \n",
            "  inflating: hidden/video_15261/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15261/._image_9.png  \n",
            "  inflating: hidden/video_15261/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15261/._image_2.png  \n",
            "  inflating: hidden/video_15261/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15261/._image_3.png  \n",
            "  inflating: hidden/video_15261/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15261/._image_1.png  \n",
            "  inflating: hidden/video_15261/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15261/._image_0.png  \n",
            "  inflating: hidden/video_15261/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15261/._image_4.png  \n",
            "  inflating: hidden/video_15261/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15261/._image_5.png  \n",
            "  inflating: hidden/video_15261/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15261/._image_7.png  \n",
            "  inflating: hidden/video_15261/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15261/._image_6.png  \n",
            "  inflating: hidden/video_16279/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16279/._image_10.png  \n",
            "  inflating: hidden/video_16279/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16279/._image_8.png  \n",
            "  inflating: hidden/video_16279/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16279/._image_9.png  \n",
            "  inflating: hidden/video_16279/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16279/._image_2.png  \n",
            "  inflating: hidden/video_16279/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16279/._image_3.png  \n",
            "  inflating: hidden/video_16279/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16279/._image_1.png  \n",
            "  inflating: hidden/video_16279/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16279/._image_0.png  \n",
            "  inflating: hidden/video_16279/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16279/._image_4.png  \n",
            "  inflating: hidden/video_16279/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16279/._image_5.png  \n",
            "  inflating: hidden/video_16279/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16279/._image_7.png  \n",
            "  inflating: hidden/video_16279/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16279/._image_6.png  \n",
            "  inflating: hidden/video_16877/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16877/._image_10.png  \n",
            "  inflating: hidden/video_16877/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16877/._image_8.png  \n",
            "  inflating: hidden/video_16877/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16877/._image_9.png  \n",
            "  inflating: hidden/video_16877/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16877/._image_2.png  \n",
            "  inflating: hidden/video_16877/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16877/._image_3.png  \n",
            "  inflating: hidden/video_16877/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16877/._image_1.png  \n",
            "  inflating: hidden/video_16877/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16877/._image_0.png  \n",
            "  inflating: hidden/video_16877/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16877/._image_4.png  \n",
            "  inflating: hidden/video_16877/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16877/._image_5.png  \n",
            "  inflating: hidden/video_16877/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16877/._image_7.png  \n",
            "  inflating: hidden/video_16877/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16877/._image_6.png  \n",
            "  inflating: hidden/video_15098/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15098/._image_10.png  \n",
            "  inflating: hidden/video_15098/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15098/._image_8.png  \n",
            "  inflating: hidden/video_15098/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15098/._image_9.png  \n",
            "  inflating: hidden/video_15098/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15098/._image_2.png  \n",
            "  inflating: hidden/video_15098/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15098/._image_3.png  \n",
            "  inflating: hidden/video_15098/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15098/._image_1.png  \n",
            "  inflating: hidden/video_15098/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15098/._image_0.png  \n",
            "  inflating: hidden/video_15098/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15098/._image_4.png  \n",
            "  inflating: hidden/video_15098/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15098/._image_5.png  \n",
            "  inflating: hidden/video_15098/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15098/._image_7.png  \n",
            "  inflating: hidden/video_15098/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15098/._image_6.png  \n",
            "  inflating: hidden/video_15850/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15850/._image_10.png  \n",
            "  inflating: hidden/video_15850/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15850/._image_8.png  \n",
            "  inflating: hidden/video_15850/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15850/._image_9.png  \n",
            "  inflating: hidden/video_15850/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15850/._image_2.png  \n",
            "  inflating: hidden/video_15850/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15850/._image_3.png  \n",
            "  inflating: hidden/video_15850/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15850/._image_1.png  \n",
            "  inflating: hidden/video_15850/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15850/._image_0.png  \n",
            "  inflating: hidden/video_15850/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15850/._image_4.png  \n",
            "  inflating: hidden/video_15850/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15850/._image_5.png  \n",
            "  inflating: hidden/video_15850/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15850/._image_7.png  \n",
            "  inflating: hidden/video_15850/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15850/._image_6.png  \n",
            "  inflating: hidden/video_15408/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15408/._image_10.png  \n",
            "  inflating: hidden/video_15408/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15408/._image_8.png  \n",
            "  inflating: hidden/video_15408/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15408/._image_9.png  \n",
            "  inflating: hidden/video_15408/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15408/._image_2.png  \n",
            "  inflating: hidden/video_15408/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15408/._image_3.png  \n",
            "  inflating: hidden/video_15408/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15408/._image_1.png  \n",
            "  inflating: hidden/video_15408/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15408/._image_0.png  \n",
            "  inflating: hidden/video_15408/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15408/._image_4.png  \n",
            "  inflating: hidden/video_15408/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15408/._image_5.png  \n",
            "  inflating: hidden/video_15408/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15408/._image_7.png  \n",
            "  inflating: hidden/video_15408/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15408/._image_6.png  \n",
            "  inflating: hidden/video_16883/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16883/._image_10.png  \n",
            "  inflating: hidden/video_16883/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16883/._image_8.png  \n",
            "  inflating: hidden/video_16883/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16883/._image_9.png  \n",
            "  inflating: hidden/video_16883/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16883/._image_2.png  \n",
            "  inflating: hidden/video_16883/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16883/._image_3.png  \n",
            "  inflating: hidden/video_16883/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16883/._image_1.png  \n",
            "  inflating: hidden/video_16883/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16883/._image_0.png  \n",
            "  inflating: hidden/video_16883/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16883/._image_4.png  \n",
            "  inflating: hidden/video_16883/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16883/._image_5.png  \n",
            "  inflating: hidden/video_16883/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16883/._image_7.png  \n",
            "  inflating: hidden/video_16883/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16883/._image_6.png  \n",
            "  inflating: hidden/video_15266/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15266/._image_10.png  \n",
            "  inflating: hidden/video_15266/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15266/._image_8.png  \n",
            "  inflating: hidden/video_15266/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15266/._image_9.png  \n",
            "  inflating: hidden/video_15266/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15266/._image_2.png  \n",
            "  inflating: hidden/video_15266/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15266/._image_3.png  \n",
            "  inflating: hidden/video_15266/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15266/._image_1.png  \n",
            "  inflating: hidden/video_15266/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15266/._image_0.png  \n",
            "  inflating: hidden/video_15266/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15266/._image_4.png  \n",
            "  inflating: hidden/video_15266/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15266/._image_5.png  \n",
            "  inflating: hidden/video_15266/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15266/._image_7.png  \n",
            "  inflating: hidden/video_15266/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15266/._image_6.png  \n",
            "  inflating: hidden/video_15868/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15868/._image_10.png  \n",
            "  inflating: hidden/video_15868/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15868/._image_8.png  \n",
            "  inflating: hidden/video_15868/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15868/._image_9.png  \n",
            "  inflating: hidden/video_15868/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15868/._image_2.png  \n",
            "  inflating: hidden/video_15868/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15868/._image_3.png  \n",
            "  inflating: hidden/video_15868/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15868/._image_1.png  \n",
            "  inflating: hidden/video_15868/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15868/._image_0.png  \n",
            "  inflating: hidden/video_15868/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15868/._image_4.png  \n",
            "  inflating: hidden/video_15868/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15868/._image_5.png  \n",
            "  inflating: hidden/video_15868/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15868/._image_7.png  \n",
            "  inflating: hidden/video_15868/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15868/._image_6.png  \n",
            "  inflating: hidden/video_15054/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15054/._image_10.png  \n",
            "  inflating: hidden/video_15054/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15054/._image_8.png  \n",
            "  inflating: hidden/video_15054/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15054/._image_9.png  \n",
            "  inflating: hidden/video_15054/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15054/._image_2.png  \n",
            "  inflating: hidden/video_15054/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15054/._image_3.png  \n",
            "  inflating: hidden/video_15054/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15054/._image_1.png  \n",
            "  inflating: hidden/video_15054/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15054/._image_0.png  \n",
            "  inflating: hidden/video_15054/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15054/._image_4.png  \n",
            "  inflating: hidden/video_15054/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15054/._image_5.png  \n",
            "  inflating: hidden/video_15054/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15054/._image_7.png  \n",
            "  inflating: hidden/video_15054/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15054/._image_6.png  \n",
            "  inflating: hidden/video_15430/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15430/._image_10.png  \n",
            "  inflating: hidden/video_15430/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15430/._image_8.png  \n",
            "  inflating: hidden/video_15430/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15430/._image_9.png  \n",
            "  inflating: hidden/video_15430/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15430/._image_2.png  \n",
            "  inflating: hidden/video_15430/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15430/._image_3.png  \n",
            "  inflating: hidden/video_15430/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15430/._image_1.png  \n",
            "  inflating: hidden/video_15430/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15430/._image_0.png  \n",
            "  inflating: hidden/video_15430/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15430/._image_4.png  \n",
            "  inflating: hidden/video_15430/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15430/._image_5.png  \n",
            "  inflating: hidden/video_15430/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15430/._image_7.png  \n",
            "  inflating: hidden/video_15430/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15430/._image_6.png  \n",
            "  inflating: hidden/video_15602/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15602/._image_10.png  \n",
            "  inflating: hidden/video_15602/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15602/._image_8.png  \n",
            "  inflating: hidden/video_15602/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15602/._image_9.png  \n",
            "  inflating: hidden/video_15602/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15602/._image_2.png  \n",
            "  inflating: hidden/video_15602/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15602/._image_3.png  \n",
            "  inflating: hidden/video_15602/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15602/._image_1.png  \n",
            "  inflating: hidden/video_15602/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15602/._image_0.png  \n",
            "  inflating: hidden/video_15602/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15602/._image_4.png  \n",
            "  inflating: hidden/video_15602/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15602/._image_5.png  \n",
            "  inflating: hidden/video_15602/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15602/._image_7.png  \n",
            "  inflating: hidden/video_15602/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15602/._image_6.png  \n",
            "  inflating: hidden/video_16087/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16087/._image_10.png  \n",
            "  inflating: hidden/video_16087/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16087/._image_8.png  \n",
            "  inflating: hidden/video_16087/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16087/._image_9.png  \n",
            "  inflating: hidden/video_16087/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16087/._image_2.png  \n",
            "  inflating: hidden/video_16087/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16087/._image_3.png  \n",
            "  inflating: hidden/video_16087/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16087/._image_1.png  \n",
            "  inflating: hidden/video_16087/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16087/._image_0.png  \n",
            "  inflating: hidden/video_16087/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16087/._image_4.png  \n",
            "  inflating: hidden/video_16087/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16087/._image_5.png  \n",
            "  inflating: hidden/video_16087/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16087/._image_7.png  \n",
            "  inflating: hidden/video_16087/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16087/._image_6.png  \n",
            "  inflating: hidden/video_16241/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16241/._image_10.png  \n",
            "  inflating: hidden/video_16241/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16241/._image_8.png  \n",
            "  inflating: hidden/video_16241/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16241/._image_9.png  \n",
            "  inflating: hidden/video_16241/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16241/._image_2.png  \n",
            "  inflating: hidden/video_16241/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16241/._image_3.png  \n",
            "  inflating: hidden/video_16241/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16241/._image_1.png  \n",
            "  inflating: hidden/video_16241/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16241/._image_0.png  \n",
            "  inflating: hidden/video_16241/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16241/._image_4.png  \n",
            "  inflating: hidden/video_16241/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16241/._image_5.png  \n",
            "  inflating: hidden/video_16241/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16241/._image_7.png  \n",
            "  inflating: hidden/video_16241/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16241/._image_6.png  \n",
            "  inflating: hidden/video_16073/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16073/._image_10.png  \n",
            "  inflating: hidden/video_16073/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16073/._image_8.png  \n",
            "  inflating: hidden/video_16073/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16073/._image_9.png  \n",
            "  inflating: hidden/video_16073/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16073/._image_2.png  \n",
            "  inflating: hidden/video_16073/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16073/._image_3.png  \n",
            "  inflating: hidden/video_16073/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16073/._image_1.png  \n",
            "  inflating: hidden/video_16073/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16073/._image_0.png  \n",
            "  inflating: hidden/video_16073/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16073/._image_4.png  \n",
            "  inflating: hidden/video_16073/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16073/._image_5.png  \n",
            "  inflating: hidden/video_16073/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16073/._image_7.png  \n",
            "  inflating: hidden/video_16073/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16073/._image_6.png  \n",
            "  inflating: hidden/video_15292/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15292/._image_10.png  \n",
            "  inflating: hidden/video_15292/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15292/._image_8.png  \n",
            "  inflating: hidden/video_15292/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15292/._image_9.png  \n",
            "  inflating: hidden/video_15292/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15292/._image_2.png  \n",
            "  inflating: hidden/video_15292/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15292/._image_3.png  \n",
            "  inflating: hidden/video_15292/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15292/._image_1.png  \n",
            "  inflating: hidden/video_15292/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15292/._image_0.png  \n",
            "  inflating: hidden/video_15292/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15292/._image_4.png  \n",
            "  inflating: hidden/video_15292/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15292/._image_5.png  \n",
            "  inflating: hidden/video_15292/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15292/._image_7.png  \n",
            "  inflating: hidden/video_15292/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15292/._image_6.png  \n",
            "  inflating: hidden/video_16417/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16417/._image_10.png  \n",
            "  inflating: hidden/video_16417/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16417/._image_8.png  \n",
            "  inflating: hidden/video_16417/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16417/._image_9.png  \n",
            "  inflating: hidden/video_16417/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16417/._image_2.png  \n",
            "  inflating: hidden/video_16417/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16417/._image_3.png  \n",
            "  inflating: hidden/video_16417/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16417/._image_1.png  \n",
            "  inflating: hidden/video_16417/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16417/._image_0.png  \n",
            "  inflating: hidden/video_16417/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16417/._image_4.png  \n",
            "  inflating: hidden/video_16417/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16417/._image_5.png  \n",
            "  inflating: hidden/video_16417/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16417/._image_7.png  \n",
            "  inflating: hidden/video_16417/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16417/._image_6.png  \n",
            "  inflating: hidden/video_16625/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16625/._image_10.png  \n",
            "  inflating: hidden/video_16625/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16625/._image_8.png  \n",
            "  inflating: hidden/video_16625/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16625/._image_9.png  \n",
            "  inflating: hidden/video_16625/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16625/._image_2.png  \n",
            "  inflating: hidden/video_16625/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16625/._image_3.png  \n",
            "  inflating: hidden/video_16625/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16625/._image_1.png  \n",
            "  inflating: hidden/video_16625/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16625/._image_0.png  \n",
            "  inflating: hidden/video_16625/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16625/._image_4.png  \n",
            "  inflating: hidden/video_16625/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16625/._image_5.png  \n",
            "  inflating: hidden/video_16625/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16625/._image_7.png  \n",
            "  inflating: hidden/video_16625/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16625/._image_6.png  \n",
            "  inflating: hidden/video_16884/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16884/._image_10.png  \n",
            "  inflating: hidden/video_16884/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16884/._image_8.png  \n",
            "  inflating: hidden/video_16884/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16884/._image_9.png  \n",
            "  inflating: hidden/video_16884/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16884/._image_2.png  \n",
            "  inflating: hidden/video_16884/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16884/._image_3.png  \n",
            "  inflating: hidden/video_16884/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16884/._image_1.png  \n",
            "  inflating: hidden/video_16884/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16884/._image_0.png  \n",
            "  inflating: hidden/video_16884/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16884/._image_4.png  \n",
            "  inflating: hidden/video_16884/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16884/._image_5.png  \n",
            "  inflating: hidden/video_16884/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16884/._image_7.png  \n",
            "  inflating: hidden/video_16884/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16884/._image_6.png  \n",
            "  inflating: hidden/video_15857/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15857/._image_10.png  \n",
            "  inflating: hidden/video_15857/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15857/._image_8.png  \n",
            "  inflating: hidden/video_15857/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15857/._image_9.png  \n",
            "  inflating: hidden/video_15857/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15857/._image_2.png  \n",
            "  inflating: hidden/video_15857/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15857/._image_3.png  \n",
            "  inflating: hidden/video_15857/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15857/._image_1.png  \n",
            "  inflating: hidden/video_15857/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15857/._image_0.png  \n",
            "  inflating: hidden/video_15857/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15857/._image_4.png  \n",
            "  inflating: hidden/video_15857/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15857/._image_5.png  \n",
            "  inflating: hidden/video_15857/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15857/._image_7.png  \n",
            "  inflating: hidden/video_15857/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15857/._image_6.png  \n",
            "  inflating: hidden/video_15259/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15259/._image_10.png  \n",
            "  inflating: hidden/video_15259/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15259/._image_8.png  \n",
            "  inflating: hidden/video_15259/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15259/._image_9.png  \n",
            "  inflating: hidden/video_15259/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15259/._image_2.png  \n",
            "  inflating: hidden/video_15259/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15259/._image_3.png  \n",
            "  inflating: hidden/video_15259/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15259/._image_1.png  \n",
            "  inflating: hidden/video_15259/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15259/._image_0.png  \n",
            "  inflating: hidden/video_15259/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15259/._image_4.png  \n",
            "  inflating: hidden/video_15259/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15259/._image_5.png  \n",
            "  inflating: hidden/video_15259/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15259/._image_7.png  \n",
            "  inflating: hidden/video_15259/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15259/._image_6.png  \n",
            "  inflating: hidden/video_16428/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16428/._image_10.png  \n",
            "  inflating: hidden/video_16428/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16428/._image_8.png  \n",
            "  inflating: hidden/video_16428/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16428/._image_9.png  \n",
            "  inflating: hidden/video_16428/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16428/._image_2.png  \n",
            "  inflating: hidden/video_16428/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16428/._image_3.png  \n",
            "  inflating: hidden/video_16428/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16428/._image_1.png  \n",
            "  inflating: hidden/video_16428/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16428/._image_0.png  \n",
            "  inflating: hidden/video_16428/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16428/._image_4.png  \n",
            "  inflating: hidden/video_16428/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16428/._image_5.png  \n",
            "  inflating: hidden/video_16428/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16428/._image_7.png  \n",
            "  inflating: hidden/video_16428/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16428/._image_6.png  \n",
            "  inflating: hidden/video_16870/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16870/._image_10.png  \n",
            "  inflating: hidden/video_16870/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16870/._image_8.png  \n",
            "  inflating: hidden/video_16870/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16870/._image_9.png  \n",
            "  inflating: hidden/video_16870/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16870/._image_2.png  \n",
            "  inflating: hidden/video_16870/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16870/._image_3.png  \n",
            "  inflating: hidden/video_16870/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16870/._image_1.png  \n",
            "  inflating: hidden/video_16870/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16870/._image_0.png  \n",
            "  inflating: hidden/video_16870/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16870/._image_4.png  \n",
            "  inflating: hidden/video_16870/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16870/._image_5.png  \n",
            "  inflating: hidden/video_16870/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16870/._image_7.png  \n",
            "  inflating: hidden/video_16870/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16870/._image_6.png  \n",
            "  inflating: hidden/video_15669/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15669/._image_10.png  \n",
            "  inflating: hidden/video_15669/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15669/._image_8.png  \n",
            "  inflating: hidden/video_15669/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15669/._image_9.png  \n",
            "  inflating: hidden/video_15669/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15669/._image_2.png  \n",
            "  inflating: hidden/video_15669/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15669/._image_3.png  \n",
            "  inflating: hidden/video_15669/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15669/._image_1.png  \n",
            "  inflating: hidden/video_15669/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15669/._image_0.png  \n",
            "  inflating: hidden/video_15669/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15669/._image_4.png  \n",
            "  inflating: hidden/video_15669/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15669/._image_5.png  \n",
            "  inflating: hidden/video_15669/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15669/._image_7.png  \n",
            "  inflating: hidden/video_15669/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15669/._image_6.png  \n",
            "  inflating: hidden/video_16488/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16488/._image_10.png  \n",
            "  inflating: hidden/video_16488/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16488/._image_8.png  \n",
            "  inflating: hidden/video_16488/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16488/._image_9.png  \n",
            "  inflating: hidden/video_16488/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16488/._image_2.png  \n",
            "  inflating: hidden/video_16488/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16488/._image_3.png  \n",
            "  inflating: hidden/video_16488/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16488/._image_1.png  \n",
            "  inflating: hidden/video_16488/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16488/._image_0.png  \n",
            "  inflating: hidden/video_16488/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16488/._image_4.png  \n",
            "  inflating: hidden/video_16488/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16488/._image_5.png  \n",
            "  inflating: hidden/video_16488/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16488/._image_7.png  \n",
            "  inflating: hidden/video_16488/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16488/._image_6.png  \n",
            "  inflating: hidden/video_15803/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15803/._image_10.png  \n",
            "  inflating: hidden/video_15803/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15803/._image_8.png  \n",
            "  inflating: hidden/video_15803/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15803/._image_9.png  \n",
            "  inflating: hidden/video_15803/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15803/._image_2.png  \n",
            "  inflating: hidden/video_15803/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15803/._image_3.png  \n",
            "  inflating: hidden/video_15803/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15803/._image_1.png  \n",
            "  inflating: hidden/video_15803/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15803/._image_0.png  \n",
            "  inflating: hidden/video_15803/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15803/._image_4.png  \n",
            "  inflating: hidden/video_15803/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15803/._image_5.png  \n",
            "  inflating: hidden/video_15803/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15803/._image_7.png  \n",
            "  inflating: hidden/video_15803/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15803/._image_6.png  \n",
            "  inflating: hidden/video_16824/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16824/._image_10.png  \n",
            "  inflating: hidden/video_16824/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16824/._image_8.png  \n",
            "  inflating: hidden/video_16824/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16824/._image_9.png  \n",
            "  inflating: hidden/video_16824/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16824/._image_2.png  \n",
            "  inflating: hidden/video_16824/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16824/._image_3.png  \n",
            "  inflating: hidden/video_16824/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16824/._image_1.png  \n",
            "  inflating: hidden/video_16824/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16824/._image_0.png  \n",
            "  inflating: hidden/video_16824/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16824/._image_4.png  \n",
            "  inflating: hidden/video_16824/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16824/._image_5.png  \n",
            "  inflating: hidden/video_16824/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16824/._image_7.png  \n",
            "  inflating: hidden/video_16824/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16824/._image_6.png  \n",
            "  inflating: hidden/video_16018/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16018/._image_10.png  \n",
            "  inflating: hidden/video_16018/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16018/._image_8.png  \n",
            "  inflating: hidden/video_16018/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16018/._image_9.png  \n",
            "  inflating: hidden/video_16018/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16018/._image_2.png  \n",
            "  inflating: hidden/video_16018/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16018/._image_3.png  \n",
            "  inflating: hidden/video_16018/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16018/._image_1.png  \n",
            "  inflating: hidden/video_16018/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16018/._image_0.png  \n",
            "  inflating: hidden/video_16018/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16018/._image_4.png  \n",
            "  inflating: hidden/video_16018/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16018/._image_5.png  \n",
            "  inflating: hidden/video_16018/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16018/._image_7.png  \n",
            "  inflating: hidden/video_16018/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16018/._image_6.png  \n",
            "  inflating: hidden/video_15000/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15000/._image_10.png  \n",
            "  inflating: hidden/video_15000/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15000/._image_8.png  \n",
            "  inflating: hidden/video_15000/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15000/._image_9.png  \n",
            "  inflating: hidden/video_15000/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15000/._image_2.png  \n",
            "  inflating: hidden/video_15000/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15000/._image_3.png  \n",
            "  inflating: hidden/video_15000/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15000/._image_1.png  \n",
            "  inflating: hidden/video_15000/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15000/._image_0.png  \n",
            "  inflating: hidden/video_15000/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15000/._image_4.png  \n",
            "  inflating: hidden/video_15000/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15000/._image_5.png  \n",
            "  inflating: hidden/video_15000/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15000/._image_7.png  \n",
            "  inflating: hidden/video_15000/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15000/._image_6.png  \n",
            "  inflating: hidden/video_16685/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16685/._image_10.png  \n",
            "  inflating: hidden/video_16685/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16685/._image_8.png  \n",
            "  inflating: hidden/video_16685/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16685/._image_9.png  \n",
            "  inflating: hidden/video_16685/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16685/._image_2.png  \n",
            "  inflating: hidden/video_16685/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16685/._image_3.png  \n",
            "  inflating: hidden/video_16685/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16685/._image_1.png  \n",
            "  inflating: hidden/video_16685/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16685/._image_0.png  \n",
            "  inflating: hidden/video_16685/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16685/._image_4.png  \n",
            "  inflating: hidden/video_16685/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16685/._image_5.png  \n",
            "  inflating: hidden/video_16685/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16685/._image_7.png  \n",
            "  inflating: hidden/video_16685/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16685/._image_6.png  \n",
            "  inflating: hidden/video_15232/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15232/._image_10.png  \n",
            "  inflating: hidden/video_15232/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15232/._image_8.png  \n",
            "  inflating: hidden/video_15232/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15232/._image_9.png  \n",
            "  inflating: hidden/video_15232/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15232/._image_2.png  \n",
            "  inflating: hidden/video_15232/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15232/._image_3.png  \n",
            "  inflating: hidden/video_15232/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15232/._image_1.png  \n",
            "  inflating: hidden/video_15232/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15232/._image_0.png  \n",
            "  inflating: hidden/video_15232/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15232/._image_4.png  \n",
            "  inflating: hidden/video_15232/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15232/._image_5.png  \n",
            "  inflating: hidden/video_15232/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15232/._image_7.png  \n",
            "  inflating: hidden/video_15232/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15232/._image_6.png  \n",
            "  inflating: hidden/video_15656/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15656/._image_10.png  \n",
            "  inflating: hidden/video_15656/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15656/._image_8.png  \n",
            "  inflating: hidden/video_15656/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15656/._image_9.png  \n",
            "  inflating: hidden/video_15656/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15656/._image_2.png  \n",
            "  inflating: hidden/video_15656/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15656/._image_3.png  \n",
            "  inflating: hidden/video_15656/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15656/._image_1.png  \n",
            "  inflating: hidden/video_15656/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15656/._image_0.png  \n",
            "  inflating: hidden/video_15656/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15656/._image_4.png  \n",
            "  inflating: hidden/video_15656/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15656/._image_5.png  \n",
            "  inflating: hidden/video_15656/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15656/._image_7.png  \n",
            "  inflating: hidden/video_15656/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15656/._image_6.png  \n",
            "  inflating: hidden/video_15464/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15464/._image_10.png  \n",
            "  inflating: hidden/video_15464/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15464/._image_8.png  \n",
            "  inflating: hidden/video_15464/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15464/._image_9.png  \n",
            "  inflating: hidden/video_15464/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15464/._image_2.png  \n",
            "  inflating: hidden/video_15464/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15464/._image_3.png  \n",
            "  inflating: hidden/video_15464/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15464/._image_1.png  \n",
            "  inflating: hidden/video_15464/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15464/._image_0.png  \n",
            "  inflating: hidden/video_15464/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15464/._image_4.png  \n",
            "  inflating: hidden/video_15464/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15464/._image_5.png  \n",
            "  inflating: hidden/video_15464/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15464/._image_7.png  \n",
            "  inflating: hidden/video_15464/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15464/._image_6.png  \n",
            "  inflating: hidden/video_16027/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16027/._image_10.png  \n",
            "  inflating: hidden/video_16027/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16027/._image_8.png  \n",
            "  inflating: hidden/video_16027/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16027/._image_9.png  \n",
            "  inflating: hidden/video_16027/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16027/._image_2.png  \n",
            "  inflating: hidden/video_16027/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16027/._image_3.png  \n",
            "  inflating: hidden/video_16027/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16027/._image_1.png  \n",
            "  inflating: hidden/video_16027/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16027/._image_0.png  \n",
            "  inflating: hidden/video_16027/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16027/._image_4.png  \n",
            "  inflating: hidden/video_16027/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16027/._image_5.png  \n",
            "  inflating: hidden/video_16027/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16027/._image_7.png  \n",
            "  inflating: hidden/video_16027/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16027/._image_6.png  \n",
            "  inflating: hidden/video_15490/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15490/._image_10.png  \n",
            "  inflating: hidden/video_15490/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15490/._image_8.png  \n",
            "  inflating: hidden/video_15490/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15490/._image_9.png  \n",
            "  inflating: hidden/video_15490/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15490/._image_2.png  \n",
            "  inflating: hidden/video_15490/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15490/._image_3.png  \n",
            "  inflating: hidden/video_15490/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15490/._image_1.png  \n",
            "  inflating: hidden/video_15490/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15490/._image_0.png  \n",
            "  inflating: hidden/video_15490/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15490/._image_4.png  \n",
            "  inflating: hidden/video_15490/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15490/._image_5.png  \n",
            "  inflating: hidden/video_15490/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15490/._image_7.png  \n",
            "  inflating: hidden/video_15490/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15490/._image_6.png  \n",
            "  inflating: hidden/video_16215/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16215/._image_10.png  \n",
            "  inflating: hidden/video_16215/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16215/._image_8.png  \n",
            "  inflating: hidden/video_16215/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16215/._image_9.png  \n",
            "  inflating: hidden/video_16215/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16215/._image_2.png  \n",
            "  inflating: hidden/video_16215/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16215/._image_3.png  \n",
            "  inflating: hidden/video_16215/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16215/._image_1.png  \n",
            "  inflating: hidden/video_16215/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16215/._image_0.png  \n",
            "  inflating: hidden/video_16215/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16215/._image_4.png  \n",
            "  inflating: hidden/video_16215/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16215/._image_5.png  \n",
            "  inflating: hidden/video_16215/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16215/._image_7.png  \n",
            "  inflating: hidden/video_16215/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16215/._image_6.png  \n",
            "  inflating: hidden/video_16671/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16671/._image_10.png  \n",
            "  inflating: hidden/video_16671/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16671/._image_8.png  \n",
            "  inflating: hidden/video_16671/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16671/._image_9.png  \n",
            "  inflating: hidden/video_16671/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16671/._image_2.png  \n",
            "  inflating: hidden/video_16671/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16671/._image_3.png  \n",
            "  inflating: hidden/video_16671/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16671/._image_1.png  \n",
            "  inflating: hidden/video_16671/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16671/._image_0.png  \n",
            "  inflating: hidden/video_16671/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16671/._image_4.png  \n",
            "  inflating: hidden/video_16671/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16671/._image_5.png  \n",
            "  inflating: hidden/video_16671/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16671/._image_7.png  \n",
            "  inflating: hidden/video_16671/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16671/._image_6.png  \n",
            "  inflating: hidden/video_16443/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16443/._image_10.png  \n",
            "  inflating: hidden/video_16443/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16443/._image_8.png  \n",
            "  inflating: hidden/video_16443/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16443/._image_9.png  \n",
            "  inflating: hidden/video_16443/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16443/._image_2.png  \n",
            "  inflating: hidden/video_16443/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16443/._image_3.png  \n",
            "  inflating: hidden/video_16443/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16443/._image_1.png  \n",
            "  inflating: hidden/video_16443/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16443/._image_0.png  \n",
            "  inflating: hidden/video_16443/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16443/._image_4.png  \n",
            "  inflating: hidden/video_16443/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16443/._image_5.png  \n",
            "  inflating: hidden/video_16443/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16443/._image_7.png  \n",
            "  inflating: hidden/video_16443/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16443/._image_6.png  \n",
            "  inflating: hidden/video_16823/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16823/._image_10.png  \n",
            "  inflating: hidden/video_16823/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16823/._image_8.png  \n",
            "  inflating: hidden/video_16823/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16823/._image_9.png  \n",
            "  inflating: hidden/video_16823/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16823/._image_2.png  \n",
            "  inflating: hidden/video_16823/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16823/._image_3.png  \n",
            "  inflating: hidden/video_16823/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16823/._image_1.png  \n",
            "  inflating: hidden/video_16823/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16823/._image_0.png  \n",
            "  inflating: hidden/video_16823/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16823/._image_4.png  \n",
            "  inflating: hidden/video_16823/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16823/._image_5.png  \n",
            "  inflating: hidden/video_16823/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16823/._image_7.png  \n",
            "  inflating: hidden/video_16823/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16823/._image_6.png  \n",
            "  inflating: hidden/video_16649/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16649/._image_10.png  \n",
            "  inflating: hidden/video_16649/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16649/._image_8.png  \n",
            "  inflating: hidden/video_16649/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16649/._image_9.png  \n",
            "  inflating: hidden/video_16649/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16649/._image_2.png  \n",
            "  inflating: hidden/video_16649/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16649/._image_3.png  \n",
            "  inflating: hidden/video_16649/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16649/._image_1.png  \n",
            "  inflating: hidden/video_16649/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16649/._image_0.png  \n",
            "  inflating: hidden/video_16649/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16649/._image_4.png  \n",
            "  inflating: hidden/video_16649/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16649/._image_5.png  \n",
            "  inflating: hidden/video_16649/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16649/._image_7.png  \n",
            "  inflating: hidden/video_16649/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16649/._image_6.png  \n",
            "  inflating: hidden/video_15038/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15038/._image_10.png  \n",
            "  inflating: hidden/video_15038/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15038/._image_8.png  \n",
            "  inflating: hidden/video_15038/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15038/._image_9.png  \n",
            "  inflating: hidden/video_15038/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15038/._image_2.png  \n",
            "  inflating: hidden/video_15038/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15038/._image_3.png  \n",
            "  inflating: hidden/video_15038/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15038/._image_1.png  \n",
            "  inflating: hidden/video_15038/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15038/._image_0.png  \n",
            "  inflating: hidden/video_15038/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15038/._image_4.png  \n",
            "  inflating: hidden/video_15038/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15038/._image_5.png  \n",
            "  inflating: hidden/video_15038/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15038/._image_7.png  \n",
            "  inflating: hidden/video_15038/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15038/._image_6.png  \n",
            "  inflating: hidden/video_15804/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15804/._image_10.png  \n",
            "  inflating: hidden/video_15804/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15804/._image_8.png  \n",
            "  inflating: hidden/video_15804/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15804/._image_9.png  \n",
            "  inflating: hidden/video_15804/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15804/._image_2.png  \n",
            "  inflating: hidden/video_15804/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15804/._image_3.png  \n",
            "  inflating: hidden/video_15804/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15804/._image_1.png  \n",
            "  inflating: hidden/video_15804/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15804/._image_0.png  \n",
            "  inflating: hidden/video_15804/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15804/._image_4.png  \n",
            "  inflating: hidden/video_15804/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15804/._image_5.png  \n",
            "  inflating: hidden/video_15804/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15804/._image_7.png  \n",
            "  inflating: hidden/video_15804/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15804/._image_6.png  \n",
            "  inflating: hidden/video_16444/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16444/._image_10.png  \n",
            "  inflating: hidden/video_16444/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16444/._image_8.png  \n",
            "  inflating: hidden/video_16444/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16444/._image_9.png  \n",
            "  inflating: hidden/video_16444/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16444/._image_2.png  \n",
            "  inflating: hidden/video_16444/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16444/._image_3.png  \n",
            "  inflating: hidden/video_16444/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16444/._image_1.png  \n",
            "  inflating: hidden/video_16444/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16444/._image_0.png  \n",
            "  inflating: hidden/video_16444/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16444/._image_4.png  \n",
            "  inflating: hidden/video_16444/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16444/._image_5.png  \n",
            "  inflating: hidden/video_16444/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16444/._image_7.png  \n",
            "  inflating: hidden/video_16444/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16444/._image_6.png  \n",
            "  inflating: hidden/video_16676/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16676/._image_10.png  \n",
            "  inflating: hidden/video_16676/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16676/._image_8.png  \n",
            "  inflating: hidden/video_16676/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16676/._image_9.png  \n",
            "  inflating: hidden/video_16676/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16676/._image_2.png  \n",
            "  inflating: hidden/video_16676/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16676/._image_3.png  \n",
            "  inflating: hidden/video_16676/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16676/._image_1.png  \n",
            "  inflating: hidden/video_16676/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16676/._image_0.png  \n",
            "  inflating: hidden/video_16676/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16676/._image_4.png  \n",
            "  inflating: hidden/video_16676/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16676/._image_5.png  \n",
            "  inflating: hidden/video_16676/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16676/._image_7.png  \n",
            "  inflating: hidden/video_16676/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16676/._image_6.png  \n",
            "  inflating: hidden/video_15497/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15497/._image_10.png  \n",
            "  inflating: hidden/video_15497/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15497/._image_8.png  \n",
            "  inflating: hidden/video_15497/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15497/._image_9.png  \n",
            "  inflating: hidden/video_15497/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15497/._image_2.png  \n",
            "  inflating: hidden/video_15497/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15497/._image_3.png  \n",
            "  inflating: hidden/video_15497/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15497/._image_1.png  \n",
            "  inflating: hidden/video_15497/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15497/._image_0.png  \n",
            "  inflating: hidden/video_15497/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15497/._image_4.png  \n",
            "  inflating: hidden/video_15497/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15497/._image_5.png  \n",
            "  inflating: hidden/video_15497/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15497/._image_7.png  \n",
            "  inflating: hidden/video_15497/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15497/._image_6.png  \n",
            "  inflating: hidden/video_16212/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16212/._image_10.png  \n",
            "  inflating: hidden/video_16212/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16212/._image_8.png  \n",
            "  inflating: hidden/video_16212/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16212/._image_9.png  \n",
            "  inflating: hidden/video_16212/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16212/._image_2.png  \n",
            "  inflating: hidden/video_16212/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16212/._image_3.png  \n",
            "  inflating: hidden/video_16212/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16212/._image_1.png  \n",
            "  inflating: hidden/video_16212/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16212/._image_0.png  \n",
            "  inflating: hidden/video_16212/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16212/._image_4.png  \n",
            "  inflating: hidden/video_16212/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16212/._image_5.png  \n",
            "  inflating: hidden/video_16212/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16212/._image_7.png  \n",
            "  inflating: hidden/video_16212/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16212/._image_6.png  \n",
            "  inflating: hidden/video_16020/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16020/._image_10.png  \n",
            "  inflating: hidden/video_16020/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16020/._image_8.png  \n",
            "  inflating: hidden/video_16020/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16020/._image_9.png  \n",
            "  inflating: hidden/video_16020/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16020/._image_2.png  \n",
            "  inflating: hidden/video_16020/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16020/._image_3.png  \n",
            "  inflating: hidden/video_16020/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16020/._image_1.png  \n",
            "  inflating: hidden/video_16020/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16020/._image_0.png  \n",
            "  inflating: hidden/video_16020/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16020/._image_4.png  \n",
            "  inflating: hidden/video_16020/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16020/._image_5.png  \n",
            "  inflating: hidden/video_16020/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16020/._image_7.png  \n",
            "  inflating: hidden/video_16020/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16020/._image_6.png  \n",
            "  inflating: hidden/video_15463/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15463/._image_10.png  \n",
            "  inflating: hidden/video_15463/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15463/._image_8.png  \n",
            "  inflating: hidden/video_15463/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15463/._image_9.png  \n",
            "  inflating: hidden/video_15463/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15463/._image_2.png  \n",
            "  inflating: hidden/video_15463/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15463/._image_3.png  \n",
            "  inflating: hidden/video_15463/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15463/._image_1.png  \n",
            "  inflating: hidden/video_15463/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15463/._image_0.png  \n",
            "  inflating: hidden/video_15463/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15463/._image_4.png  \n",
            "  inflating: hidden/video_15463/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15463/._image_5.png  \n",
            "  inflating: hidden/video_15463/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15463/._image_7.png  \n",
            "  inflating: hidden/video_15463/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15463/._image_6.png  \n",
            "  inflating: hidden/video_15651/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15651/._image_10.png  \n",
            "  inflating: hidden/video_15651/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15651/._image_8.png  \n",
            "  inflating: hidden/video_15651/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15651/._image_9.png  \n",
            "  inflating: hidden/video_15651/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15651/._image_2.png  \n",
            "  inflating: hidden/video_15651/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15651/._image_3.png  \n",
            "  inflating: hidden/video_15651/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15651/._image_1.png  \n",
            "  inflating: hidden/video_15651/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15651/._image_0.png  \n",
            "  inflating: hidden/video_15651/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15651/._image_4.png  \n",
            "  inflating: hidden/video_15651/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15651/._image_5.png  \n",
            "  inflating: hidden/video_15651/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15651/._image_7.png  \n",
            "  inflating: hidden/video_15651/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15651/._image_6.png  \n",
            "  inflating: hidden/video_15235/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15235/._image_10.png  \n",
            "  inflating: hidden/video_15235/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15235/._image_8.png  \n",
            "  inflating: hidden/video_15235/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15235/._image_9.png  \n",
            "  inflating: hidden/video_15235/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15235/._image_2.png  \n",
            "  inflating: hidden/video_15235/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15235/._image_3.png  \n",
            "  inflating: hidden/video_15235/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15235/._image_1.png  \n",
            "  inflating: hidden/video_15235/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15235/._image_0.png  \n",
            "  inflating: hidden/video_15235/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15235/._image_4.png  \n",
            "  inflating: hidden/video_15235/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15235/._image_5.png  \n",
            "  inflating: hidden/video_15235/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15235/._image_7.png  \n",
            "  inflating: hidden/video_15235/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15235/._image_6.png  \n",
            "  inflating: hidden/video_15007/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15007/._image_10.png  \n",
            "  inflating: hidden/video_15007/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15007/._image_8.png  \n",
            "  inflating: hidden/video_15007/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15007/._image_9.png  \n",
            "  inflating: hidden/video_15007/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15007/._image_2.png  \n",
            "  inflating: hidden/video_15007/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15007/._image_3.png  \n",
            "  inflating: hidden/video_15007/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15007/._image_1.png  \n",
            "  inflating: hidden/video_15007/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15007/._image_0.png  \n",
            "  inflating: hidden/video_15007/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15007/._image_4.png  \n",
            "  inflating: hidden/video_15007/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15007/._image_5.png  \n",
            "  inflating: hidden/video_15007/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15007/._image_7.png  \n",
            "  inflating: hidden/video_15007/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15007/._image_6.png  \n",
            "  inflating: hidden/video_16682/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16682/._image_10.png  \n",
            "  inflating: hidden/video_16682/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16682/._image_8.png  \n",
            "  inflating: hidden/video_16682/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16682/._image_9.png  \n",
            "  inflating: hidden/video_16682/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16682/._image_2.png  \n",
            "  inflating: hidden/video_16682/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16682/._image_3.png  \n",
            "  inflating: hidden/video_16682/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16682/._image_1.png  \n",
            "  inflating: hidden/video_16682/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16682/._image_0.png  \n",
            "  inflating: hidden/video_16682/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16682/._image_4.png  \n",
            "  inflating: hidden/video_16682/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16682/._image_5.png  \n",
            "  inflating: hidden/video_16682/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16682/._image_7.png  \n",
            "  inflating: hidden/video_16682/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16682/._image_6.png  \n",
            "  inflating: hidden/video_16815/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16815/._image_10.png  \n",
            "  inflating: hidden/video_16815/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16815/._image_8.png  \n",
            "  inflating: hidden/video_16815/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16815/._image_9.png  \n",
            "  inflating: hidden/video_16815/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16815/._image_2.png  \n",
            "  inflating: hidden/video_16815/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16815/._image_3.png  \n",
            "  inflating: hidden/video_16815/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16815/._image_1.png  \n",
            "  inflating: hidden/video_16815/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16815/._image_0.png  \n",
            "  inflating: hidden/video_16815/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16815/._image_4.png  \n",
            "  inflating: hidden/video_16815/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16815/._image_5.png  \n",
            "  inflating: hidden/video_16815/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16815/._image_7.png  \n",
            "  inflating: hidden/video_16815/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16815/._image_6.png  \n",
            "  inflating: hidden/video_16029/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16029/._image_10.png  \n",
            "  inflating: hidden/video_16029/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16029/._image_8.png  \n",
            "  inflating: hidden/video_16029/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16029/._image_9.png  \n",
            "  inflating: hidden/video_16029/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16029/._image_2.png  \n",
            "  inflating: hidden/video_16029/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16029/._image_3.png  \n",
            "  inflating: hidden/video_16029/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16029/._image_1.png  \n",
            "  inflating: hidden/video_16029/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16029/._image_0.png  \n",
            "  inflating: hidden/video_16029/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16029/._image_4.png  \n",
            "  inflating: hidden/video_16029/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16029/._image_5.png  \n",
            "  inflating: hidden/video_16029/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16029/._image_7.png  \n",
            "  inflating: hidden/video_16029/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16029/._image_6.png  \n",
            "  inflating: hidden/video_15658/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15658/._image_10.png  \n",
            "  inflating: hidden/video_15658/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15658/._image_8.png  \n",
            "  inflating: hidden/video_15658/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15658/._image_9.png  \n",
            "  inflating: hidden/video_15658/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15658/._image_2.png  \n",
            "  inflating: hidden/video_15658/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15658/._image_3.png  \n",
            "  inflating: hidden/video_15658/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15658/._image_1.png  \n",
            "  inflating: hidden/video_15658/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15658/._image_0.png  \n",
            "  inflating: hidden/video_15658/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15658/._image_4.png  \n",
            "  inflating: hidden/video_15658/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15658/._image_5.png  \n",
            "  inflating: hidden/video_15658/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15658/._image_7.png  \n",
            "  inflating: hidden/video_15658/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15658/._image_6.png  \n",
            "  inflating: hidden/video_15832/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15832/._image_10.png  \n",
            "  inflating: hidden/video_15832/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15832/._image_8.png  \n",
            "  inflating: hidden/video_15832/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15832/._image_9.png  \n",
            "  inflating: hidden/video_15832/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15832/._image_2.png  \n",
            "  inflating: hidden/video_15832/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15832/._image_3.png  \n",
            "  inflating: hidden/video_15832/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15832/._image_1.png  \n",
            "  inflating: hidden/video_15832/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15832/._image_0.png  \n",
            "  inflating: hidden/video_15832/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15832/._image_4.png  \n",
            "  inflating: hidden/video_15832/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15832/._image_5.png  \n",
            "  inflating: hidden/video_15832/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15832/._image_7.png  \n",
            "  inflating: hidden/video_15832/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15832/._image_6.png  \n",
            "  inflating: hidden/video_16224/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16224/._image_10.png  \n",
            "  inflating: hidden/video_16224/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16224/._image_8.png  \n",
            "  inflating: hidden/video_16224/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16224/._image_9.png  \n",
            "  inflating: hidden/video_16224/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16224/._image_2.png  \n",
            "  inflating: hidden/video_16224/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16224/._image_3.png  \n",
            "  inflating: hidden/video_16224/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16224/._image_1.png  \n",
            "  inflating: hidden/video_16224/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16224/._image_0.png  \n",
            "  inflating: hidden/video_16224/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16224/._image_4.png  \n",
            "  inflating: hidden/video_16224/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16224/._image_5.png  \n",
            "  inflating: hidden/video_16224/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16224/._image_7.png  \n",
            "  inflating: hidden/video_16224/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16224/._image_6.png  \n",
            "  inflating: hidden/video_15693/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15693/._image_10.png  \n",
            "  inflating: hidden/video_15693/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15693/._image_8.png  \n",
            "  inflating: hidden/video_15693/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15693/._image_9.png  \n",
            "  inflating: hidden/video_15693/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15693/._image_2.png  \n",
            "  inflating: hidden/video_15693/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15693/._image_3.png  \n",
            "  inflating: hidden/video_15693/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15693/._image_1.png  \n",
            "  inflating: hidden/video_15693/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15693/._image_0.png  \n",
            "  inflating: hidden/video_15693/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15693/._image_4.png  \n",
            "  inflating: hidden/video_15693/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15693/._image_5.png  \n",
            "  inflating: hidden/video_15693/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15693/._image_7.png  \n",
            "  inflating: hidden/video_15693/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15693/._image_6.png  \n",
            "  inflating: hidden/video_16016/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16016/._image_10.png  \n",
            "  inflating: hidden/video_16016/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16016/._image_8.png  \n",
            "  inflating: hidden/video_16016/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16016/._image_9.png  \n",
            "  inflating: hidden/video_16016/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16016/._image_2.png  \n",
            "  inflating: hidden/video_16016/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16016/._image_3.png  \n",
            "  inflating: hidden/video_16016/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16016/._image_1.png  \n",
            "  inflating: hidden/video_16016/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16016/._image_0.png  \n",
            "  inflating: hidden/video_16016/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16016/._image_4.png  \n",
            "  inflating: hidden/video_16016/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16016/._image_5.png  \n",
            "  inflating: hidden/video_16016/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16016/._image_7.png  \n",
            "  inflating: hidden/video_16016/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16016/._image_6.png  \n",
            "  inflating: hidden/video_16472/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16472/._image_10.png  \n",
            "  inflating: hidden/video_16472/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16472/._image_8.png  \n",
            "  inflating: hidden/video_16472/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16472/._image_9.png  \n",
            "  inflating: hidden/video_16472/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16472/._image_2.png  \n",
            "  inflating: hidden/video_16472/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16472/._image_3.png  \n",
            "  inflating: hidden/video_16472/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16472/._image_1.png  \n",
            "  inflating: hidden/video_16472/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16472/._image_0.png  \n",
            "  inflating: hidden/video_16472/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16472/._image_4.png  \n",
            "  inflating: hidden/video_16472/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16472/._image_5.png  \n",
            "  inflating: hidden/video_16472/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16472/._image_7.png  \n",
            "  inflating: hidden/video_16472/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16472/._image_6.png  \n",
            "  inflating: hidden/video_16640/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16640/._image_10.png  \n",
            "  inflating: hidden/video_16640/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16640/._image_8.png  \n",
            "  inflating: hidden/video_16640/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16640/._image_9.png  \n",
            "  inflating: hidden/video_16640/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16640/._image_2.png  \n",
            "  inflating: hidden/video_16640/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16640/._image_3.png  \n",
            "  inflating: hidden/video_16640/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16640/._image_1.png  \n",
            "  inflating: hidden/video_16640/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16640/._image_0.png  \n",
            "  inflating: hidden/video_16640/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16640/._image_4.png  \n",
            "  inflating: hidden/video_16640/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16640/._image_5.png  \n",
            "  inflating: hidden/video_16640/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16640/._image_7.png  \n",
            "  inflating: hidden/video_16640/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16640/._image_6.png  \n",
            "  inflating: hidden/video_15203/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15203/._image_10.png  \n",
            "  inflating: hidden/video_15203/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15203/._image_8.png  \n",
            "  inflating: hidden/video_15203/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15203/._image_9.png  \n",
            "  inflating: hidden/video_15203/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15203/._image_2.png  \n",
            "  inflating: hidden/video_15203/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15203/._image_3.png  \n",
            "  inflating: hidden/video_15203/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15203/._image_1.png  \n",
            "  inflating: hidden/video_15203/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15203/._image_0.png  \n",
            "  inflating: hidden/video_15203/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15203/._image_4.png  \n",
            "  inflating: hidden/video_15203/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15203/._image_5.png  \n",
            "  inflating: hidden/video_15203/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15203/._image_7.png  \n",
            "  inflating: hidden/video_15203/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15203/._image_6.png  \n",
            "  inflating: hidden/video_16486/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16486/._image_10.png  \n",
            "  inflating: hidden/video_16486/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16486/._image_8.png  \n",
            "  inflating: hidden/video_16486/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16486/._image_9.png  \n",
            "  inflating: hidden/video_16486/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16486/._image_2.png  \n",
            "  inflating: hidden/video_16486/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16486/._image_3.png  \n",
            "  inflating: hidden/video_16486/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16486/._image_1.png  \n",
            "  inflating: hidden/video_16486/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16486/._image_0.png  \n",
            "  inflating: hidden/video_16486/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16486/._image_4.png  \n",
            "  inflating: hidden/video_16486/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16486/._image_5.png  \n",
            "  inflating: hidden/video_16486/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16486/._image_7.png  \n",
            "  inflating: hidden/video_16486/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16486/._image_6.png  \n",
            "  inflating: hidden/video_15031/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15031/._image_10.png  \n",
            "  inflating: hidden/video_15031/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15031/._image_8.png  \n",
            "  inflating: hidden/video_15031/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15031/._image_9.png  \n",
            "  inflating: hidden/video_15031/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15031/._image_2.png  \n",
            "  inflating: hidden/video_15031/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15031/._image_3.png  \n",
            "  inflating: hidden/video_15031/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15031/._image_1.png  \n",
            "  inflating: hidden/video_15031/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15031/._image_0.png  \n",
            "  inflating: hidden/video_15031/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15031/._image_4.png  \n",
            "  inflating: hidden/video_15031/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15031/._image_5.png  \n",
            "  inflating: hidden/video_15031/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15031/._image_7.png  \n",
            "  inflating: hidden/video_15031/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15031/._image_6.png  \n",
            "  inflating: hidden/video_15455/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15455/._image_10.png  \n",
            "  inflating: hidden/video_15455/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15455/._image_8.png  \n",
            "  inflating: hidden/video_15455/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15455/._image_9.png  \n",
            "  inflating: hidden/video_15455/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15455/._image_2.png  \n",
            "  inflating: hidden/video_15455/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15455/._image_3.png  \n",
            "  inflating: hidden/video_15455/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15455/._image_1.png  \n",
            "  inflating: hidden/video_15455/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15455/._image_0.png  \n",
            "  inflating: hidden/video_15455/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15455/._image_4.png  \n",
            "  inflating: hidden/video_15455/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15455/._image_5.png  \n",
            "  inflating: hidden/video_15455/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15455/._image_7.png  \n",
            "  inflating: hidden/video_15455/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15455/._image_6.png  \n",
            "  inflating: hidden/video_15667/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15667/._image_10.png  \n",
            "  inflating: hidden/video_15667/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15667/._image_8.png  \n",
            "  inflating: hidden/video_15667/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15667/._image_9.png  \n",
            "  inflating: hidden/video_15667/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15667/._image_2.png  \n",
            "  inflating: hidden/video_15667/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15667/._image_3.png  \n",
            "  inflating: hidden/video_15667/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15667/._image_1.png  \n",
            "  inflating: hidden/video_15667/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15667/._image_0.png  \n",
            "  inflating: hidden/video_15667/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15667/._image_4.png  \n",
            "  inflating: hidden/video_15667/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15667/._image_5.png  \n",
            "  inflating: hidden/video_15667/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15667/._image_7.png  \n",
            "  inflating: hidden/video_15667/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15667/._image_6.png  \n",
            "  inflating: hidden/video_15009/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15009/._image_10.png  \n",
            "  inflating: hidden/video_15009/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15009/._image_8.png  \n",
            "  inflating: hidden/video_15009/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15009/._image_9.png  \n",
            "  inflating: hidden/video_15009/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15009/._image_2.png  \n",
            "  inflating: hidden/video_15009/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15009/._image_3.png  \n",
            "  inflating: hidden/video_15009/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15009/._image_1.png  \n",
            "  inflating: hidden/video_15009/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15009/._image_0.png  \n",
            "  inflating: hidden/video_15009/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15009/._image_4.png  \n",
            "  inflating: hidden/video_15009/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15009/._image_5.png  \n",
            "  inflating: hidden/video_15009/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15009/._image_7.png  \n",
            "  inflating: hidden/video_15009/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15009/._image_6.png  \n",
            "  inflating: hidden/video_15835/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15835/._image_10.png  \n",
            "  inflating: hidden/video_15835/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15835/._image_8.png  \n",
            "  inflating: hidden/video_15835/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15835/._image_9.png  \n",
            "  inflating: hidden/video_15835/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15835/._image_2.png  \n",
            "  inflating: hidden/video_15835/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15835/._image_3.png  \n",
            "  inflating: hidden/video_15835/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15835/._image_1.png  \n",
            "  inflating: hidden/video_15835/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15835/._image_0.png  \n",
            "  inflating: hidden/video_15835/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15835/._image_4.png  \n",
            "  inflating: hidden/video_15835/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15835/._image_5.png  \n",
            "  inflating: hidden/video_15835/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15835/._image_7.png  \n",
            "  inflating: hidden/video_15835/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15835/._image_6.png  \n",
            "  inflating: hidden/video_15499/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15499/._image_10.png  \n",
            "  inflating: hidden/video_15499/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15499/._image_8.png  \n",
            "  inflating: hidden/video_15499/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15499/._image_9.png  \n",
            "  inflating: hidden/video_15499/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15499/._image_2.png  \n",
            "  inflating: hidden/video_15499/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15499/._image_3.png  \n",
            "  inflating: hidden/video_15499/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15499/._image_1.png  \n",
            "  inflating: hidden/video_15499/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15499/._image_0.png  \n",
            "  inflating: hidden/video_15499/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15499/._image_4.png  \n",
            "  inflating: hidden/video_15499/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15499/._image_5.png  \n",
            "  inflating: hidden/video_15499/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15499/._image_7.png  \n",
            "  inflating: hidden/video_15499/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15499/._image_6.png  \n",
            "  inflating: hidden/video_16812/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16812/._image_10.png  \n",
            "  inflating: hidden/video_16812/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16812/._image_8.png  \n",
            "  inflating: hidden/video_16812/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16812/._image_9.png  \n",
            "  inflating: hidden/video_16812/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16812/._image_2.png  \n",
            "  inflating: hidden/video_16812/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16812/._image_3.png  \n",
            "  inflating: hidden/video_16812/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16812/._image_1.png  \n",
            "  inflating: hidden/video_16812/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16812/._image_0.png  \n",
            "  inflating: hidden/video_16812/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16812/._image_4.png  \n",
            "  inflating: hidden/video_16812/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16812/._image_5.png  \n",
            "  inflating: hidden/video_16812/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16812/._image_7.png  \n",
            "  inflating: hidden/video_16812/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16812/._image_6.png  \n",
            "  inflating: hidden/video_16678/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16678/._image_10.png  \n",
            "  inflating: hidden/video_16678/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16678/._image_8.png  \n",
            "  inflating: hidden/video_16678/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16678/._image_9.png  \n",
            "  inflating: hidden/video_16678/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16678/._image_2.png  \n",
            "  inflating: hidden/video_16678/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16678/._image_3.png  \n",
            "  inflating: hidden/video_16678/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16678/._image_1.png  \n",
            "  inflating: hidden/video_16678/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16678/._image_0.png  \n",
            "  inflating: hidden/video_16678/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16678/._image_4.png  \n",
            "  inflating: hidden/video_16678/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16678/._image_5.png  \n",
            "  inflating: hidden/video_16678/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16678/._image_7.png  \n",
            "  inflating: hidden/video_16678/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16678/._image_6.png  \n",
            "  inflating: hidden/video_15660/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15660/._image_10.png  \n",
            "  inflating: hidden/video_15660/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15660/._image_8.png  \n",
            "  inflating: hidden/video_15660/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15660/._image_9.png  \n",
            "  inflating: hidden/video_15660/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15660/._image_2.png  \n",
            "  inflating: hidden/video_15660/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15660/._image_3.png  \n",
            "  inflating: hidden/video_15660/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15660/._image_1.png  \n",
            "  inflating: hidden/video_15660/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15660/._image_0.png  \n",
            "  inflating: hidden/video_15660/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15660/._image_4.png  \n",
            "  inflating: hidden/video_15660/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15660/._image_5.png  \n",
            "  inflating: hidden/video_15660/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15660/._image_7.png  \n",
            "  inflating: hidden/video_15660/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15660/._image_6.png  \n",
            "  inflating: hidden/video_15452/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15452/._image_10.png  \n",
            "  inflating: hidden/video_15452/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15452/._image_8.png  \n",
            "  inflating: hidden/video_15452/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15452/._image_9.png  \n",
            "  inflating: hidden/video_15452/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15452/._image_2.png  \n",
            "  inflating: hidden/video_15452/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15452/._image_3.png  \n",
            "  inflating: hidden/video_15452/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15452/._image_1.png  \n",
            "  inflating: hidden/video_15452/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15452/._image_0.png  \n",
            "  inflating: hidden/video_15452/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15452/._image_4.png  \n",
            "  inflating: hidden/video_15452/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15452/._image_5.png  \n",
            "  inflating: hidden/video_15452/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15452/._image_7.png  \n",
            "  inflating: hidden/video_15452/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15452/._image_6.png  \n",
            "  inflating: hidden/video_15036/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15036/._image_10.png  \n",
            "  inflating: hidden/video_15036/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15036/._image_8.png  \n",
            "  inflating: hidden/video_15036/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15036/._image_9.png  \n",
            "  inflating: hidden/video_15036/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15036/._image_2.png  \n",
            "  inflating: hidden/video_15036/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15036/._image_3.png  \n",
            "  inflating: hidden/video_15036/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15036/._image_1.png  \n",
            "  inflating: hidden/video_15036/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15036/._image_0.png  \n",
            "  inflating: hidden/video_15036/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15036/._image_4.png  \n",
            "  inflating: hidden/video_15036/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15036/._image_5.png  \n",
            "  inflating: hidden/video_15036/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15036/._image_7.png  \n",
            "  inflating: hidden/video_15036/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15036/._image_6.png  \n",
            "  inflating: hidden/video_15204/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15204/._image_10.png  \n",
            "  inflating: hidden/video_15204/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15204/._image_8.png  \n",
            "  inflating: hidden/video_15204/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15204/._image_9.png  \n",
            "  inflating: hidden/video_15204/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15204/._image_2.png  \n",
            "  inflating: hidden/video_15204/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15204/._image_3.png  \n",
            "  inflating: hidden/video_15204/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15204/._image_1.png  \n",
            "  inflating: hidden/video_15204/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15204/._image_0.png  \n",
            "  inflating: hidden/video_15204/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15204/._image_4.png  \n",
            "  inflating: hidden/video_15204/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15204/._image_5.png  \n",
            "  inflating: hidden/video_15204/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15204/._image_7.png  \n",
            "  inflating: hidden/video_15204/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15204/._image_6.png  \n",
            "  inflating: hidden/video_16481/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16481/._image_10.png  \n",
            "  inflating: hidden/video_16481/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16481/._image_8.png  \n",
            "  inflating: hidden/video_16481/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16481/._image_9.png  \n",
            "  inflating: hidden/video_16481/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16481/._image_2.png  \n",
            "  inflating: hidden/video_16481/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16481/._image_3.png  \n",
            "  inflating: hidden/video_16481/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16481/._image_1.png  \n",
            "  inflating: hidden/video_16481/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16481/._image_0.png  \n",
            "  inflating: hidden/video_16481/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16481/._image_4.png  \n",
            "  inflating: hidden/video_16481/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16481/._image_5.png  \n",
            "  inflating: hidden/video_16481/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16481/._image_7.png  \n",
            "  inflating: hidden/video_16481/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16481/._image_6.png  \n",
            "  inflating: hidden/video_16647/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16647/._image_10.png  \n",
            "  inflating: hidden/video_16647/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16647/._image_8.png  \n",
            "  inflating: hidden/video_16647/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16647/._image_9.png  \n",
            "  inflating: hidden/video_16647/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16647/._image_2.png  \n",
            "  inflating: hidden/video_16647/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16647/._image_3.png  \n",
            "  inflating: hidden/video_16647/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16647/._image_1.png  \n",
            "  inflating: hidden/video_16647/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16647/._image_0.png  \n",
            "  inflating: hidden/video_16647/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16647/._image_4.png  \n",
            "  inflating: hidden/video_16647/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16647/._image_5.png  \n",
            "  inflating: hidden/video_16647/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16647/._image_7.png  \n",
            "  inflating: hidden/video_16647/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16647/._image_6.png  \n",
            "  inflating: hidden/video_16475/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16475/._image_10.png  \n",
            "  inflating: hidden/video_16475/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16475/._image_8.png  \n",
            "  inflating: hidden/video_16475/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16475/._image_9.png  \n",
            "  inflating: hidden/video_16475/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16475/._image_2.png  \n",
            "  inflating: hidden/video_16475/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16475/._image_3.png  \n",
            "  inflating: hidden/video_16475/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16475/._image_1.png  \n",
            "  inflating: hidden/video_16475/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16475/._image_0.png  \n",
            "  inflating: hidden/video_16475/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16475/._image_4.png  \n",
            "  inflating: hidden/video_16475/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16475/._image_5.png  \n",
            "  inflating: hidden/video_16475/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16475/._image_7.png  \n",
            "  inflating: hidden/video_16475/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16475/._image_6.png  \n",
            "  inflating: hidden/video_15694/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_15694/._image_10.png  \n",
            "  inflating: hidden/video_15694/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_15694/._image_8.png  \n",
            "  inflating: hidden/video_15694/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_15694/._image_9.png  \n",
            "  inflating: hidden/video_15694/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_15694/._image_2.png  \n",
            "  inflating: hidden/video_15694/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_15694/._image_3.png  \n",
            "  inflating: hidden/video_15694/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_15694/._image_1.png  \n",
            "  inflating: hidden/video_15694/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_15694/._image_0.png  \n",
            "  inflating: hidden/video_15694/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_15694/._image_4.png  \n",
            "  inflating: hidden/video_15694/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_15694/._image_5.png  \n",
            "  inflating: hidden/video_15694/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_15694/._image_7.png  \n",
            "  inflating: hidden/video_15694/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_15694/._image_6.png  \n",
            "  inflating: hidden/video_16011/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16011/._image_10.png  \n",
            "  inflating: hidden/video_16011/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16011/._image_8.png  \n",
            "  inflating: hidden/video_16011/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16011/._image_9.png  \n",
            "  inflating: hidden/video_16011/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16011/._image_2.png  \n",
            "  inflating: hidden/video_16011/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16011/._image_3.png  \n",
            "  inflating: hidden/video_16011/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16011/._image_1.png  \n",
            "  inflating: hidden/video_16011/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16011/._image_0.png  \n",
            "  inflating: hidden/video_16011/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16011/._image_4.png  \n",
            "  inflating: hidden/video_16011/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16011/._image_5.png  \n",
            "  inflating: hidden/video_16011/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16011/._image_7.png  \n",
            "  inflating: hidden/video_16011/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16011/._image_6.png  \n",
            "  inflating: hidden/video_16223/image_10.png  \n",
            "  inflating: __MACOSX/hidden/video_16223/._image_10.png  \n",
            "  inflating: hidden/video_16223/image_8.png  \n",
            "  inflating: __MACOSX/hidden/video_16223/._image_8.png  \n",
            "  inflating: hidden/video_16223/image_9.png  \n",
            "  inflating: __MACOSX/hidden/video_16223/._image_9.png  \n",
            "  inflating: hidden/video_16223/image_2.png  \n",
            "  inflating: __MACOSX/hidden/video_16223/._image_2.png  \n",
            "  inflating: hidden/video_16223/image_3.png  \n",
            "  inflating: __MACOSX/hidden/video_16223/._image_3.png  \n",
            "  inflating: hidden/video_16223/image_1.png  \n",
            "  inflating: __MACOSX/hidden/video_16223/._image_1.png  \n",
            "  inflating: hidden/video_16223/image_0.png  \n",
            "  inflating: __MACOSX/hidden/video_16223/._image_0.png  \n",
            "  inflating: hidden/video_16223/image_4.png  \n",
            "  inflating: __MACOSX/hidden/video_16223/._image_4.png  \n",
            "  inflating: hidden/video_16223/image_5.png  \n",
            "  inflating: __MACOSX/hidden/video_16223/._image_5.png  \n",
            "  inflating: hidden/video_16223/image_7.png  \n",
            "  inflating: __MACOSX/hidden/video_16223/._image_7.png  \n",
            "  inflating: hidden/video_16223/image_6.png  \n",
            "  inflating: __MACOSX/hidden/video_16223/._image_6.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv hidden/ data/\n",
        "!mkdir hidden/\n",
        "!mv data/ hidden/data/"
      ],
      "metadata": {
        "id": "fUJ6aauS_VRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Annotate the hidden set\n",
        "import sys\n",
        "\n",
        "def annotate(min_i,max_i,output_dir):\n",
        "    with open(output_dir + 'annotations.txt', 'w') as f:\n",
        "        for i in range(min_i, max_i):\n",
        "            f.write(f'video_{i} 0 10 0 \\n') #should be 11 frames instead of 22\n",
        "\n",
        "\n",
        "annotate(15000, 17000, 'hidden/')"
      ],
      "metadata": {
        "id": "ToBNvUWOP-GS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Dataloader method\n",
        "# are these the correct settings? Cannot reuse previous load_data method unless we add mask and shuffle as passable params\n",
        "def load_hidden_data(root, annotation_file, batch_size=2):\n",
        "    preprocess = transforms.Compose([\n",
        "            ImglistToTensor(),  # list of PIL images to (FRAMES x CHANNELS x HEIGHT x WIDTH) tensor\n",
        "            # transforms.Resize(299),  # image batch, resize smaller edge to 299\n",
        "            transforms.Resize((128,128)),\n",
        "            # transforms.CenterCrop(299),  # image batch, center crop to square 299x299\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "    dataset = VideoFrameDataset(\n",
        "        root_path=root,\n",
        "        annotationfile_path=annotation_file,\n",
        "        num_segments=1,\n",
        "        frames_per_segment=11,\n",
        "        imagefile_template='image_{:d}.png',\n",
        "        transform=preprocess,\n",
        "        mask=False,\n",
        "        test_mode=False\n",
        "    )\n",
        "\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "            dataset=dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=2,\n",
        "            pin_memory=True\n",
        "        )\n",
        "    return dataloader\n",
        "\n",
        "### Load the train and validation datasets\n",
        "batch_size = 1\n",
        "hiddenloader = load_hidden_data('hidden/data/', 'hidden/annotations.txt', batch_size)"
      ],
      "metadata": {
        "id": "h5WYcaIHQz53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Use Encoder and Decoder to predict the hidden set\n",
        "\n",
        "# From brightspace:\n",
        "# There are 2000 videos with 11 frames each in the hidden dataset.\n",
        "# You need to submit a saved pytorch tensor or numpy array with the size (2000, 160, 240) \n",
        "# that each (160, 240) matrix corresponding to the mask of 22nd frame of each video in the hidden set.\n",
        "\n",
        "#predicted mask for frame 22, in order\n",
        "def predict_masks_for_hidden(encoder, decoder, hiddenloader):\n",
        "    hidden_results = []\n",
        "\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    for i, data in enumerate(hiddenloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        print(f\"input shape: {inputs.shape}\")\n",
        "\n",
        "        # forward pass through encoder to get the embeddings\n",
        "        predicted_embeddings = encoder(inputs.transpose(1, 2))\n",
        "\n",
        "        print(f\"predicted_embeddings before reshape: {predicted_embeddings.shape}\")\n",
        "\n",
        "        # Reshape predicted embeddings to (b t) (h w) m\n",
        "        predicted_embeddings = rearrange(predicted_embeddings, 'b t n m -> (b t) n m')\n",
        "\n",
        "        print(f\"predicted_embeddings after reshape: {predicted_embeddings.shape}\")\n",
        "\n",
        "        # forward pass through decoder to get the masks\n",
        "        outputs = decoder(predicted_embeddings)\n",
        "\n",
        "        print(f\"outputs: {outputs.shape}\")\n",
        "\n",
        "        # use argmax to go from logits to classes\n",
        "        prediction = torch.argmax(outputs, 1)\n",
        "\n",
        "        #print(torch.max(prediction))\n",
        "\n",
        "\n",
        "        hidden_results.append(prediction[21]) # this only works when batch_size = 1\n",
        "\n",
        "    results_hidden_tensor = torch.stack(hidden_results)\n",
        "    return results_hidden_tensor\n",
        "\n",
        "results = predict_masks_for_hidden(encoder, decoder, hiddenloader)\n",
        "torch.save(results, 'results_hidden_tensor.pt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SG3e2TZiNC01",
        "outputId": "080ec8f3-b435-466e-f7ed-c477252dd72b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n",
            "input shape: torch.Size([1, 11, 3, 128, 128])\n",
            "predicted_embeddings before reshape: torch.Size([1, 22, 256, 384])\n",
            "predicted_embeddings after reshape: torch.Size([22, 256, 384])\n",
            "outputs: torch.Size([22, 49, 160, 240])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results.shape)\n",
        "\n",
        "print(torch.max(results[1000]))\n",
        "print(results[0])\n",
        "\n",
        "print(results.unique())\n",
        "\n",
        "plt.imshow(results[0].cpu().detach().numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "rXkWBFqYMg1h",
        "outputId": "f838848c-6248-4c3e-f692-c8bd36181c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2000, 160, 240])\n",
            "tensor(7, device='cuda:0')\n",
            "tensor([[7, 7, 7,  ..., 7, 7, 7],\n",
            "        [7, 7, 7,  ..., 7, 7, 7],\n",
            "        [7, 7, 7,  ..., 7, 7, 7],\n",
            "        ...,\n",
            "        [7, 7, 7,  ..., 7, 7, 7],\n",
            "        [7, 7, 7,  ..., 7, 7, 7],\n",
            "        [7, 7, 7,  ..., 7, 7, 7]], device='cuda:0')\n",
            "tensor([7], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1d64310100>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M = 8\n",
        "M2 = 4"
      ],
      "metadata": {
        "id": "iOvJsbNdq9WB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_cosine_similarity(embeddings):\n",
        "  first_patch_embeddings = embeddings[:, 0, :]\n",
        "  cosine_sim_matrix = F.cosine_similarity(first_patch_embeddings.unsqueeze(1), first_patch_embeddings.unsqueeze(0), dim=2)\n",
        "  # remove diagonal since it will always be 1\n",
        "  mean = (cosine_sim_matrix.sum() - cosine_sim_matrix.trace()) / (cosine_sim_matrix.numel() - cosine_sim_matrix.size(0))\n",
        "  sense_check = cosine_sim_matrix.trace()/cosine_sim_matrix.size(0) # should be 1\n",
        "  return mean, sense_check\n",
        "\n",
        "x = torch.rand(3000, 2, 4)\n",
        "mean_cosine_similarity(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzKsLKK7rD0X",
        "outputId": "81bd9e26-1e11-4ab9-fd32-496f5b9c1601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.7777), tensor(1.))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def compute_rank(prediction_blocks, threshold=0.95):\n",
        "  embeddings = prediction_blocks.reshape(-1, prediction_blocks.size(-1))\n",
        "\n",
        "  sample_mean = torch.mean(embeddings, dim=0, keepdim=True)\n",
        "\n",
        "  covariance = torch.matmul((embeddings - sample_mean).T, embeddings - sample_mean) / embeddings.size(0)\n",
        "  eigenvalues, _ = torch.linalg.eigh(covariance)\n",
        "\n",
        "  total_variance = torch.sum(eigenvalues)\n",
        "\n",
        "  explained_variance_ratio = eigenvalues / total_variance\n",
        "  cumulative_explained_variance_ratio = torch.cumsum(explained_variance_ratio, dim=0)\n",
        "\n",
        "  return torch.sum(cumulative_explained_variance_ratio < threshold) + 1\n",
        "\n",
        "def compute_rank_per_frame(prediction_blocks, threshold=0.95):\n",
        "  frame_ranks = torch.zeros(prediction_blocks.size(1), dtype=torch.int64)\n",
        "  for i in range(prediction_blocks.size(1)):\n",
        "    frame_ranks[i] = compute_rank(prediction_blocks[:, i, :, :], threshold)\n",
        "  \n",
        "  return frame_ranks\n",
        "\n",
        "x = torch.ones(4, 3, 8, 2758);\n",
        "y = torch.rand(5, 6, 8, 2758);\n",
        "\n",
        "print(x.shape)\n",
        "print(compute_rank(x))\n",
        "print(compute_rank_per_frame(x))\n",
        "print(compute_rank(y))\n",
        "print(compute_rank_per_frame(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtrO_eXFN7rn",
        "outputId": "d5d5d863-520d-4dbc-9744-8bb86f90458c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 8, 2758])\n",
            "tensor(1)\n",
            "tensor([1, 1, 1])\n",
            "tensor(2751)\n",
            "tensor([2757, 2757, 2757, 2757, 2757, 2757])\n"
          ]
        }
      ]
    }
  ]
}